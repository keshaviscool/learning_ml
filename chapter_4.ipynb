{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d90fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12014f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Haha')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"haha2\")\n",
    "plt.ylabel(\"Haha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f913e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100,1)), X] # just to increase the nuumber of features for demo purposes ig\n",
    "thetha_best = np.linalg.pinv(X_b.T.dot(X_b)).dot(X_b.T).dot(y) ## you can also use pinv... why??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48a03cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.16256879],\n",
       "       [2.88422668]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetha_best ## LEARN SVD and EigenValues and MOORE Penrose Inverse later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7ce1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2,1 )), X_new]\n",
    "\n",
    "y_predict = np.dot(X_new_b, thetha_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c9ae609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.16256879],\n",
       "       [9.93102214]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3723da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel = \"X\"\n",
    "plt.ylabel = \"Y\"\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5107101e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using scikit learn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca15e0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.16256879])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f7dd570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.88422668]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a97c2b",
   "metadata": {},
   "source": [
    " Now we will look at very different ways to train a Linear Regression model, better\n",
    " suited for cases where there are a large number of features, or too many training\n",
    " instances to fit in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4cf39",
   "metadata": {},
   "source": [
    "Suppose you are lost in the mountains in a dense fog; you can only feel the slope of\n",
    " the ground below your feet. A good strategy to get to the bottom of the valley quickly\n",
    " is to go downhill in the direction of the steepest slope. This is exactly what Gradient\n",
    " Descent does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bff386a",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf26776",
   "metadata": {},
   "source": [
    "### important\n",
    "\n",
    " When using Gradient Descent, you should ensure that all features\n",
    " have a similar scale (e.g., using Scikit-Learn’s StandardScaler\n",
    " class), or else it will take much longer to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5856bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# np.random.rand gives only between 0 and 1\n",
    "# np.random.randint gives only integers\n",
    "# np.random.randn gives maybe float values with no restriction??\n",
    "thetha = np.random.randn(2,1) # random intialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93ebd10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1 # learning rate\n",
    "n_iterations = 1000000 # also called, epochs\n",
    "m = 100 # number of data points (X)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(thetha) - y)\n",
    "\n",
    "    thetha = thetha - eta * gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f07dbc",
   "metadata": {},
   "source": [
    "To find a good learning rate, you can use Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b3b83",
   "metadata": {},
   "source": [
    "## Stochiastic (Random) Gradient Descent\n",
    "\n",
    "Therefore randomness is good to escape from local optima, but bad because it means\n",
    " that the algorithm can never settle at the minimum. One solution to this dilemma is\n",
    " to gradually reduce the learning rate. The steps start out large (which helps make\n",
    " quick progress and escape local minima), then get smaller and smaller, allowing the\n",
    " algorithm to settle at the global minimum. This process is called simulated annealing,\n",
    " because it resembles the process of annealing in metallurgy where molten metal is\n",
    " slowly cooled down. The function that determines the learning rate at each iteration\n",
    " is called the learning schedule. If the learning rate is reduced too quickly, you may get\n",
    " stuck in a local minimum, or even end up frozen halfway to the minimum. If the\n",
    " learning rate is reduced too slowly, you may jump around the minimum for a long\n",
    " time and end up with a suboptimal solution if you halt training too early."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31dbda",
   "metadata": {},
   "source": [
    "# implementing SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d0f6d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "t0, t1 = 5, 50 #learning schedule hyperparameters\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0/ (t+t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40cd59c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.09803921568627451\n",
      "0.09615384615384616\n",
      "0.09433962264150944\n",
      "0.09259259259259259\n",
      "0.09090909090909091\n",
      "0.08928571428571429\n",
      "0.08771929824561403\n",
      "0.08620689655172414\n",
      "0.0847457627118644\n",
      "0.08333333333333333\n",
      "0.08196721311475409\n",
      "0.08064516129032258\n",
      "0.07936507936507936\n",
      "0.078125\n",
      "0.07692307692307693\n",
      "0.07575757575757576\n",
      "0.07462686567164178\n",
      "0.07352941176470588\n",
      "0.07246376811594203\n",
      "0.07142857142857142\n",
      "0.07042253521126761\n",
      "0.06944444444444445\n",
      "0.0684931506849315\n",
      "0.06756756756756757\n",
      "0.06666666666666667\n",
      "0.06578947368421052\n",
      "0.06493506493506493\n",
      "0.0641025641025641\n",
      "0.06329113924050633\n",
      "0.0625\n",
      "0.06172839506172839\n",
      "0.06097560975609756\n",
      "0.060240963855421686\n",
      "0.05952380952380952\n",
      "0.058823529411764705\n",
      "0.05813953488372093\n",
      "0.05747126436781609\n",
      "0.056818181818181816\n",
      "0.056179775280898875\n",
      "0.05555555555555555\n",
      "0.054945054945054944\n",
      "0.05434782608695652\n",
      "0.053763440860215055\n",
      "0.05319148936170213\n",
      "0.05263157894736842\n",
      "0.052083333333333336\n",
      "0.05154639175257732\n",
      "0.05102040816326531\n",
      "0.050505050505050504\n",
      "0.05\n",
      "0.04950495049504951\n",
      "0.049019607843137254\n",
      "0.04854368932038835\n",
      "0.04807692307692308\n",
      "0.047619047619047616\n",
      "0.04716981132075472\n",
      "0.04672897196261682\n",
      "0.046296296296296294\n",
      "0.045871559633027525\n",
      "0.045454545454545456\n",
      "0.04504504504504504\n",
      "0.044642857142857144\n",
      "0.04424778761061947\n",
      "0.043859649122807015\n",
      "0.043478260869565216\n",
      "0.04310344827586207\n",
      "0.042735042735042736\n",
      "0.0423728813559322\n",
      "0.04201680672268908\n",
      "0.041666666666666664\n",
      "0.04132231404958678\n",
      "0.040983606557377046\n",
      "0.04065040650406504\n",
      "0.04032258064516129\n",
      "0.04\n",
      "0.03968253968253968\n",
      "0.03937007874015748\n",
      "0.0390625\n",
      "0.03875968992248062\n",
      "0.038461538461538464\n",
      "0.03816793893129771\n",
      "0.03787878787878788\n",
      "0.03759398496240601\n",
      "0.03731343283582089\n",
      "0.037037037037037035\n",
      "0.03676470588235294\n",
      "0.0364963503649635\n",
      "0.036231884057971016\n",
      "0.03597122302158273\n",
      "0.03571428571428571\n",
      "0.03546099290780142\n",
      "0.035211267605633804\n",
      "0.03496503496503497\n",
      "0.034722222222222224\n",
      "0.034482758620689655\n",
      "0.03424657534246575\n",
      "0.034013605442176874\n",
      "0.033783783783783786\n",
      "0.03355704697986577\n",
      "0.03333333333333333\n",
      "0.033112582781456956\n",
      "0.03289473684210526\n",
      "0.032679738562091505\n",
      "0.032467532467532464\n",
      "0.03225806451612903\n",
      "0.03205128205128205\n",
      "0.03184713375796178\n",
      "0.03164556962025317\n",
      "0.031446540880503145\n",
      "0.03125\n",
      "0.031055900621118012\n",
      "0.030864197530864196\n",
      "0.03067484662576687\n",
      "0.03048780487804878\n",
      "0.030303030303030304\n",
      "0.030120481927710843\n",
      "0.029940119760479042\n",
      "0.02976190476190476\n",
      "0.029585798816568046\n",
      "0.029411764705882353\n",
      "0.029239766081871343\n",
      "0.029069767441860465\n",
      "0.028901734104046242\n",
      "0.028735632183908046\n",
      "0.02857142857142857\n",
      "0.028409090909090908\n",
      "0.02824858757062147\n",
      "0.028089887640449437\n",
      "0.027932960893854747\n",
      "0.027777777777777776\n",
      "0.027624309392265192\n",
      "0.027472527472527472\n",
      "0.0273224043715847\n",
      "0.02717391304347826\n",
      "0.02702702702702703\n",
      "0.026881720430107527\n",
      "0.026737967914438502\n",
      "0.026595744680851064\n",
      "0.026455026455026454\n",
      "0.02631578947368421\n",
      "0.02617801047120419\n",
      "0.026041666666666668\n",
      "0.025906735751295335\n",
      "0.02577319587628866\n",
      "0.02564102564102564\n",
      "0.025510204081632654\n",
      "0.025380710659898477\n",
      "0.025252525252525252\n",
      "0.02512562814070352\n",
      "0.025\n",
      "0.024875621890547265\n",
      "0.024752475247524754\n",
      "0.024630541871921183\n",
      "0.024509803921568627\n",
      "0.024390243902439025\n",
      "0.024271844660194174\n",
      "0.024154589371980676\n",
      "0.02403846153846154\n",
      "0.023923444976076555\n",
      "0.023809523809523808\n",
      "0.023696682464454975\n",
      "0.02358490566037736\n",
      "0.023474178403755867\n",
      "0.02336448598130841\n",
      "0.023255813953488372\n",
      "0.023148148148148147\n",
      "0.02304147465437788\n",
      "0.022935779816513763\n",
      "0.0228310502283105\n",
      "0.022727272727272728\n",
      "0.02262443438914027\n",
      "0.02252252252252252\n",
      "0.02242152466367713\n",
      "0.022321428571428572\n",
      "0.022222222222222223\n",
      "0.022123893805309734\n",
      "0.022026431718061675\n",
      "0.021929824561403508\n",
      "0.021834061135371178\n",
      "0.021739130434782608\n",
      "0.021645021645021644\n",
      "0.021551724137931036\n",
      "0.02145922746781116\n",
      "0.021367521367521368\n",
      "0.02127659574468085\n",
      "0.0211864406779661\n",
      "0.02109704641350211\n",
      "0.02100840336134454\n",
      "0.02092050209205021\n",
      "0.020833333333333332\n",
      "0.02074688796680498\n",
      "0.02066115702479339\n",
      "0.0205761316872428\n",
      "0.020491803278688523\n",
      "0.02040816326530612\n",
      "0.02032520325203252\n",
      "0.020242914979757085\n",
      "0.020161290322580645\n",
      "0.020080321285140562\n",
      "0.02\n",
      "0.0199203187250996\n",
      "0.01984126984126984\n",
      "0.019762845849802372\n",
      "0.01968503937007874\n",
      "0.0196078431372549\n",
      "0.01953125\n",
      "0.019455252918287938\n",
      "0.01937984496124031\n",
      "0.019305019305019305\n",
      "0.019230769230769232\n",
      "0.019157088122605363\n",
      "0.019083969465648856\n",
      "0.019011406844106463\n",
      "0.01893939393939394\n",
      "0.018867924528301886\n",
      "0.018796992481203006\n",
      "0.018726591760299626\n",
      "0.018656716417910446\n",
      "0.01858736059479554\n",
      "0.018518518518518517\n",
      "0.01845018450184502\n",
      "0.01838235294117647\n",
      "0.018315018315018316\n",
      "0.01824817518248175\n",
      "0.01818181818181818\n",
      "0.018115942028985508\n",
      "0.018050541516245487\n",
      "0.017985611510791366\n",
      "0.017921146953405017\n",
      "0.017857142857142856\n",
      "0.017793594306049824\n",
      "0.01773049645390071\n",
      "0.0176678445229682\n",
      "0.017605633802816902\n",
      "0.017543859649122806\n",
      "0.017482517482517484\n",
      "0.017421602787456445\n",
      "0.017361111111111112\n",
      "0.01730103806228374\n",
      "0.017241379310344827\n",
      "0.01718213058419244\n",
      "0.017123287671232876\n",
      "0.017064846416382253\n",
      "0.017006802721088437\n",
      "0.01694915254237288\n",
      "0.016891891891891893\n",
      "0.016835016835016835\n",
      "0.016778523489932886\n",
      "0.016722408026755852\n",
      "0.016666666666666666\n",
      "0.016611295681063124\n",
      "0.016556291390728478\n",
      "0.0165016501650165\n",
      "0.01644736842105263\n",
      "0.01639344262295082\n",
      "0.016339869281045753\n",
      "0.016286644951140065\n",
      "0.016233766233766232\n",
      "0.016181229773462782\n",
      "0.016129032258064516\n",
      "0.01607717041800643\n",
      "0.016025641025641024\n",
      "0.01597444089456869\n",
      "0.01592356687898089\n",
      "0.015873015873015872\n",
      "0.015822784810126583\n",
      "0.015772870662460567\n",
      "0.015723270440251572\n",
      "0.01567398119122257\n",
      "0.015625\n",
      "0.01557632398753894\n",
      "0.015527950310559006\n",
      "0.015479876160990712\n",
      "0.015432098765432098\n",
      "0.015384615384615385\n",
      "0.015337423312883436\n",
      "0.01529051987767584\n",
      "0.01524390243902439\n",
      "0.015197568389057751\n",
      "0.015151515151515152\n",
      "0.015105740181268883\n",
      "0.015060240963855422\n",
      "0.015015015015015015\n",
      "0.014970059880239521\n",
      "0.014925373134328358\n",
      "0.01488095238095238\n",
      "0.01483679525222552\n",
      "0.014792899408284023\n",
      "0.014749262536873156\n",
      "0.014705882352941176\n",
      "0.01466275659824047\n",
      "0.014619883040935672\n",
      "0.014577259475218658\n",
      "0.014534883720930232\n",
      "0.014492753623188406\n",
      "0.014450867052023121\n",
      "0.01440922190201729\n",
      "0.014367816091954023\n",
      "0.014326647564469915\n",
      "0.014285714285714285\n",
      "0.014245014245014245\n",
      "0.014204545454545454\n",
      "0.014164305949008499\n",
      "0.014124293785310734\n",
      "0.014084507042253521\n",
      "0.014044943820224719\n",
      "0.014005602240896359\n",
      "0.013966480446927373\n",
      "0.013927576601671309\n",
      "0.013888888888888888\n",
      "0.013850415512465374\n",
      "0.013812154696132596\n",
      "0.013774104683195593\n",
      "0.013736263736263736\n",
      "0.0136986301369863\n",
      "0.01366120218579235\n",
      "0.013623978201634877\n",
      "0.01358695652173913\n",
      "0.013550135501355014\n",
      "0.013513513513513514\n",
      "0.013477088948787063\n",
      "0.013440860215053764\n",
      "0.013404825737265416\n",
      "0.013368983957219251\n",
      "0.013333333333333334\n",
      "0.013297872340425532\n",
      "0.013262599469496022\n",
      "0.013227513227513227\n",
      "0.013192612137203167\n",
      "0.013157894736842105\n",
      "0.013123359580052493\n",
      "0.013089005235602094\n",
      "0.013054830287206266\n",
      "0.013020833333333334\n",
      "0.012987012987012988\n",
      "0.012953367875647668\n",
      "0.012919896640826873\n",
      "0.01288659793814433\n",
      "0.012853470437017995\n",
      "0.01282051282051282\n",
      "0.01278772378516624\n",
      "0.012755102040816327\n",
      "0.01272264631043257\n",
      "0.012690355329949238\n",
      "0.012658227848101266\n",
      "0.012626262626262626\n",
      "0.012594458438287154\n",
      "0.01256281407035176\n",
      "0.012531328320802004\n",
      "0.0125\n",
      "0.012468827930174564\n",
      "0.012437810945273632\n",
      "0.01240694789081886\n",
      "0.012376237623762377\n",
      "0.012345679012345678\n",
      "0.012315270935960592\n",
      "0.012285012285012284\n",
      "0.012254901960784314\n",
      "0.012224938875305624\n",
      "0.012195121951219513\n",
      "0.012165450121654502\n",
      "0.012135922330097087\n",
      "0.012106537530266344\n",
      "0.012077294685990338\n",
      "0.012048192771084338\n",
      "0.01201923076923077\n",
      "0.011990407673860911\n",
      "0.011961722488038277\n",
      "0.011933174224343675\n",
      "0.011904761904761904\n",
      "0.011876484560570071\n",
      "0.011848341232227487\n",
      "0.01182033096926714\n",
      "0.01179245283018868\n",
      "0.011764705882352941\n",
      "0.011737089201877934\n",
      "0.0117096018735363\n",
      "0.011682242990654205\n",
      "0.011655011655011656\n",
      "0.011627906976744186\n",
      "0.01160092807424594\n",
      "0.011574074074074073\n",
      "0.011547344110854504\n",
      "0.01152073732718894\n",
      "0.011494252873563218\n",
      "0.011467889908256881\n",
      "0.011441647597254004\n",
      "0.01141552511415525\n",
      "0.011389521640091117\n",
      "0.011363636363636364\n",
      "0.011337868480725623\n",
      "0.011312217194570135\n",
      "0.011286681715575621\n",
      "0.01126126126126126\n",
      "0.011235955056179775\n",
      "0.011210762331838564\n",
      "0.011185682326621925\n",
      "0.011160714285714286\n",
      "0.011135857461024499\n",
      "0.011111111111111112\n",
      "0.011086474501108648\n",
      "0.011061946902654867\n",
      "0.011037527593818985\n",
      "0.011013215859030838\n",
      "0.01098901098901099\n",
      "0.010964912280701754\n",
      "0.010940919037199124\n",
      "0.010917030567685589\n",
      "0.010893246187363835\n",
      "0.010869565217391304\n",
      "0.010845986984815618\n",
      "0.010822510822510822\n",
      "0.01079913606911447\n",
      "0.010775862068965518\n",
      "0.010752688172043012\n",
      "0.01072961373390558\n",
      "0.010706638115631691\n",
      "0.010683760683760684\n",
      "0.010660980810234541\n",
      "0.010638297872340425\n",
      "0.010615711252653927\n",
      "0.01059322033898305\n",
      "0.010570824524312896\n",
      "0.010548523206751054\n",
      "0.010526315789473684\n",
      "0.01050420168067227\n",
      "0.010482180293501049\n",
      "0.010460251046025104\n",
      "0.010438413361169102\n",
      "0.010416666666666666\n",
      "0.010395010395010396\n",
      "0.01037344398340249\n",
      "0.010351966873706004\n",
      "0.010330578512396695\n",
      "0.010309278350515464\n",
      "0.0102880658436214\n",
      "0.01026694045174538\n",
      "0.010245901639344262\n",
      "0.010224948875255624\n",
      "0.01020408163265306\n",
      "0.010183299389002037\n",
      "0.01016260162601626\n",
      "0.010141987829614604\n",
      "0.010121457489878543\n",
      "0.010101010101010102\n",
      "0.010080645161290322\n",
      "0.01006036217303823\n",
      "0.010040160642570281\n",
      "0.01002004008016032\n",
      "0.01\n",
      "0.00998003992015968\n",
      "0.0099601593625498\n",
      "0.009940357852882704\n",
      "0.00992063492063492\n",
      "0.009900990099009901\n",
      "0.009881422924901186\n",
      "0.009861932938856016\n",
      "0.00984251968503937\n",
      "0.009823182711198428\n",
      "0.00980392156862745\n",
      "0.009784735812133072\n",
      "0.009765625\n",
      "0.009746588693957114\n",
      "0.009727626459143969\n",
      "0.009708737864077669\n",
      "0.009689922480620155\n",
      "0.009671179883945842\n",
      "0.009652509652509652\n",
      "0.009633911368015413\n",
      "0.009615384615384616\n",
      "0.009596928982725527\n",
      "0.009578544061302681\n",
      "0.009560229445506692\n",
      "0.009541984732824428\n",
      "0.009523809523809525\n",
      "0.009505703422053232\n",
      "0.009487666034155597\n",
      "0.00946969696969697\n",
      "0.00945179584120983\n",
      "0.009433962264150943\n",
      "0.009416195856873822\n",
      "0.009398496240601503\n",
      "0.009380863039399626\n",
      "0.009363295880149813\n",
      "0.009345794392523364\n",
      "0.009328358208955223\n",
      "0.00931098696461825\n",
      "0.00929368029739777\n",
      "0.00927643784786642\n",
      "0.009259259259259259\n",
      "0.009242144177449169\n",
      "0.00922509225092251\n",
      "0.009208103130755065\n",
      "0.009191176470588236\n",
      "0.009174311926605505\n",
      "0.009157509157509158\n",
      "0.009140767824497258\n",
      "0.009124087591240875\n",
      "0.009107468123861567\n",
      "0.00909090909090909\n",
      "0.009074410163339383\n",
      "0.009057971014492754\n",
      "0.009041591320072333\n",
      "0.009025270758122744\n",
      "0.009009009009009009\n",
      "0.008992805755395683\n",
      "0.008976660682226212\n",
      "0.008960573476702509\n",
      "0.008944543828264758\n",
      "0.008928571428571428\n",
      "0.008912655971479501\n",
      "0.008896797153024912\n",
      "0.008880994671403197\n",
      "0.008865248226950355\n",
      "0.008849557522123894\n",
      "0.0088339222614841\n",
      "0.008818342151675485\n",
      "0.008802816901408451\n",
      "0.008787346221441126\n",
      "0.008771929824561403\n",
      "0.008756567425569177\n",
      "0.008741258741258742\n",
      "0.008726003490401396\n",
      "0.008710801393728223\n",
      "0.008695652173913044\n",
      "0.008680555555555556\n",
      "0.008665511265164644\n",
      "0.00865051903114187\n",
      "0.008635578583765112\n",
      "0.008620689655172414\n",
      "0.008605851979345954\n",
      "0.00859106529209622\n",
      "0.008576329331046312\n",
      "0.008561643835616438\n",
      "0.008547008547008548\n",
      "0.008532423208191127\n",
      "0.008517887563884156\n",
      "0.008503401360544218\n",
      "0.008488964346349746\n",
      "0.00847457627118644\n",
      "0.008460236886632826\n",
      "0.008445945945945946\n",
      "0.008431703204047217\n",
      "0.008417508417508417\n",
      "0.008403361344537815\n",
      "0.008389261744966443\n",
      "0.008375209380234505\n",
      "0.008361204013377926\n",
      "0.008347245409015025\n",
      "0.008333333333333333\n",
      "0.008319467554076539\n",
      "0.008305647840531562\n",
      "0.008291873963515755\n",
      "0.008278145695364239\n",
      "0.008264462809917356\n",
      "0.00825082508250825\n",
      "0.008237232289950576\n",
      "0.008223684210526315\n",
      "0.008210180623973728\n",
      "0.00819672131147541\n",
      "0.008183306055646482\n",
      "0.008169934640522876\n",
      "0.008156606851549755\n",
      "0.008143322475570033\n",
      "0.008130081300813009\n",
      "0.008116883116883116\n",
      "0.008103727714748784\n",
      "0.008090614886731391\n",
      "0.008077544426494346\n",
      "0.008064516129032258\n",
      "0.008051529790660225\n",
      "0.008038585209003215\n",
      "0.008025682182985553\n",
      "0.008012820512820512\n",
      "0.008\n",
      "0.007987220447284345\n",
      "0.007974481658692184\n",
      "0.007961783439490446\n",
      "0.00794912559618442\n",
      "0.007936507936507936\n",
      "0.00792393026941363\n",
      "0.007911392405063292\n",
      "0.007898894154818325\n",
      "0.007886435331230283\n",
      "0.007874015748031496\n",
      "0.007861635220125786\n",
      "0.007849293563579277\n",
      "0.007836990595611285\n",
      "0.00782472613458529\n",
      "0.0078125\n",
      "0.0078003120124804995\n",
      "0.00778816199376947\n",
      "0.007776049766718507\n",
      "0.007763975155279503\n",
      "0.007751937984496124\n",
      "0.007739938080495356\n",
      "0.0077279752704791345\n",
      "0.007716049382716049\n",
      "0.007704160246533128\n",
      "0.007692307692307693\n",
      "0.007680491551459293\n",
      "0.007668711656441718\n",
      "0.007656967840735069\n",
      "0.00764525993883792\n",
      "0.007633587786259542\n",
      "0.007621951219512195\n",
      "0.0076103500761035\n",
      "0.007598784194528876\n",
      "0.007587253414264037\n",
      "0.007575757575757576\n",
      "0.007564296520423601\n",
      "0.0075528700906344415\n",
      "0.007541478129713424\n",
      "0.007530120481927711\n",
      "0.007518796992481203\n",
      "0.0075075075075075074\n",
      "0.0074962518740629685\n",
      "0.0074850299401197605\n",
      "0.007473841554559043\n",
      "0.007462686567164179\n",
      "0.007451564828614009\n",
      "0.00744047619047619\n",
      "0.007429420505200594\n",
      "0.00741839762611276\n",
      "0.007407407407407408\n",
      "0.0073964497041420114\n",
      "0.007385524372230428\n",
      "0.007374631268436578\n",
      "0.007363770250368188\n",
      "0.007352941176470588\n",
      "0.007342143906020558\n",
      "0.007331378299120235\n",
      "0.007320644216691069\n",
      "0.007309941520467836\n",
      "0.0072992700729927005\n",
      "0.007288629737609329\n",
      "0.00727802037845706\n",
      "0.007267441860465116\n",
      "0.00725689404934688\n",
      "0.007246376811594203\n",
      "0.00723589001447178\n",
      "0.0072254335260115606\n",
      "0.007215007215007215\n",
      "0.007204610951008645\n",
      "0.007194244604316547\n",
      "0.007183908045977011\n",
      "0.007173601147776184\n",
      "0.0071633237822349575\n",
      "0.00715307582260372\n",
      "0.007142857142857143\n",
      "0.007132667617689016\n",
      "0.007122507122507123\n",
      "0.007112375533428165\n",
      "0.007102272727272727\n",
      "0.0070921985815602835\n",
      "0.007082152974504249\n",
      "0.007072135785007072\n",
      "0.007062146892655367\n",
      "0.007052186177715092\n",
      "0.007042253521126761\n",
      "0.007032348804500703\n",
      "0.007022471910112359\n",
      "0.0070126227208976155\n",
      "0.0070028011204481795\n",
      "0.006993006993006993\n",
      "0.006983240223463687\n",
      "0.00697350069735007\n",
      "0.006963788300835654\n",
      "0.006954102920723227\n",
      "0.006944444444444444\n",
      "0.006934812760055479\n",
      "0.006925207756232687\n",
      "0.006915629322268326\n",
      "0.006906077348066298\n",
      "0.006896551724137931\n",
      "0.006887052341597796\n",
      "0.0068775790921595595\n",
      "0.006868131868131868\n",
      "0.006858710562414266\n",
      "0.00684931506849315\n",
      "0.006839945280437756\n",
      "0.006830601092896175\n",
      "0.0068212824010914054\n",
      "0.006811989100817439\n",
      "0.006802721088435374\n",
      "0.006793478260869565\n",
      "0.0067842605156037995\n",
      "0.006775067750677507\n",
      "0.006765899864682003\n",
      "0.006756756756756757\n",
      "0.006747638326585695\n",
      "0.006738544474393531\n",
      "0.006729475100942127\n",
      "0.006720430107526882\n",
      "0.006711409395973154\n",
      "0.006702412868632708\n",
      "0.006693440428380187\n",
      "0.0066844919786096255\n",
      "0.006675567423230975\n",
      "0.006666666666666667\n",
      "0.006657789613848202\n",
      "0.006648936170212766\n",
      "0.006640106241699867\n",
      "0.006631299734748011\n",
      "0.006622516556291391\n",
      "0.006613756613756613\n",
      "0.0066050198150594455\n",
      "0.006596306068601583\n",
      "0.006587615283267457\n",
      "0.006578947368421052\n",
      "0.006570302233902759\n",
      "0.006561679790026247\n",
      "0.00655307994757536\n",
      "0.006544502617801047\n",
      "0.006535947712418301\n",
      "0.006527415143603133\n",
      "0.00651890482398957\n",
      "0.006510416666666667\n",
      "0.006501950585175552\n",
      "0.006493506493506494\n",
      "0.00648508430609598\n",
      "0.006476683937823834\n",
      "0.00646830530401035\n",
      "0.006459948320413436\n",
      "0.0064516129032258064\n",
      "0.006443298969072165\n",
      "0.006435006435006435\n",
      "0.006426735218508998\n",
      "0.006418485237483954\n",
      "0.00641025641025641\n",
      "0.006402048655569782\n",
      "0.00639386189258312\n",
      "0.006385696040868455\n",
      "0.006377551020408163\n",
      "0.006369426751592357\n",
      "0.006361323155216285\n",
      "0.0063532401524777635\n",
      "0.006345177664974619\n",
      "0.0063371356147021544\n",
      "0.006329113924050633\n",
      "0.006321112515802781\n",
      "0.006313131313131313\n",
      "0.006305170239596469\n",
      "0.006297229219143577\n",
      "0.006289308176100629\n",
      "0.00628140703517588\n",
      "0.006273525721455458\n",
      "0.006265664160401002\n",
      "0.006257822277847309\n",
      "0.00625\n",
      "0.006242197253433208\n",
      "0.006234413965087282\n",
      "0.0062266500622665\n",
      "0.006218905472636816\n",
      "0.006211180124223602\n",
      "0.00620347394540943\n",
      "0.006195786864931847\n",
      "0.006188118811881188\n",
      "0.006180469715698393\n",
      "0.006172839506172839\n",
      "0.006165228113440197\n",
      "0.006157635467980296\n",
      "0.006150061500615006\n",
      "0.006142506142506142\n",
      "0.006134969325153374\n",
      "0.006127450980392157\n",
      "0.006119951040391677\n",
      "0.006112469437652812\n",
      "0.006105006105006105\n",
      "0.006097560975609756\n",
      "0.0060901339829476245\n",
      "0.006082725060827251\n",
      "0.006075334143377886\n",
      "0.006067961165048544\n",
      "0.006060606060606061\n",
      "0.006053268765133172\n",
      "0.006045949214026602\n",
      "0.006038647342995169\n",
      "0.006031363088057901\n",
      "0.006024096385542169\n",
      "0.006016847172081829\n",
      "0.006009615384615385\n",
      "0.006002400960384154\n",
      "0.005995203836930456\n",
      "0.005988023952095809\n",
      "0.005980861244019139\n",
      "0.005973715651135006\n",
      "0.0059665871121718375\n",
      "0.0059594755661501785\n",
      "0.005952380952380952\n",
      "0.005945303210463734\n",
      "0.0059382422802850355\n",
      "0.005931198102016607\n",
      "0.005924170616113744\n",
      "0.005917159763313609\n",
      "0.00591016548463357\n",
      "0.0059031877213695395\n",
      "0.00589622641509434\n",
      "0.005889281507656066\n",
      "0.0058823529411764705\n",
      "0.005875440658049354\n",
      "0.005868544600938967\n",
      "0.005861664712778429\n",
      "0.00585480093676815\n",
      "0.005847953216374269\n",
      "0.005841121495327103\n",
      "0.005834305717619603\n",
      "0.005827505827505828\n",
      "0.005820721769499418\n",
      "0.005813953488372093\n",
      "0.005807200929152149\n",
      "0.00580046403712297\n",
      "0.005793742757821553\n",
      "0.005787037037037037\n",
      "0.005780346820809248\n",
      "0.005773672055427252\n",
      "0.0057670126874279125\n",
      "0.00576036866359447\n",
      "0.005753739930955121\n",
      "0.005747126436781609\n",
      "0.0057405281285878304\n",
      "0.005733944954128441\n",
      "0.0057273768613974796\n",
      "0.005720823798627002\n",
      "0.005714285714285714\n",
      "0.005707762557077625\n",
      "0.005701254275940707\n",
      "0.0056947608200455585\n",
      "0.005688282138794084\n",
      "0.005681818181818182\n",
      "0.0056753688989784334\n",
      "0.005668934240362812\n",
      "0.0056625141562853904\n",
      "0.005656108597285068\n",
      "0.005649717514124294\n",
      "0.0056433408577878106\n",
      "0.005636978579481398\n",
      "0.00563063063063063\n",
      "0.00562429696287964\n",
      "0.0056179775280898875\n",
      "0.005611672278338945\n",
      "0.005605381165919282\n",
      "0.005599104143337066\n",
      "0.005592841163310962\n",
      "0.00558659217877095\n",
      "0.005580357142857143\n",
      "0.005574136008918618\n",
      "0.005567928730512249\n",
      "0.0055617352614015575\n",
      "0.005555555555555556\n",
      "0.005549389567147614\n",
      "0.005543237250554324\n",
      "0.005537098560354375\n",
      "0.0055309734513274336\n",
      "0.0055248618784530384\n",
      "0.005518763796909493\n",
      "0.005512679162072767\n",
      "0.005506607929515419\n",
      "0.005500550055005501\n",
      "0.005494505494505495\n",
      "0.005488474204171241\n",
      "0.005482456140350877\n",
      "0.00547645125958379\n",
      "0.005470459518599562\n",
      "0.00546448087431694\n",
      "0.0054585152838427945\n",
      "0.0054525627044711015\n",
      "0.0054466230936819175\n",
      "0.00544069640914037\n",
      "0.005434782608695652\n",
      "0.0054288816503800215\n",
      "0.005422993492407809\n",
      "0.005417118093174431\n",
      "0.005411255411255411\n",
      "0.005405405405405406\n",
      "0.005399568034557235\n",
      "0.005393743257820928\n",
      "0.005387931034482759\n",
      "0.005382131324004306\n",
      "0.005376344086021506\n",
      "0.0053705692803437165\n",
      "0.00536480686695279\n",
      "0.0053590568060021436\n",
      "0.0053533190578158455\n",
      "0.0053475935828877\n",
      "0.005341880341880342\n",
      "0.005336179295624333\n",
      "0.005330490405117271\n",
      "0.005324813631522897\n",
      "0.005319148936170213\n",
      "0.005313496280552604\n",
      "0.005307855626326964\n",
      "0.005302226935312832\n",
      "0.005296610169491525\n",
      "0.005291005291005291\n",
      "0.005285412262156448\n",
      "0.005279831045406547\n",
      "0.005274261603375527\n",
      "0.005268703898840885\n",
      "0.005263157894736842\n",
      "0.005257623554153523\n",
      "0.005252100840336135\n",
      "0.005246589716684155\n",
      "0.005241090146750524\n",
      "0.005235602094240838\n",
      "0.005230125523012552\n",
      "0.00522466039707419\n",
      "0.005219206680584551\n",
      "0.005213764337851929\n",
      "0.005208333333333333\n",
      "0.005202913631633715\n",
      "0.005197505197505198\n",
      "0.005192107995846314\n",
      "0.005186721991701245\n",
      "0.0051813471502590676\n",
      "0.005175983436853002\n",
      "0.005170630816959669\n",
      "0.005165289256198347\n",
      "0.005159958720330237\n",
      "0.005154639175257732\n",
      "0.005149330587023687\n",
      "0.0051440329218107\n",
      "0.0051387461459403904\n",
      "0.00513347022587269\n",
      "0.005128205128205128\n",
      "0.005122950819672131\n",
      "0.00511770726714432\n",
      "0.005112474437627812\n",
      "0.005107252298263534\n",
      "0.00510204081632653\n",
      "0.0050968399592252805\n",
      "0.0050916496945010185\n",
      "0.00508646998982706\n",
      "0.00508130081300813\n",
      "0.005076142131979695\n",
      "0.005070993914807302\n",
      "0.005065856129685917\n",
      "0.005060728744939271\n",
      "0.005055611729019211\n",
      "0.005050505050505051\n",
      "0.005045408678102927\n",
      "0.005040322580645161\n",
      "0.005035246727089627\n",
      "0.005030181086519115\n",
      "0.005025125628140704\n",
      "0.0050200803212851405\n",
      "0.0050150451354062184\n",
      "0.00501002004008016\n",
      "0.005005005005005005\n",
      "0.005\n",
      "0.004995004995004995\n",
      "0.00499001996007984\n",
      "0.004985044865403789\n",
      "0.0049800796812749\n",
      "0.004975124378109453\n",
      "0.004970178926441352\n",
      "0.004965243296921549\n",
      "0.00496031746031746\n",
      "0.004955401387512388\n",
      "0.0049504950495049506\n",
      "0.004945598417408506\n",
      "0.004940711462450593\n",
      "0.004935834155972359\n",
      "0.004930966469428008\n",
      "0.0049261083743842365\n",
      "0.004921259842519685\n",
      "0.004916420845624385\n",
      "0.004911591355599214\n",
      "0.004906771344455349\n",
      "0.004901960784313725\n",
      "0.004897159647404506\n",
      "0.004892367906066536\n",
      "0.004887585532746823\n",
      "0.0048828125\n",
      "0.004878048780487805\n",
      "0.004873294346978557\n",
      "0.004868549172346641\n",
      "0.0048638132295719845\n",
      "0.004859086491739553\n",
      "0.0048543689320388345\n",
      "0.004849660523763337\n",
      "0.0048449612403100775\n",
      "0.00484027105517909\n",
      "0.004835589941972921\n",
      "0.004830917874396135\n",
      "0.004826254826254826\n",
      "0.0048216007714561235\n",
      "0.004816955684007707\n",
      "0.004812319538017324\n",
      "0.004807692307692308\n",
      "0.004803073967339097\n",
      "0.0047984644913627635\n",
      "0.004793863854266539\n",
      "0.004789272030651341\n",
      "0.004784688995215311\n",
      "0.004780114722753346\n",
      "0.004775549188156638\n",
      "0.004770992366412214\n",
      "0.004766444232602479\n",
      "0.004761904761904762\n",
      "0.004757373929590866\n",
      "0.004752851711026616\n",
      "0.004748338081671415\n",
      "0.004743833017077799\n",
      "0.004739336492890996\n",
      "0.004734848484848485\n",
      "0.004730368968779565\n",
      "0.004725897920604915\n",
      "0.004721435316336166\n",
      "0.0047169811320754715\n",
      "0.00471253534401508\n",
      "0.004708097928436911\n",
      "0.004703668861712135\n",
      "0.004699248120300752\n",
      "0.004694835680751174\n",
      "0.004690431519699813\n",
      "0.004686035613870665\n",
      "0.0046816479400749065\n",
      "0.004677268475210477\n",
      "0.004672897196261682\n",
      "0.004668534080298786\n",
      "0.0046641791044776115\n",
      "0.004659832246039142\n",
      "0.004655493482309125\n",
      "0.004651162790697674\n",
      "0.004646840148698885\n",
      "0.004642525533890436\n",
      "0.00463821892393321\n",
      "0.004633920296570899\n",
      "0.004629629629629629\n",
      "0.004625346901017576\n",
      "0.0046210720887245845\n",
      "0.0046168051708217915\n",
      "0.004612546125461255\n",
      "0.004608294930875576\n",
      "0.004604051565377533\n",
      "0.004599816007359705\n",
      "0.004595588235294118\n",
      "0.004591368227731864\n",
      "0.0045871559633027525\n",
      "0.00458295142071494\n",
      "0.004578754578754579\n",
      "0.004574565416285453\n",
      "0.004570383912248629\n",
      "0.0045662100456621\n",
      "0.004562043795620438\n",
      "0.004557885141294439\n",
      "0.004553734061930784\n",
      "0.004549590536851683\n",
      "0.004545454545454545\n",
      "0.004541326067211626\n",
      "0.004537205081669692\n",
      "0.004533091568449683\n",
      "0.004528985507246377\n",
      "0.004524886877828055\n",
      "0.0045207956600361665\n",
      "0.004516711833785004\n",
      "0.004512635379061372\n",
      "0.004508566275924256\n",
      "0.0045045045045045045\n",
      "0.004500450045004501\n",
      "0.0044964028776978415\n",
      "0.004492362982929021\n",
      "0.004488330341113106\n",
      "0.004484304932735426\n",
      "0.004480286738351254\n",
      "0.004476275738585497\n",
      "0.004472271914132379\n",
      "0.004468275245755138\n",
      "0.004464285714285714\n",
      "0.0044603033006244425\n",
      "0.004456327985739751\n",
      "0.004452359750667854\n",
      "0.004448398576512456\n",
      "0.0044444444444444444\n",
      "0.004440497335701598\n",
      "0.0044365572315882874\n",
      "0.004432624113475178\n",
      "0.0044286979627989375\n",
      "0.004424778761061947\n",
      "0.004420866489832007\n",
      "0.00441696113074205\n",
      "0.00441306266548985\n",
      "0.004409171075837742\n",
      "0.004405286343612335\n",
      "0.0044014084507042256\n",
      "0.0043975373790677225\n",
      "0.004393673110720563\n",
      "0.004389815627743635\n",
      "0.0043859649122807015\n",
      "0.0043821209465381246\n",
      "0.0043782837127845885\n",
      "0.004374453193350831\n",
      "0.004370629370629371\n",
      "0.004366812227074236\n",
      "0.004363001745200698\n",
      "0.004359197907585004\n",
      "0.004355400696864111\n",
      "0.004351610095735422\n",
      "0.004347826086956522\n",
      "0.004344048653344918\n",
      "0.004340277777777778\n",
      "0.004336513443191674\n",
      "0.004332755632582322\n",
      "0.004329004329004329\n",
      "0.004325259515570935\n",
      "0.00432152117545376\n",
      "0.004317789291882556\n",
      "0.004314063848144953\n",
      "0.004310344827586207\n",
      "0.004306632213608958\n",
      "0.004302925989672977\n",
      "0.004299226139294927\n",
      "0.00429553264604811\n",
      "0.004291845493562232\n",
      "0.004288164665523156\n",
      "0.004284490145672665\n",
      "0.004280821917808219\n",
      "0.00427715996578272\n",
      "0.004273504273504274\n",
      "0.004269854824935952\n",
      "0.004266211604095563\n",
      "0.004262574595055414\n",
      "0.004258943781942078\n",
      "0.00425531914893617\n",
      "0.004251700680272109\n",
      "0.004248088360237893\n",
      "0.004244482173174873\n",
      "0.004240882103477523\n",
      "0.00423728813559322\n",
      "0.004233700254022015\n",
      "0.004230118443316413\n",
      "0.00422654268808115\n",
      "0.004222972972972973\n",
      "0.004219409282700422\n",
      "0.0042158516020236085\n",
      "0.004212299915754001\n",
      "0.004208754208754209\n",
      "0.004205214465937763\n",
      "0.004201680672268907\n",
      "0.0041981528127623844\n",
      "0.0041946308724832215\n",
      "0.004191114836546521\n",
      "0.0041876046901172526\n",
      "0.0041841004184100415\n",
      "0.004180602006688963\n",
      "0.004177109440267335\n",
      "0.004173622704507512\n",
      "0.004170141784820684\n",
      "0.004166666666666667\n",
      "0.004163197335553705\n",
      "0.004159733777038269\n",
      "0.004156275976724855\n",
      "0.004152823920265781\n",
      "0.004149377593360996\n",
      "0.0041459369817578775\n",
      "0.004142502071251036\n",
      "0.0041390728476821195\n",
      "0.0041356492969396195\n",
      "0.004132231404958678\n",
      "0.004128819157720892\n",
      "0.004125412541254125\n",
      "0.004122011541632316\n",
      "0.004118616144975288\n",
      "0.00411522633744856\n",
      "0.004111842105263158\n",
      "0.004108463434675432\n",
      "0.004105090311986864\n",
      "0.004101722723543888\n",
      "0.004098360655737705\n",
      "0.004095004095004095\n",
      "0.004091653027823241\n",
      "0.004088307440719542\n",
      "0.004084967320261438\n",
      "0.004081632653061225\n",
      "0.004078303425774877\n",
      "0.004074979625101874\n",
      "0.004071661237785016\n",
      "0.0040683482506102524\n",
      "0.0040650406504065045\n",
      "0.004061738424045491\n",
      "0.004058441558441558\n",
      "0.0040551500405515\n",
      "0.004051863857374392\n",
      "0.004048582995951417\n",
      "0.0040453074433656954\n",
      "0.004042037186742118\n",
      "0.004038772213247173\n",
      "0.004035512510088781\n",
      "0.004032258064516129\n",
      "0.0040290088638195\n",
      "0.004025764895330112\n",
      "0.004022526146419952\n",
      "0.0040192926045016075\n",
      "0.004016064257028112\n",
      "0.0040128410914927765\n",
      "0.00400962309542903\n",
      "0.004006410256410256\n",
      "0.0040032025620496394\n",
      "0.004\n",
      "0.003996802557953637\n",
      "0.003993610223642172\n",
      "0.0039904229848363925\n",
      "0.003987240829346092\n",
      "0.00398406374501992\n",
      "0.003980891719745223\n",
      "0.003977724741447892\n",
      "0.00397456279809221\n",
      "0.003971405877680699\n",
      "0.003968253968253968\n",
      "0.003965107057890563\n",
      "0.003961965134706815\n",
      "0.00395882818685669\n",
      "0.003955696202531646\n",
      "0.003952569169960474\n",
      "0.0039494470774091624\n",
      "0.003946329913180742\n",
      "0.003943217665615142\n",
      "0.003940110323089046\n",
      "0.003937007874015748\n",
      "0.003933910306845004\n",
      "0.003930817610062893\n",
      "0.003927729772191673\n",
      "0.003924646781789639\n",
      "0.00392156862745098\n",
      "0.003918495297805642\n",
      "0.003915426781519186\n",
      "0.003912363067292645\n",
      "0.003909304143862392\n",
      "0.00390625\n",
      "0.0039032006245121\n",
      "0.0039001560062402497\n",
      "0.003897116134060795\n",
      "0.003894080996884735\n",
      "0.0038910505836575876\n",
      "0.0038880248833592537\n",
      "0.003885003885003885\n",
      "0.0038819875776397515\n",
      "0.003878975950349108\n",
      "0.003875968992248062\n",
      "0.0038729666924864447\n",
      "0.003869969040247678\n",
      "0.0038669760247486465\n",
      "0.0038639876352395673\n",
      "0.003861003861003861\n",
      "0.0038580246913580245\n",
      "0.0038550501156515036\n",
      "0.003852080123266564\n",
      "0.003849114703618168\n",
      "0.0038461538461538464\n",
      "0.003843197540353574\n",
      "0.0038402457757296467\n",
      "0.003837298541826554\n",
      "0.003834355828220859\n",
      "0.0038314176245210726\n",
      "0.0038284839203675345\n",
      "0.0038255547054322878\n",
      "0.00382262996941896\n",
      "0.0038197097020626434\n",
      "0.003816793893129771\n",
      "0.0038138825324180014\n",
      "0.0038109756097560975\n",
      "0.003808073115003808\n",
      "0.00380517503805175\n",
      "0.0038022813688212928\n",
      "0.003799392097264438\n",
      "0.0037965072133637054\n",
      "0.0037936267071320183\n",
      "0.0037907505686125853\n",
      "0.003787878787878788\n",
      "0.003785011355034065\n",
      "0.0037821482602118004\n",
      "0.003779289493575208\n",
      "0.0037764350453172208\n",
      "0.0037735849056603774\n",
      "0.003770739064856712\n",
      "0.0037678975131876413\n",
      "0.0037650602409638554\n",
      "0.003762227238525207\n",
      "0.0037593984962406013\n",
      "0.003756574004507889\n",
      "0.0037537537537537537\n",
      "0.0037509377344336083\n",
      "0.0037481259370314842\n",
      "0.003745318352059925\n",
      "0.0037425149700598802\n",
      "0.0037397157816005983\n",
      "0.0037369207772795215\n",
      "0.0037341299477221808\n",
      "0.0037313432835820895\n",
      "0.0037285607755406414\n",
      "0.0037257824143070045\n",
      "0.0037230081906180195\n",
      "0.003720238095238095\n",
      "0.0037174721189591076\n",
      "0.003714710252600297\n",
      "0.003711952487008166\n",
      "0.00370919881305638\n",
      "0.0037064492216456633\n",
      "0.003703703703703704\n",
      "0.003700962250185048\n",
      "0.0036982248520710057\n",
      "0.003695491500369549\n",
      "0.003692762186115214\n",
      "0.0036900369003690036\n",
      "0.003687315634218289\n",
      "0.0036845983787767134\n",
      "0.003681885125184094\n",
      "0.003679175864606328\n",
      "0.003676470588235294\n",
      "0.0036737692872887582\n",
      "0.003671071953010279\n",
      "0.003668378576669112\n",
      "0.0036656891495601175\n",
      "0.003663003663003663\n",
      "0.0036603221083455345\n",
      "0.0036576444769568397\n",
      "0.003654970760233918\n",
      "0.003652300949598247\n",
      "0.0036496350364963502\n",
      "0.0036469730123997084\n",
      "0.0036443148688046646\n",
      "0.003641660597232338\n",
      "0.00363901018922853\n",
      "0.0036363636363636364\n",
      "0.003633720930232558\n",
      "0.0036310820624546117\n",
      "0.00362844702467344\n",
      "0.0036258158085569255\n",
      "0.0036231884057971015\n",
      "0.003620564808110065\n",
      "0.00361794500723589\n",
      "0.0036153289949385392\n",
      "0.0036127167630057803\n",
      "0.0036101083032490976\n",
      "0.0036075036075036075\n",
      "0.003604902667627974\n",
      "0.0036023054755043226\n",
      "0.003599712023038157\n",
      "0.0035971223021582736\n",
      "0.0035945363048166786\n",
      "0.0035919540229885057\n",
      "0.003589375448671931\n",
      "0.003586800573888092\n",
      "0.0035842293906810036\n",
      "0.0035816618911174787\n",
      "0.0035790980672870437\n",
      "0.00357653791130186\n",
      "0.0035739814152966403\n",
      "0.0035714285714285713\n",
      "0.0035688793718772305\n",
      "0.003566333808844508\n",
      "0.003563791874554526\n",
      "0.0035612535612535613\n",
      "0.0035587188612099642\n",
      "0.0035561877667140826\n",
      "0.0035536602700781805\n",
      "0.0035511363636363635\n",
      "0.0035486160397444995\n",
      "0.0035460992907801418\n",
      "0.003543586109142452\n",
      "0.0035410764872521247\n",
      "0.003538570417551309\n",
      "0.003536067892503536\n",
      "0.0035335689045936395\n",
      "0.0035310734463276836\n",
      "0.0035285815102328866\n",
      "0.003526093088857546\n",
      "0.0035236081747709656\n",
      "0.0035211267605633804\n",
      "0.003518648838845883\n",
      "0.0035161744022503515\n",
      "0.0035137034434293743\n",
      "0.0035112359550561797\n",
      "0.0035087719298245615\n",
      "0.0035063113604488078\n",
      "0.00350385423966363\n",
      "0.0035014005602240898\n",
      "0.0034989503149055285\n",
      "0.0034965034965034965\n",
      "0.0034940600978336828\n",
      "0.0034916201117318434\n",
      "0.0034891835310537334\n",
      "0.003486750348675035\n",
      "0.003484320557491289\n",
      "0.003481894150417827\n",
      "0.003479471120389701\n",
      "0.0034770514603616135\n",
      "0.0034746351633078527\n",
      "0.003472222222222222\n",
      "0.0034698126301179735\n",
      "0.0034674063800277394\n",
      "0.003465003465003465\n",
      "0.0034626038781163434\n",
      "0.0034602076124567475\n",
      "0.003457814661134163\n",
      "0.0034554250172771253\n",
      "0.003453038674033149\n",
      "0.003450655624568668\n",
      "0.0034482758620689655\n",
      "0.0034458993797381117\n",
      "0.003443526170798898\n",
      "0.0034411562284927736\n",
      "0.0034387895460797797\n",
      "0.003436426116838488\n",
      "0.003434065934065934\n",
      "0.0034317089910775567\n",
      "0.003429355281207133\n",
      "0.003427004797806717\n",
      "0.003424657534246575\n",
      "0.0034223134839151265\n",
      "0.003419972640218878\n",
      "0.003417634996582365\n",
      "0.0034153005464480873\n",
      "0.0034129692832764505\n",
      "0.0034106412005457027\n",
      "0.0034083162917518746\n",
      "0.0034059945504087193\n",
      "0.0034036759700476512\n",
      "0.003401360544217687\n",
      "0.003399048266485384\n",
      "0.0033967391304347825\n",
      "0.0033944331296673455\n",
      "0.0033921302578018998\n",
      "0.003389830508474576\n",
      "0.0033875338753387536\n",
      "0.003385240352064997\n",
      "0.0033829499323410014\n",
      "0.0033806626098715348\n",
      "0.0033783783783783786\n",
      "0.00337609723160027\n",
      "0.0033738191632928477\n",
      "0.0033715441672285905\n",
      "0.0033692722371967657\n",
      "0.003367003367003367\n",
      "0.0033647375504710633\n",
      "0.0033624747814391394\n",
      "0.003360215053763441\n",
      "0.0033579583613163196\n",
      "0.003355704697986577\n",
      "0.00335345405767941\n",
      "0.003351206434316354\n",
      "0.003348961821835231\n",
      "0.0033467202141900937\n",
      "0.0033444816053511705\n",
      "0.0033422459893048127\n",
      "0.0033400133600534404\n",
      "0.0033377837116154874\n",
      "0.00333555703802535\n",
      "0.0033333333333333335\n",
      "0.0033311125916055963\n",
      "0.003328894806924101\n",
      "0.00332667997338656\n",
      "0.003324468085106383\n",
      "0.0033222591362126247\n",
      "0.0033200531208499337\n",
      "0.0033178500331785005\n",
      "0.0033156498673740055\n",
      "0.0033134526176275677\n",
      "0.0033112582781456954\n",
      "0.0033090668431502318\n",
      "0.0033068783068783067\n",
      "0.003304692663582287\n",
      "0.0033025099075297227\n",
      "0.0033003300330033004\n",
      "0.0032981530343007917\n",
      "0.0032959789057350032\n",
      "0.0032938076416337285\n",
      "0.0032916392363396972\n",
      "0.003289473684210526\n",
      "0.003287310979618672\n",
      "0.0032851511169513796\n",
      "0.003282994090610637\n",
      "0.0032808398950131233\n",
      "0.003278688524590164\n",
      "0.00327653997378768\n",
      "0.0032743942370661427\n",
      "0.0032722513089005235\n",
      "0.0032701111837802484\n",
      "0.0032679738562091504\n",
      "0.0032658393207054214\n",
      "0.0032637075718015664\n",
      "0.0032615786040443573\n",
      "0.003259452411994785\n",
      "0.003257328990228013\n",
      "0.0032552083333333335\n",
      "0.0032530904359141183\n",
      "0.003250975292587776\n",
      "0.003248862897985705\n",
      "0.003246753246753247\n",
      "0.003244646333549643\n",
      "0.00324254215304799\n",
      "0.0032404406999351912\n",
      "0.003238341968911917\n",
      "0.003236245954692557\n",
      "0.003234152652005175\n",
      "0.003232062055591467\n",
      "0.003229974160206718\n",
      "0.0032278889606197547\n",
      "0.0032258064516129032\n",
      "0.003223726627981947\n",
      "0.0032216494845360823\n",
      "0.003219575016097875\n",
      "0.0032175032175032173\n",
      "0.003215434083601286\n",
      "0.003213367609254499\n",
      "0.0032113037893384713\n",
      "0.003209242618741977\n",
      "0.003207184092366902\n",
      "0.003205128205128205\n",
      "0.0032030749519538757\n",
      "0.003201024327784891\n",
      "0.003198976327575176\n",
      "0.00319693094629156\n",
      "0.003194888178913738\n",
      "0.0031928480204342275\n",
      "0.003190810465858328\n",
      "0.0031887755102040817\n",
      "0.0031867431485022306\n",
      "0.0031847133757961785\n",
      "0.003182686187141948\n",
      "0.0031806615776081423\n",
      "0.003178639542275906\n",
      "0.0031766200762388818\n",
      "0.0031746031746031746\n",
      "0.0031725888324873096\n",
      "0.0031705770450221942\n",
      "0.0031685678073510772\n",
      "0.0031665611146295125\n",
      "0.0031645569620253164\n",
      "0.0031625553447185324\n",
      "0.0031605562579013905\n",
      "0.003158559696778269\n",
      "0.0031565656565656565\n",
      "0.0031545741324921135\n",
      "0.0031525851197982345\n",
      "0.00315059861373661\n",
      "0.0031486146095717885\n",
      "0.0031466331025802393\n",
      "0.0031446540880503146\n",
      "0.0031426775612822125\n",
      "0.00314070351758794\n",
      "0.003138731952291274\n",
      "0.003136762860727729\n",
      "0.003134796238244514\n",
      "0.003132832080200501\n",
      "0.0031308703819661866\n",
      "0.0031289111389236545\n",
      "0.0031269543464665416\n",
      "0.003125\n",
      "0.003123048094940662\n",
      "0.003121098626716604\n",
      "0.0031191515907673115\n",
      "0.003117206982543641\n",
      "0.003115264797507788\n",
      "0.00311332503113325\n",
      "0.0031113876789047915\n",
      "0.003109452736318408\n",
      "0.003107520198881293\n",
      "0.003105590062111801\n",
      "0.0031036623215394167\n",
      "0.003101736972704715\n",
      "0.0030998140111593306\n",
      "0.0030978934324659233\n",
      "0.0030959752321981426\n",
      "0.003094059405940594\n",
      "0.0030921459492888066\n",
      "0.0030902348578491965\n",
      "0.0030883261272390363\n",
      "0.0030864197530864196\n",
      "0.0030845157310302285\n",
      "0.0030826140567200987\n",
      "0.0030807147258163892\n",
      "0.003078817733990148\n",
      "0.003076923076923077\n",
      "0.003075030750307503\n",
      "0.003073140749846343\n",
      "0.003071253071253071\n",
      "0.003069367710251688\n",
      "0.003067484662576687\n",
      "0.0030656039239730227\n",
      "0.0030637254901960784\n",
      "0.003061849357011635\n",
      "0.0030599755201958386\n",
      "0.0030581039755351682\n",
      "0.003056234718826406\n",
      "0.0030543677458766036\n",
      "0.0030525030525030525\n",
      "0.003050640634533252\n",
      "0.003048780487804878\n",
      "0.0030469226081657527\n",
      "0.0030450669914738123\n",
      "0.0030432136335970784\n",
      "0.0030413625304136255\n",
      "0.00303951367781155\n",
      "0.003037667071688943\n",
      "0.0030358227079538553\n",
      "0.003033980582524272\n",
      "0.0030321406913280777\n",
      "0.0030303030303030303\n",
      "0.0030284675953967293\n",
      "0.003026634382566586\n",
      "0.0030248033877797943\n",
      "0.003022974607013301\n",
      "0.0030211480362537764\n",
      "0.0030193236714975845\n",
      "0.0030175015087507543\n",
      "0.0030156815440289505\n",
      "0.0030138637733574444\n",
      "0.0030120481927710845\n",
      "0.0030102347983142685\n",
      "0.0030084235860409147\n",
      "0.003006614552014432\n",
      "0.0030048076923076925\n",
      "0.003003003003003003\n",
      "0.003001200480192077\n",
      "0.002999400119976005\n",
      "0.002997601918465228\n",
      "0.0029958058717795086\n",
      "0.0029940119760479044\n",
      "0.002992220227408737\n",
      "0.0029904306220095694\n",
      "0.002988643156007173\n",
      "0.002986857825567503\n",
      "0.0029850746268656717\n",
      "0.0029832935560859188\n",
      "0.0029815146094215863\n",
      "0.0029797377830750892\n",
      "0.0029779630732578916\n",
      "0.002976190476190476\n",
      "0.00297441998810232\n",
      "0.002972651605231867\n",
      "0.0029708853238265003\n",
      "0.0029691211401425177\n",
      "0.002967359050445104\n",
      "0.0029655990510083037\n",
      "0.002963841138114997\n",
      "0.002962085308056872\n",
      "0.002960331557134399\n",
      "0.0029585798816568047\n",
      "0.0029568302779420462\n",
      "0.002955082742316785\n",
      "0.0029533372711163615\n",
      "0.0029515938606847697\n",
      "0.0029498525073746312\n",
      "0.00294811320754717\n",
      "0.0029463759575721863\n",
      "0.002944640753828033\n",
      "0.002942907592701589\n",
      "0.0029411764705882353\n",
      "0.0029394473838918285\n",
      "0.002937720329024677\n",
      "0.002935995302407516\n",
      "0.0029342723004694834\n",
      "0.002932551319648094\n",
      "0.0029308323563892145\n",
      "0.0029291154071470417\n",
      "0.002927400468384075\n",
      "0.002925687536571094\n",
      "0.0029239766081871343\n",
      "0.0029222676797194622\n",
      "0.0029205607476635513\n",
      "0.002918855808523059\n",
      "0.0029171528588098016\n",
      "0.0029154518950437317\n",
      "0.002913752913752914\n",
      "0.0029120559114735\n",
      "0.002910360884749709\n",
      "0.0029086678301337987\n",
      "0.0029069767441860465\n",
      "0.002905287623474724\n",
      "0.0029036004645760743\n",
      "0.002901915264074289\n",
      "0.002900232018561485\n",
      "0.002898550724637681\n",
      "0.0028968713789107765\n",
      "0.0028951939779965257\n",
      "0.0028935185185185184\n",
      "0.002891844997108155\n",
      "0.002890173410404624\n",
      "0.0028885037550548816\n",
      "0.002886836027713626\n",
      "0.0028851702250432777\n",
      "0.0028835063437139563\n",
      "0.002881844380403458\n",
      "0.002880184331797235\n",
      "0.0028785261945883708\n",
      "0.0028768699654775605\n",
      "0.002875215641173088\n",
      "0.0028735632183908046\n",
      "0.002871912693854107\n",
      "0.0028702640642939152\n",
      "0.002868617326448652\n",
      "0.0028669724770642203\n",
      "0.0028653295128939827\n",
      "0.0028636884306987398\n",
      "0.0028620492272467086\n",
      "0.002860411899313501\n",
      "0.002858776443682104\n",
      "0.002857142857142857\n",
      "0.0028555111364934323\n",
      "0.0028538812785388126\n",
      "0.002852253280091272\n",
      "0.0028506271379703536\n",
      "0.002849002849002849\n",
      "0.0028473804100227792\n",
      "0.0028457598178713715\n",
      "0.002844141069397042\n",
      "0.0028425241614553724\n",
      "0.002840909090909091\n",
      "0.0028392958546280523\n",
      "0.0028376844494892167\n",
      "0.0028360748723766306\n",
      "0.002834467120181406\n",
      "0.0028328611898017\n",
      "0.0028312570781426952\n",
      "0.0028296547821165816\n",
      "0.002828054298642534\n",
      "0.002826455624646693\n",
      "0.002824858757062147\n",
      "0.00282326369282891\n",
      "0.0028216704288939053\n",
      "0.0028200789622109417\n",
      "0.002818489289740699\n",
      "0.0028169014084507044\n",
      "0.002815315315315315\n",
      "0.0028137310073157004\n",
      "0.00281214848143982\n",
      "0.002810567734682406\n",
      "0.0028089887640449437\n",
      "0.002807411566535654\n",
      "0.0028058361391694723\n",
      "0.0028042624789680315\n",
      "0.002802690582959641\n",
      "0.0028011204481792717\n",
      "0.002799552071668533\n",
      "0.0027979854504756574\n",
      "0.002796420581655481\n",
      "0.002794857462269424\n",
      "0.002793296089385475\n",
      "0.0027917364600781687\n",
      "0.0027901785714285715\n",
      "0.002788622420524261\n",
      "0.002787068004459309\n",
      "0.002785515320334262\n",
      "0.0027839643652561247\n",
      "0.0027824151363383415\n",
      "0.0027808676307007787\n",
      "0.0027793218454697055\n",
      "0.002777777777777778\n",
      "0.00277623542476402\n",
      "0.002774694783573807\n",
      "0.0027731558513588465\n",
      "0.002771618625277162\n",
      "0.002770083102493075\n",
      "0.0027685492801771874\n",
      "0.002767017155506364\n",
      "0.0027654867256637168\n",
      "0.002763957987838585\n",
      "0.0027624309392265192\n",
      "0.0027609055770292656\n",
      "0.0027593818984547464\n",
      "0.0027578599007170436\n",
      "0.0027563395810363835\n",
      "0.0027548209366391185\n",
      "0.0027533039647577094\n",
      "0.00275178866263071\n",
      "0.0027502750275027505\n",
      "0.002748763056624519\n",
      "0.0027472527472527475\n",
      "0.0027457440966501922\n",
      "0.0027442371020856204\n",
      "0.0027427317608337905\n",
      "0.0027412280701754384\n",
      "0.0027397260273972603\n",
      "0.002738225629791895\n",
      "0.002736726874657909\n",
      "0.002735229759299781\n",
      "0.002733734281027884\n",
      "0.00273224043715847\n",
      "0.002730748225013654\n",
      "0.0027292576419213972\n",
      "0.002727768685215494\n",
      "0.0027262813522355507\n",
      "0.0027247956403269754\n",
      "0.0027233115468409588\n",
      "0.0027218290691344584\n",
      "0.002720348204570185\n",
      "0.0027188689505165853\n",
      "0.002717391304347826\n",
      "0.0027159152634437804\n",
      "0.0027144408251900108\n",
      "0.0027129679869777536\n",
      "0.0027114967462039045\n",
      "0.0027100271002710027\n",
      "0.0027085590465872156\n",
      "0.0027070925825663237\n",
      "0.0027056277056277055\n",
      "0.0027041644131963224\n",
      "0.002702702702702703\n",
      "0.002701242571582928\n",
      "0.0026997840172786176\n",
      "0.002698327037236913\n",
      "0.002696871628910464\n",
      "0.0026954177897574125\n",
      "0.0026939655172413795\n",
      "0.0026925148088314485\n",
      "0.002691065662002153\n",
      "0.0026896180742334587\n",
      "0.002688172043010753\n",
      "0.0026867275658248252\n",
      "0.0026852846401718583\n",
      "0.0026838432635534087\n",
      "0.002682403433476395\n",
      "0.002680965147453083\n",
      "0.0026795284030010718\n",
      "0.002678093197643278\n",
      "0.0026766595289079227\n",
      "0.002675227394328518\n",
      "0.00267379679144385\n",
      "0.002672367717797969\n",
      "0.002670940170940171\n",
      "0.0026695141484249867\n",
      "0.0026680896478121665\n",
      "0.0026666666666666666\n",
      "0.0026652452025586353\n",
      "0.002663825253063399\n",
      "0.0026624068157614484\n",
      "0.0026609898882384245\n",
      "0.0026595744680851063\n",
      "0.002658160552897395\n",
      "0.002656748140276302\n",
      "0.0026553372278279343\n",
      "0.002653927813163482\n",
      "0.002652519893899204\n",
      "0.002651113467656416\n",
      "0.002649708532061473\n",
      "0.0026483050847457626\n",
      "0.0026469031233456856\n",
      "0.0026455026455026454\n",
      "0.0026441036488630354\n",
      "0.002642706131078224\n",
      "0.002641310089804543\n",
      "0.0026399155227032735\n",
      "0.002638522427440633\n",
      "0.0026371308016877636\n",
      "0.002635740643120717\n",
      "0.0026343519494204425\n",
      "0.0026329647182727752\n",
      "0.002631578947368421\n",
      "0.0026301946344029457\n",
      "0.0026288117770767614\n",
      "0.002627430373095113\n",
      "0.0026260504201680674\n",
      "0.0026246719160104987\n",
      "0.0026232948583420775\n",
      "0.0026219192448872575\n",
      "0.002620545073375262\n",
      "0.0026191723415400735\n",
      "0.002617801047120419\n",
      "0.0026164311878597592\n",
      "0.002615062761506276\n",
      "0.0026136957658128594\n",
      "0.002612330198537095\n",
      "0.0026109660574412533\n",
      "0.0026096033402922755\n",
      "0.0026082420448617634\n",
      "0.0026068821689259644\n",
      "0.0026055237102657635\n",
      "0.0026041666666666665\n",
      "0.0026028110359187923\n",
      "0.0026014568158168575\n",
      "0.0026001040041601664\n",
      "0.002598752598752599\n",
      "0.0025974025974025974\n",
      "0.002596053997923157\n",
      "0.002594706798131811\n",
      "0.0025933609958506223\n",
      "0.002592016588906169\n",
      "0.0025906735751295338\n",
      "0.002589331952356292\n",
      "0.002587991718426501\n",
      "0.002586652871184687\n",
      "0.0025853154084798345\n",
      "0.002583979328165375\n",
      "0.0025826446280991736\n",
      "0.002581311306143521\n",
      "0.0025799793601651187\n",
      "0.0025786487880350697\n",
      "0.002577319587628866\n",
      "0.002575991756826378\n",
      "0.0025746652935118436\n",
      "0.0025733401955738548\n",
      "0.00257201646090535\n",
      "0.002570694087403599\n",
      "0.0025693730729701952\n",
      "0.0025680534155110425\n",
      "0.002566735112936345\n",
      "0.002565418163160595\n",
      "0.002564102564102564\n",
      "0.0025627883136852894\n",
      "0.0025614754098360654\n",
      "0.002560163850486431\n",
      "0.00255885363357216\n",
      "0.0025575447570332483\n",
      "0.002556237218813906\n",
      "0.0025549310168625446\n",
      "0.002553626149131767\n",
      "0.002552322613578356\n",
      "0.002551020408163265\n",
      "0.0025497195308516064\n",
      "0.0025484199796126403\n",
      "0.0025471217524197657\n",
      "0.0025458248472505093\n",
      "0.002544529262086514\n",
      "0.00254323499491353\n",
      "0.002541942043721403\n",
      "0.002540650406504065\n",
      "0.0025393600812595226\n",
      "0.0025380710659898475\n",
      "0.0025367833587011668\n",
      "0.002535496957403651\n",
      "0.002534211860111505\n",
      "0.0025329280648429585\n",
      "0.002531645569620253\n",
      "0.0025303643724696357\n",
      "0.0025290844714213456\n",
      "0.0025278058645096056\n",
      "0.0025265285497726125\n",
      "0.0025252525252525255\n",
      "0.002523977788995457\n",
      "0.0025227043390514633\n",
      "0.0025214321734745334\n",
      "0.0025201612903225806\n",
      "0.0025188916876574307\n",
      "0.0025176233635448137\n",
      "0.0025163563160543532\n",
      "0.0025150905432595573\n",
      "0.002513826043237808\n",
      "0.002512562814070352\n",
      "0.0025113008538422904\n",
      "0.0025100401606425703\n",
      "0.002508780732563974\n",
      "0.0025075225677031092\n",
      "0.002506265664160401\n",
      "0.00250501002004008\n",
      "0.0025037556334501754\n",
      "0.0025025025025025025\n",
      "0.0025012506253126563\n",
      "0.0025\n",
      "0.0024987506246876563\n",
      "0.0024975024975024975\n",
      "0.0024962556165751375\n",
      "0.00249500998003992\n",
      "0.0024937655860349127\n",
      "0.0024925224327018943\n",
      "0.002491280518186348\n",
      "0.00249003984063745\n",
      "0.0024888003982080635\n",
      "0.0024875621890547263\n",
      "0.002486325211337643\n",
      "0.002485089463220676\n",
      "0.0024838549428713363\n",
      "0.0024826216484607746\n",
      "0.0024813895781637717\n",
      "0.00248015873015873\n",
      "0.002478929102627665\n",
      "0.002477700693756194\n",
      "0.0024764735017335313\n",
      "0.0024752475247524753\n",
      "0.002474022761009401\n",
      "0.002472799208704253\n",
      "0.002471576866040534\n",
      "0.0024703557312252965\n",
      "0.0024691358024691358\n",
      "0.0024679170779861796\n",
      "0.00246669955599408\n",
      "0.002465483234714004\n",
      "0.0024642681123706258\n",
      "0.0024630541871921183\n",
      "0.002461841457410143\n",
      "0.0024606299212598425\n",
      "0.002459419576979833\n",
      "0.0024582104228121925\n",
      "0.002457002457002457\n",
      "0.002455795677799607\n",
      "0.002454590083456063\n",
      "0.0024533856722276743\n",
      "0.0024521824423737125\n",
      "0.0024509803921568627\n",
      "0.002449779519843214\n",
      "0.002448579823702253\n",
      "0.0024473813020068525\n",
      "0.002446183953033268\n",
      "0.0024449877750611247\n",
      "0.0024437927663734115\n",
      "0.002442598925256473\n",
      "0.00244140625\n",
      "0.002440214738897023\n",
      "0.0024390243902439024\n",
      "0.0024378352023403218\n",
      "0.0024366471734892786\n",
      "0.0024354603019970775\n",
      "0.0024342745861733205\n",
      "0.0024330900243309003\n",
      "0.0024319066147859923\n",
      "0.0024307243558580457\n",
      "0.0024295432458697765\n",
      "0.0024283632831471587\n",
      "0.0024271844660194173\n",
      "0.0024260067928190197\n",
      "0.0024248302618816685\n",
      "0.0024236548715462916\n",
      "0.0024224806201550387\n",
      "0.002421307506053269\n",
      "0.002420135527589545\n",
      "0.0024189646831156266\n",
      "0.0024177949709864605\n",
      "0.002416626389560174\n",
      "0.0024154589371980675\n",
      "0.0024142926122646064\n",
      "0.002413127413127413\n",
      "0.00241196333815726\n",
      "0.0024108003857280617\n",
      "0.0024096385542168677\n",
      "0.0024084778420038534\n",
      "0.002407318247472316\n",
      "0.002406159769008662\n",
      "0.002405002405002405\n",
      "0.002403846153846154\n",
      "0.002402691013935608\n",
      "0.0024015369836695487\n",
      "0.002400384061449832\n",
      "0.0023992322456813818\n",
      "0.002398081534772182\n",
      "0.0023969319271332696\n",
      "0.0023957834211787254\n",
      "0.0023946360153256703\n",
      "0.0023934897079942556\n",
      "0.0023923444976076554\n",
      "0.0023912003825920613\n",
      "0.002390057361376673\n",
      "0.0023889154323936935\n",
      "0.002387774594078319\n",
      "0.002386634844868735\n",
      "0.002385496183206107\n",
      "0.002384358607534573\n",
      "0.0023832221163012394\n",
      "0.0023820867079561697\n",
      "0.002380952380952381\n",
      "0.002379819133745835\n",
      "0.002378686964795433\n",
      "0.0023775558725630053\n",
      "0.002376425855513308\n",
      "0.0023752969121140144\n",
      "0.0023741690408357074\n",
      "0.0023730422401518746\n",
      "0.0023719165085388993\n",
      "0.002370791844476055\n",
      "0.002369668246445498\n",
      "0.0023685457129322598\n",
      "0.0023674242424242425\n",
      "0.00236630383341221\n",
      "0.0023651844843897824\n",
      "0.002364066193853428\n",
      "0.0023629489603024575\n",
      "0.0023618327822390174\n",
      "0.002360717658168083\n",
      "0.0023596035865974517\n",
      "0.0023584905660377358\n",
      "0.0023573785950023575\n",
      "0.00235626767200754\n",
      "0.0023551577955723034\n",
      "0.0023540489642184556\n",
      "0.002352941176470588\n",
      "0.0023518344308560675\n",
      "0.0023507287259050304\n",
      "0.002349624060150376\n",
      "0.0023485204321277596\n",
      "0.002347417840375587\n",
      "0.002346316283435007\n",
      "0.0023452157598499064\n",
      "0.0023441162681669013\n",
      "0.0023430178069353325\n",
      "0.00234192037470726\n",
      "0.0023408239700374533\n",
      "0.002339728591483388\n",
      "0.0023386342376052385\n",
      "0.0023375409069658717\n",
      "0.002336448598130841\n",
      "0.002335357309668379\n",
      "0.002334267040149393\n",
      "0.0023331777881474567\n",
      "0.0023320895522388058\n",
      "0.002331002331002331\n",
      "0.002329916123019571\n",
      "0.002328830926874709\n",
      "0.0023277467411545625\n",
      "0.002326663564448581\n",
      "0.002325581395348837\n",
      "0.0023245002324500234\n",
      "0.0023234200743494425\n",
      "0.0023223409196470044\n",
      "0.002321262766945218\n",
      "0.002320185614849188\n",
      "0.002319109461966605\n",
      "0.0023180343069077423\n",
      "0.0023169601482854493\n",
      "0.002315886984715146\n",
      "0.0023148148148148147\n",
      "0.0023137436372049976\n",
      "0.002312673450508788\n",
      "0.002311604253351826\n",
      "0.0023105360443622922\n",
      "0.0023094688221709007\n",
      "0.0023084025854108957\n",
      "0.0023073373327180432\n",
      "0.0023062730627306273\n",
      "0.002305209774089442\n",
      "0.002304147465437788\n",
      "0.0023030861354214646\n",
      "0.0023020257826887663\n",
      "0.002300966405890474\n",
      "0.0022999080036798527\n",
      "0.0022988505747126436\n",
      "0.002297794117647059\n",
      "0.0022967386311437757\n",
      "0.002295684113865932\n",
      "0.002294630564479119\n",
      "0.0022935779816513763\n",
      "0.0022925263640531865\n",
      "0.00229147571035747\n",
      "0.0022904260192395786\n",
      "0.0022893772893772895\n",
      "0.002288329519450801\n",
      "0.0022872827081427266\n",
      "0.002286236854138089\n",
      "0.0022851919561243145\n",
      "0.0022841480127912287\n",
      "0.00228310502283105\n",
      "0.0022820629849383844\n",
      "0.002281021897810219\n",
      "0.002279981760145919\n",
      "0.0022789425706472195\n",
      "0.002277904328018223\n",
      "0.002276867030965392\n",
      "0.002275830678197542\n",
      "0.0022747952684258415\n",
      "0.002273760800363802\n",
      "0.0022727272727272726\n",
      "0.002271694684234439\n",
      "0.002270663033605813\n",
      "0.0022696323195642307\n",
      "0.002268602540834846\n",
      "0.0022675736961451248\n",
      "0.0022665457842248413\n",
      "0.0022655188038060714\n",
      "0.0022644927536231885\n",
      "0.0022634676324128564\n",
      "0.0022624434389140274\n",
      "0.002261420171867933\n",
      "0.0022603978300180833\n",
      "0.0022593764121102574\n",
      "0.002258355916892502\n",
      "0.002257336343115124\n",
      "0.002256317689530686\n",
      "0.0022552999548940008\n",
      "0.002254283137962128\n",
      "0.002253267237494367\n",
      "0.0022522522522522522\n",
      "0.0022512381809995496\n",
      "0.0022502250225022503\n",
      "0.002249212775528565\n",
      "0.0022482014388489208\n",
      "0.0022471910112359553\n",
      "0.0022461814914645105\n",
      "0.00224517287831163\n",
      "0.002244165170556553\n",
      "0.0022431583669807087\n",
      "0.002242152466367713\n",
      "0.0022411474675033617\n",
      "0.002240143369175627\n",
      "0.0022391401701746527\n",
      "0.0022381378692927483\n",
      "0.0022371364653243847\n",
      "0.0022361359570661895\n",
      "0.002235136343316942\n",
      "0.002234137622877569\n",
      "0.0022331397945511387\n",
      "0.002232142857142857\n",
      "0.0022311468094600626\n",
      "0.0022301516503122213\n",
      "0.002229157378510923\n",
      "0.0022281639928698753\n",
      "0.0022271714922048997\n",
      "0.002226179875333927\n",
      "0.0022251891410769915\n",
      "0.002224199288256228\n",
      "0.0022232103156958646\n",
      "0.0022222222222222222\n",
      "0.002221235006663705\n",
      "0.002220248667850799\n",
      "0.0022192632046160675\n",
      "0.0022182786157941437\n",
      "0.0022172949002217295\n",
      "0.002216312056737589\n",
      "0.002215330084182543\n",
      "0.0022143489813994687\n",
      "0.002213368747233289\n",
      "0.0022123893805309734\n",
      "0.0022114108801415304\n",
      "0.0022104332449160036\n",
      "0.002209456473707468\n",
      "0.002208480565371025\n",
      "0.002207505518763797\n",
      "0.002206531332744925\n",
      "0.0022055580061755625\n",
      "0.002204585537918871\n",
      "0.0022036139268400176\n",
      "0.0022026431718061676\n",
      "0.002201673271686482\n",
      "0.0022007042253521128\n",
      "0.002199736031676199\n",
      "0.0021987686895338612\n",
      "0.002197802197802198\n",
      "0.0021968365553602814\n",
      "0.0021958717610891525\n",
      "0.0021949078138718174\n",
      "0.002193944712593243\n",
      "0.0021929824561403508\n",
      "0.0021920210434020165\n",
      "0.0021910604732690623\n",
      "0.002190100744634253\n",
      "0.0021891418563922942\n",
      "0.002188183807439825\n",
      "0.0021872265966754157\n",
      "0.0021862702229995625\n",
      "0.0021853146853146855\n",
      "0.00218435998252512\n",
      "0.002183406113537118\n",
      "0.002182453077258839\n",
      "0.002181500872600349\n",
      "0.002180549498473615\n",
      "0.002179598953792502\n",
      "0.002178649237472767\n",
      "0.0021777003484320556\n",
      "0.0021767522855899\n",
      "0.002175805047867711\n",
      "0.002174858634188778\n",
      "0.002173913043478261\n",
      "0.0021729682746631897\n",
      "0.002172024326672459\n",
      "0.0021710811984368217\n",
      "0.002170138888888889\n",
      "0.0021691973969631237\n",
      "0.002168256721595837\n",
      "0.002167316861725184\n",
      "0.002166377816291161\n",
      "0.0021654395842356\n",
      "0.0021645021645021645\n",
      "0.0021635655560363477\n",
      "0.0021626297577854673\n",
      "0.00216169476869866\n",
      "0.00216076058772688\n",
      "0.0021598272138228943\n",
      "0.002158894645941278\n",
      "0.0021579628830384117\n",
      "0.0021570319240724763\n",
      "0.0021561017680034496\n",
      "0.0021551724137931034\n",
      "0.002154243860404998\n",
      "0.002153316106804479\n",
      "0.002152389151958674\n",
      "0.0021514629948364886\n",
      "0.002150537634408602\n",
      "0.0021496130696474634\n",
      "0.0021486892995272885\n",
      "0.002147766323024055\n",
      "0.0021468441391155\n",
      "0.002145922746781116\n",
      "0.002145002145002145\n",
      "0.002144082332761578\n",
      "0.0021431633090441492\n",
      "0.0021422450728363325\n",
      "0.0021413276231263384\n",
      "0.0021404109589041095\n",
      "0.002139495079161318\n",
      "0.00213857998289136\n",
      "0.0021376656690893546\n",
      "0.002136752136752137\n",
      "0.0021358393848782574\n",
      "0.002134927412467976\n",
      "0.002134016218523261\n",
      "0.0021331058020477816\n",
      "0.0021321961620469083\n",
      "0.002131287297527707\n",
      "0.0021303792074989347\n",
      "0.002129471890971039\n",
      "0.0021285653469561515\n",
      "0.002127659574468085\n",
      "0.002126754572522331\n",
      "0.0021258503401360546\n",
      "0.0021249468763280916\n",
      "0.0021240441801189465\n",
      "0.0021231422505307855\n",
      "0.0021222410865874364\n",
      "0.0021213406873143827\n",
      "0.0021204410517387615\n",
      "0.00211954217888936\n",
      "0.00211864406779661\n",
      "0.0021177467174925877\n",
      "0.0021168501270110076\n",
      "0.0021159542953872196\n",
      "0.0021150592216582064\n",
      "0.0021141649048625794\n",
      "0.002113271344040575\n",
      "0.0021123785382340513\n",
      "0.0021114864864864866\n",
      "0.002110595187842972\n",
      "0.002109704641350211\n",
      "0.002108814846056516\n",
      "0.0021079258010118043\n",
      "0.002107037505267594\n",
      "0.0021061499578770007\n",
      "0.002105263157894737\n",
      "0.0021043771043771043\n",
      "0.002103491796381994\n",
      "0.0021026072329688814\n",
      "0.002101723413198823\n",
      "0.0021008403361344537\n",
      "0.0020999580008399833\n",
      "0.0020990764063811922\n",
      "0.00209819555182543\n",
      "0.0020973154362416107\n",
      "0.0020964360587002098\n",
      "0.0020955574182732607\n",
      "0.0020946795140343527\n",
      "0.0020938023450586263\n",
      "0.002092925910422771\n",
      "0.0020920502092050207\n",
      "0.002091175240485153\n",
      "0.0020903010033444815\n",
      "0.002089427496865859\n",
      "0.0020885547201336674\n",
      "0.0020876826722338203\n",
      "0.002086811352253756\n",
      "0.0020859407592824365\n",
      "0.002085070892410342\n",
      "0.0020842017507294707\n",
      "0.0020833333333333333\n",
      "0.0020824656393169513\n",
      "0.0020815986677768525\n",
      "0.0020807324178110697\n",
      "0.0020798668885191347\n",
      "0.002079002079002079\n",
      "0.0020781379883624274\n",
      "0.002077274615704196\n",
      "0.0020764119601328905\n",
      "0.0020755500207555004\n",
      "0.002074688796680498\n",
      "0.002073828287017835\n",
      "0.0020729684908789387\n",
      "0.0020721094073767096\n",
      "0.002071251035625518\n",
      "0.002070393374741201\n",
      "0.0020695364238410598\n",
      "0.002068680182043856\n",
      "0.0020678246484698098\n",
      "0.002066969822240595\n",
      "0.002066115702479339\n",
      "0.0020652622883106154\n",
      "0.002064409578860446\n",
      "0.0020635575732562937\n",
      "0.0020627062706270625\n",
      "0.002061855670103093\n",
      "0.002061005770816158\n",
      "0.0020601565718994645\n",
      "0.002059308072487644\n",
      "0.0020584602717167557\n",
      "0.00205761316872428\n",
      "0.0020567667626491155\n",
      "0.002055921052631579\n",
      "0.002055076037813399\n",
      "0.002054231717337716\n",
      "0.002053388090349076\n",
      "0.002052545155993432\n",
      "0.002051702913418137\n",
      "0.002050861361771944\n",
      "0.002050020500205002\n",
      "0.0020491803278688526\n",
      "0.0020483408439164277\n",
      "0.0020475020475020475\n",
      "0.002046663937781416\n",
      "0.0020458265139116204\n",
      "0.002044989775051125\n",
      "0.002044153720359771\n",
      "0.002043318348998774\n",
      "0.002042483660130719\n",
      "0.002041649652919559\n",
      "0.0020408163265306124\n",
      "0.002039983680130559\n",
      "0.0020391517128874386\n",
      "0.0020383204239706482\n",
      "0.002037489812550937\n",
      "0.002036659877800407\n",
      "0.002035830618892508\n",
      "0.002035002035002035\n",
      "0.0020341741253051262\n",
      "0.0020333468889792597\n",
      "0.0020325203252032522\n",
      "0.0020316944331572532\n",
      "0.0020308692120227455\n",
      "0.0020300446609825416\n",
      "0.002029220779220779\n",
      "0.002028397565922921\n",
      "0.00202757502027575\n",
      "0.002026753141467369\n",
      "0.002025931928687196\n",
      "0.002025111381125962\n",
      "0.0020242914979757085\n",
      "0.0020234722784297854\n",
      "0.0020226537216828477\n",
      "0.0020218358269308533\n",
      "0.002021018593371059\n",
      "0.00202020202020202\n",
      "0.0020193861066235864\n",
      "0.0020185708518368995\n",
      "0.0020177562550443904\n",
      "0.002016942315449778\n",
      "0.0020161290322580645\n",
      "0.002015316404675534\n",
      "0.00201450443190975\n",
      "0.002013693113169553\n",
      "0.002012882447665056\n",
      "0.002012072434607646\n",
      "0.002011263073209976\n",
      "0.002010454362685967\n",
      "0.0020096463022508037\n",
      "0.002008838891120932\n",
      "0.002008032128514056\n",
      "0.002007226013649137\n",
      "0.0020064205457463883\n",
      "0.0020056157240272766\n",
      "0.002004811547714515\n",
      "0.002004008016032064\n",
      "0.002003205128205128\n",
      "0.002002402883460152\n",
      "0.0020016012810248197\n",
      "0.0020008003201280513\n",
      "0.002\n",
      "0.001999200319872051\n",
      "0.0019984012789768186\n",
      "0.001997602876548142\n",
      "0.001996805111821086\n",
      "0.001996007984031936\n",
      "0.0019952114924181963\n",
      "0.001994415636218588\n",
      "0.001993620414673046\n",
      "0.0019928258270227183\n",
      "0.00199203187250996\n",
      "0.001991238550378335\n",
      "0.0019904458598726115\n",
      "0.0019896538002387586\n",
      "0.001988862370723946\n",
      "0.0019880715705765406\n",
      "0.001987281399046105\n",
      "0.001986491855383393\n",
      "0.0019857029388403494\n",
      "0.001984914648670107\n",
      "0.001984126984126984\n",
      "0.0019833399444664813\n",
      "0.0019825535289452814\n",
      "0.0019817677368212444\n",
      "0.0019809825673534074\n",
      "0.0019801980198019802\n",
      "0.001979414093428345\n",
      "0.0019786307874950534\n",
      "0.001977848101265823\n",
      "0.0019770660340055358\n",
      "0.001976284584980237\n",
      "0.0019755037534571317\n",
      "0.0019747235387045812\n",
      "0.0019739439399921043\n",
      "0.001973164956590371\n",
      "0.0019723865877712033\n",
      "0.001971608832807571\n",
      "0.001970831690973591\n",
      "0.001970055161544523\n",
      "0.0019692792437967705\n",
      "0.001968503937007874\n",
      "0.0019677292404565133\n",
      "0.001966955153422502\n",
      "0.001966181675186787\n",
      "0.0019654088050314465\n",
      "0.0019646365422396855\n",
      "0.0019638648860958365\n",
      "0.0019630938358853552\n",
      "0.0019623233908948193\n",
      "0.001961553550411926\n",
      "0.00196078431372549\n",
      "0.001960015680125441\n",
      "0.001959247648902821\n",
      "0.0019584802193497847\n",
      "0.001957713390759593\n",
      "0.0019569471624266144\n",
      "0.0019561815336463224\n",
      "0.0019554165037152915\n",
      "0.001954652071931196\n",
      "0.0019538882375928096\n",
      "0.001953125\n",
      "0.001952362358453729\n",
      "0.00195160031225605\n",
      "0.0019508388607101053\n",
      "0.0019500780031201249\n",
      "0.001949317738791423\n",
      "0.0019485580670303975\n",
      "0.0019477989871445266\n",
      "0.0019470404984423676\n",
      "0.001946282600233554\n",
      "0.0019455252918287938\n",
      "0.0019447685725398677\n",
      "0.0019440124416796269\n",
      "0.00194325689856199\n",
      "0.0019425019425019425\n",
      "0.001941747572815534\n",
      "0.0019409937888198758\n",
      "0.0019402405898331393\n",
      "0.001939487975174554\n",
      "0.0019387359441644049\n",
      "0.001937984496124031\n",
      "0.0019372336303758234\n",
      "0.0019364833462432224\n",
      "0.0019357336430507162\n",
      "0.001934984520123839\n",
      "0.0019342359767891683\n",
      "0.0019334880123743233\n",
      "0.001932740626207963\n",
      "0.0019319938176197836\n",
      "0.0019312475859405175\n",
      "0.0019305019305019305\n",
      "0.0019297568506368198\n",
      "0.0019290123456790122\n",
      "0.0019282684149633628\n",
      "0.0019275250578257518\n",
      "0.0019267822736030828\n",
      "0.001926040061633282\n",
      "0.0019252984212552945\n",
      "0.001924557351809084\n",
      "0.001923816852635629\n",
      "0.0019230769230769232\n",
      "0.0019223375624759708\n",
      "0.001921598770176787\n",
      "0.001920860545524395\n",
      "0.0019201228878648233\n",
      "0.0019193857965451055\n",
      "0.001918649270913277\n",
      "0.0019179133103183737\n",
      "0.0019171779141104294\n",
      "0.0019164430816404753\n",
      "0.0019157088122605363\n",
      "0.0019149751053236309\n",
      "0.0019142419601837673\n",
      "0.0019135093761959434\n",
      "0.0019127773527161439\n",
      "0.0019120458891013384\n",
      "0.00191131498470948\n",
      "0.0019105846388995033\n",
      "0.0019098548510313217\n",
      "0.0019091256204658267\n",
      "0.0019083969465648854\n",
      "0.0019076688286913392\n",
      "0.0019069412662090007\n",
      "0.0019062142584826535\n",
      "0.0019054878048780487\n",
      "0.0019047619047619048\n",
      "0.001904036557501904\n",
      "0.001903311762466692\n",
      "0.001902587519025875\n",
      "0.001901863826550019\n",
      "0.0019011406844106464\n",
      "0.0019004180919802356\n",
      "0.001899696048632219\n",
      "0.0018989745537409798\n",
      "0.0018982536066818527\n",
      "0.0018975332068311196\n",
      "0.0018968133535660092\n",
      "0.0018960940462646946\n",
      "0.0018953752843062926\n",
      "0.0018946570670708603\n",
      "0.001893939393939394\n",
      "0.001893222264293828\n",
      "0.0018925056775170325\n",
      "0.0018917896329928112\n",
      "0.0018910741301059002\n",
      "0.001890359168241966\n",
      "0.001889644746787604\n",
      "0.0018889308651303363\n",
      "0.0018882175226586104\n",
      "0.001887504718761797\n",
      "0.0018867924528301887\n",
      "0.001886080724254998\n",
      "0.001885369532428356\n",
      "0.0018846588767433095\n",
      "0.0018839487565938207\n",
      "0.0018832391713747645\n",
      "0.0018825301204819277\n",
      "0.001881821603312006\n",
      "0.0018811136192626034\n",
      "0.00188040616773223\n",
      "0.0018796992481203006\n",
      "0.0018789928598271326\n",
      "0.0018782870022539444\n",
      "0.001877581674802854\n",
      "0.0018768768768768769\n",
      "0.001876172607879925\n",
      "0.0018754688672168042\n",
      "0.0018747656542932134\n",
      "0.0018740629685157421\n",
      "0.0018733608092918695\n",
      "0.0018726591760299626\n",
      "0.0018719580681392737\n",
      "0.0018712574850299401\n",
      "0.0018705574261129816\n",
      "0.0018698578908002991\n",
      "0.001869158878504673\n",
      "0.0018684603886397607\n",
      "0.0018677624206200972\n",
      "0.0018670649738610904\n",
      "0.001866368047779022\n",
      "0.0018656716417910447\n",
      "0.001864975755315181\n",
      "0.0018642803877703207\n",
      "0.0018635855385762206\n",
      "0.0018628912071535022\n",
      "0.00186219739292365\n",
      "0.0018615040953090098\n",
      "0.0018608113137327876\n",
      "0.0018601190476190475\n",
      "0.001859427296392711\n",
      "0.0018587360594795538\n",
      "0.0018580453363062058\n",
      "0.0018573551263001485\n",
      "0.001856665428889714\n",
      "0.001855976243504083\n",
      "0.0018552875695732839\n",
      "0.00185459940652819\n",
      "0.0018539117538005192\n",
      "0.0018532246108228317\n",
      "0.001852537977028529\n",
      "0.001851851851851852\n",
      "0.0018511662347278786\n",
      "0.001850481125092524\n",
      "0.001849796522382538\n",
      "0.0018491124260355029\n",
      "0.0018484288354898336\n",
      "0.0018477457501847746\n",
      "0.001847063169560399\n",
      "0.001846381093057607\n",
      "0.0018456995201181247\n",
      "0.0018450184501845018\n",
      "0.0018443378827001106\n",
      "0.0018436578171091445\n",
      "0.0018429782528566164\n",
      "0.0018422991893883567\n",
      "0.001841620626151013\n",
      "0.001840942562592047\n",
      "0.001840264998159735\n",
      "0.001839587932303164\n",
      "0.0018389113644722325\n",
      "0.001838235294117647\n",
      "0.0018375597206909224\n",
      "0.0018368846436443791\n",
      "0.001836210062431142\n",
      "0.0018355359765051395\n",
      "0.001834862385321101\n",
      "0.001834189288334556\n",
      "0.0018335166850018336\n",
      "0.0018328445747800588\n",
      "0.001832172957127153\n",
      "0.0018315018315018315\n",
      "0.001830831197363603\n",
      "0.0018301610541727673\n",
      "0.0018294914013904135\n",
      "0.0018288222384784199\n",
      "0.0018281535648994515\n",
      "0.001827485380116959\n",
      "0.001826817683595177\n",
      "0.0018261504747991235\n",
      "0.0018254837531945967\n",
      "0.0018248175182481751\n",
      "0.0018241517694272164\n",
      "0.0018234865061998542\n",
      "0.0018228217280349982\n",
      "0.0018221574344023323\n",
      "0.0018214936247723133\n",
      "0.001820830298616169\n",
      "0.0018201674554058974\n",
      "0.001819505094614265\n",
      "0.0018188432157148053\n",
      "0.0018181818181818182\n",
      "0.0018175209014903672\n",
      "0.001816860465116279\n",
      "0.0018162005085361425\n",
      "0.0018155410312273058\n",
      "0.0018148820326678765\n",
      "0.00181422351233672\n",
      "0.0018135654697134566\n",
      "0.0018129079042784628\n",
      "0.001812250815512867\n",
      "0.0018115942028985507\n",
      "0.0018109380659181455\n",
      "0.0018102824040550326\n",
      "0.0018096272167933405\n",
      "0.001808972503617945\n",
      "0.0018083182640144665\n",
      "0.0018076644974692696\n",
      "0.0018070112034694614\n",
      "0.0018063583815028901\n",
      "0.0018057060310581437\n",
      "0.0018050541516245488\n",
      "0.001804402742692169\n",
      "0.0018037518037518038\n",
      "0.0018031013342949874\n",
      "0.001802451333813987\n",
      "0.0018018018018018018\n",
      "0.0018011527377521613\n",
      "0.0018005041411595247\n",
      "0.0017998560115190785\n",
      "0.0017992083483267362\n",
      "0.0017985611510791368\n",
      "0.0017979144192736426\n",
      "0.0017972681524083393\n",
      "0.0017966223499820337\n",
      "0.0017959770114942528\n",
      "0.0017953321364452424\n",
      "0.0017946877243359654\n",
      "0.001794043774668102\n",
      "0.001793400286944046\n",
      "0.0017927572606669057\n",
      "0.0017921146953405018\n",
      "0.0017914725904693658\n",
      "0.0017908309455587394\n",
      "0.0017901897601145722\n",
      "0.0017895490336435219\n",
      "0.0017889087656529517\n",
      "0.00178826895565093\n",
      "0.001787629603146228\n",
      "0.0017869907076483202\n",
      "0.0017863522686673813\n",
      "0.0017857142857142857\n",
      "0.001785076758300607\n",
      "0.0017844396859386152\n",
      "0.0017838030681412772\n",
      "0.001783166904422254\n",
      "0.0017825311942959\n",
      "0.001781895937277263\n",
      "0.0017812611328820805\n",
      "0.0017806267806267807\n",
      "0.00177999288002848\n",
      "0.0017793594306049821\n",
      "0.0017787264318747777\n",
      "0.0017780938833570413\n",
      "0.0017774617845716318\n",
      "0.0017768301350390902\n",
      "0.0017761989342806395\n",
      "0.0017755681818181818\n",
      "0.001774937877174299\n",
      "0.0017743080198722497\n",
      "0.0017736786094359701\n",
      "0.0017730496453900709\n",
      "0.001772421127259837\n",
      "0.001771793054571226\n",
      "0.001771165426850868\n",
      "0.0017705382436260624\n",
      "0.0017699115044247787\n",
      "0.0017692852087756545\n",
      "0.0017686593562079944\n",
      "0.001768033946251768\n",
      "0.0017674089784376105\n",
      "0.0017667844522968198\n",
      "0.0017661603673613563\n",
      "0.0017655367231638418\n",
      "0.0017649135192375574\n",
      "0.0017642907551164433\n",
      "0.001763668430335097\n",
      "0.001763046544428773\n",
      "0.0017624250969333803\n",
      "0.0017618040873854828\n",
      "0.0017611835153222965\n",
      "0.0017605633802816902\n",
      "0.0017599436818021823\n",
      "0.0017593244194229415\n",
      "0.0017587055926837848\n",
      "0.0017580872011251757\n",
      "0.0017574692442882249\n",
      "0.0017568517217146872\n",
      "0.0017562346329469617\n",
      "0.0017556179775280898\n",
      "0.001755001755001755\n",
      "0.0017543859649122807\n",
      "0.00175377060680463\n",
      "0.0017531556802244039\n",
      "0.0017525411847178409\n",
      "0.001751927119831815\n",
      "0.0017513134851138354\n",
      "0.0017507002801120449\n",
      "0.0017500875043752187\n",
      "0.0017494751574527643\n",
      "0.0017488632388947185\n",
      "0.0017482517482517483\n",
      "0.0017476406850751485\n",
      "0.0017470300489168414\n",
      "0.0017464198393293748\n",
      "0.0017458100558659217\n",
      "0.0017452006980802793\n",
      "0.0017445917655268667\n",
      "0.0017439832577607255\n",
      "0.0017433751743375174\n",
      "0.001742767514813524\n",
      "0.0017421602787456446\n",
      "0.0017415534656913968\n",
      "0.0017409470752089136\n",
      "0.001740341106856944\n",
      "0.0017397355601948504\n",
      "0.0017391304347826088\n",
      "0.0017385257301808068\n",
      "0.001737921445950643\n",
      "0.0017373175816539264\n",
      "0.0017367141368530739\n",
      "0.001736111111111111\n",
      "0.0017355085039916696\n",
      "0.0017349063150589867\n",
      "0.001734304543877905\n",
      "0.0017337031900138697\n",
      "0.0017331022530329288\n",
      "0.0017325017325017325\n",
      "0.0017319016279875303\n",
      "0.0017313019390581717\n",
      "0.0017307026652821046\n",
      "0.0017301038062283738\n",
      "0.0017295053614666206\n",
      "0.0017289073305670815\n",
      "0.0017283097131005876\n",
      "0.0017277125086385626\n",
      "0.0017271157167530224\n",
      "0.0017265193370165745\n",
      "0.0017259233690024164\n",
      "0.001725327812284334\n",
      "0.0017247326664367024\n",
      "0.0017241379310344827\n",
      "0.001723543605653223\n",
      "0.0017229496898690559\n",
      "0.001722356183258698\n",
      "0.001721763085399449\n",
      "0.0017211703958691911\n",
      "0.0017205781142463868\n",
      "0.0017199862401100791\n",
      "0.0017193947730398899\n",
      "0.0017188037126160192\n",
      "0.001718213058419244\n",
      "0.0017176228100309172\n",
      "0.001717032967032967\n",
      "0.0017164435290078957\n",
      "0.0017158544955387784\n",
      "0.0017152658662092624\n",
      "0.0017146776406035665\n",
      "0.0017140898183064792\n",
      "0.0017135023989033585\n",
      "0.0017129153819801302\n",
      "0.0017123287671232876\n",
      "0.0017117425539198905\n",
      "0.0017111567419575632\n",
      "0.0017105713308244953\n",
      "0.001709986320109439\n",
      "0.0017094017094017094\n",
      "0.0017088174982911825\n",
      "0.0017082336863682953\n",
      "0.0017076502732240437\n",
      "0.001707067258449983\n",
      "0.0017064846416382253\n",
      "0.0017059024223814397\n",
      "0.0017053206002728514\n",
      "0.0017047391749062393\n",
      "0.0017041581458759373\n",
      "0.0017035775127768314\n",
      "0.0017029972752043597\n",
      "0.0017024174327545114\n",
      "0.0017018379850238256\n",
      "0.001701258931609391\n",
      "0.0017006802721088435\n",
      "0.0017001020061203672\n",
      "0.001699524133242692\n",
      "0.0016989466530750934\n",
      "0.0016983695652173913\n",
      "0.001697792869269949\n",
      "0.0016972165648336728\n",
      "0.0016966406515100101\n",
      "0.0016960651289009499\n",
      "0.00169548999660902\n",
      "0.001694915254237288\n",
      "0.0016943409013893595\n",
      "0.0016937669376693768\n",
      "0.0016931933626820183\n",
      "0.0016926201760324984\n",
      "0.001692047377326565\n",
      "0.0016914749661705007\n",
      "0.0016909029421711193\n",
      "0.0016903313049357674\n",
      "0.0016897600540723217\n",
      "0.0016891891891891893\n",
      "0.0016886187098953055\n",
      "0.001688048615800135\n",
      "0.0016874789065136687\n",
      "0.0016869095816464238\n",
      "0.0016863406408094434\n",
      "0.0016857720836142953\n",
      "0.0016852039096730705\n",
      "0.0016846361185983828\n",
      "0.001684068710003368\n",
      "0.0016835016835016834\n",
      "0.001682935038707506\n",
      "0.0016823687752355316\n",
      "0.0016818028927009755\n",
      "0.0016812373907195697\n",
      "0.0016806722689075631\n",
      "0.0016801075268817205\n",
      "0.0016795431642593216\n",
      "0.0016789791806581598\n",
      "0.0016784155756965425\n",
      "0.0016778523489932886\n",
      "0.0016772895001677288\n",
      "0.001676727028839705\n",
      "0.0016761649346295675\n",
      "0.001675603217158177\n",
      "0.0016750418760469012\n",
      "0.0016744809109176155\n",
      "0.0016739203213927017\n",
      "0.0016733601070950468\n",
      "0.0016728002676480427\n",
      "0.0016722408026755853\n",
      "0.001671681711802073\n",
      "0.0016711229946524064\n",
      "0.001670564650851988\n",
      "0.0016700066800267202\n",
      "0.001669449081803005\n",
      "0.0016688918558077437\n",
      "0.001668335001668335\n",
      "0.001667778519012675\n",
      "0.0016672224074691564\n",
      "0.0016666666666666668\n",
      "0.0016661112962345886\n",
      "0.0016655562958027982\n",
      "0.001665001665001665\n",
      "0.0016644474034620505\n",
      "0.0016638935108153079\n",
      "0.00166333998669328\n",
      "0.0016627868307283007\n",
      "0.0016622340425531915\n",
      "0.001661681621801263\n",
      "0.0016611295681063123\n",
      "0.0016605778811026237\n",
      "0.0016600265604249668\n",
      "0.001659475605708596\n",
      "0.0016589250165892503\n",
      "0.001658374792703151\n",
      "0.0016578249336870027\n",
      "0.0016572754391779914\n",
      "0.0016567263088137839\n",
      "0.0016561775422325273\n",
      "0.0016556291390728477\n",
      "0.0016550810989738498\n",
      "0.0016545334215751159\n",
      "0.0016539861065167053\n",
      "0.0016534391534391533\n",
      "0.001652892561983471\n",
      "0.0016523463317911435\n",
      "0.0016518004625041295\n",
      "0.0016512549537648614\n",
      "0.001650709805216243\n",
      "0.0016501650165016502\n",
      "0.001649620587264929\n",
      "0.0016490765171503958\n",
      "0.0016485328058028356\n",
      "0.0016479894528675016\n",
      "0.0016474464579901153\n",
      "0.0016469038208168643\n",
      "0.0016463615409944023\n",
      "0.0016458196181698486\n",
      "0.0016452780519907865\n",
      "0.001644736842105263\n",
      "0.001644195988161789\n",
      "0.001643655489809336\n",
      "0.001643115346697338\n",
      "0.0016425755584756898\n",
      "0.0016420361247947454\n",
      "0.0016414970453053185\n",
      "0.0016409583196586807\n",
      "0.0016404199475065617\n",
      "0.0016398819285011479\n",
      "0.001639344262295082\n",
      "0.0016388069485414618\n",
      "0.00163826998689384\n",
      "0.0016377333770062235\n",
      "0.0016371971185330713\n",
      "0.0016366612111292963\n",
      "0.0016361256544502618\n",
      "0.0016355904481517827\n",
      "0.0016350555918901242\n",
      "0.0016345210853220007\n",
      "0.0016339869281045752\n",
      "0.001633453119895459\n",
      "0.0016329196603527107\n",
      "0.001632386549134835\n",
      "0.0016318537859007832\n",
      "0.0016313213703099511\n",
      "0.0016307893020221786\n",
      "0.0016302575806977503\n",
      "0.0016297262059973925\n",
      "0.0016291951775822744\n",
      "0.0016286644951140066\n",
      "0.0016281341582546401\n",
      "0.0016276041666666667\n",
      "0.0016270745200130166\n",
      "0.0016265452179570592\n",
      "0.0016260162601626016\n",
      "0.001625487646293888\n",
      "0.0016249593760155996\n",
      "0.0016244314489928524\n",
      "0.0016239038648911985\n",
      "0.0016233766233766235\n",
      "0.0016228497241155468\n",
      "0.0016223231667748216\n",
      "0.001621796951021732\n",
      "0.001621271076523995\n",
      "0.0016207455429497568\n",
      "0.0016202203499675956\n",
      "0.0016196954972465176\n",
      "0.0016191709844559584\n",
      "0.0016186468112657818\n",
      "0.0016181229773462784\n",
      "0.0016175994823681655\n",
      "0.0016170763260025874\n",
      "0.0016165535079211122\n",
      "0.0016160310277957336\n",
      "0.0016155088852988692\n",
      "0.001614987080103359\n",
      "0.0016144656118824668\n",
      "0.0016139444803098773\n",
      "0.0016134236850596966\n",
      "0.0016129032258064516\n",
      "0.0016123831022250886\n",
      "0.0016118633139909735\n",
      "0.0016113438607798904\n",
      "0.0016108247422680412\n",
      "0.001610305958132045\n",
      "0.0016097875080489374\n",
      "0.0016092693916961698\n",
      "0.0016087516087516086\n",
      "0.0016082341588935349\n",
      "0.001607717041800643\n",
      "0.0016072002571520412\n",
      "0.0016066838046272494\n",
      "0.0016061676839061998\n",
      "0.0016056518946692357\n",
      "0.0016051364365971107\n",
      "0.0016046213093709885\n",
      "0.0016041065126724415\n",
      "0.001603592046183451\n",
      "0.0016030779095864058\n",
      "0.0016025641025641025\n",
      "0.0016020506247997437\n",
      "0.0016015374759769379\n",
      "0.001601024655779699\n",
      "0.0016005121638924455\n",
      "0.0016\n",
      "0.001599488163787588\n",
      "0.0015989766549408379\n",
      "0.00159846547314578\n",
      "0.0015979546180888463\n",
      "0.001597444089456869\n",
      "0.0015969338869370809\n",
      "0.0015964240102171138\n",
      "0.0015959144589849984\n",
      "0.001595405232929164\n",
      "0.001594896331738437\n",
      "0.0015943877551020409\n",
      "0.0015938795027095952\n",
      "0.0015933715742511153\n",
      "0.0015928639694170119\n",
      "0.0015923566878980893\n",
      "0.001591849729385546\n",
      "0.001591343093570974\n",
      "0.001590836780146357\n",
      "0.0015903307888040711\n",
      "0.001589825119236884\n",
      "0.001589319771137953\n",
      "0.0015888147442008262\n",
      "0.0015883100381194409\n",
      "0.0015878056525881232\n",
      "0.0015873015873015873\n",
      "0.0015867978419549348\n",
      "0.0015862944162436548\n",
      "0.001585791309863622\n",
      "0.0015852885225110971\n",
      "0.001584786053882726\n",
      "0.0015842839036755386\n",
      "0.0015837820715869496\n",
      "0.0015832805573147563\n",
      "0.0015827793605571383\n",
      "0.0015822784810126582\n",
      "0.0015817779183802593\n",
      "0.0015812776723592662\n",
      "0.0015807777426493834\n",
      "0.0015802781289506952\n",
      "0.001579778830963665\n",
      "0.0015792798483891346\n",
      "0.0015787811809283233\n",
      "0.0015782828282828283\n",
      "0.001577784790154623\n",
      "0.0015772870662460567\n",
      "0.001576789656259855\n",
      "0.0015762925598991173\n",
      "0.001575795776867318\n",
      "0.001575299306868305\n",
      "0.0015748031496062992\n",
      "0.0015743073047858943\n",
      "0.0015738117721120553\n",
      "0.0015733165512901196\n",
      "0.0015728216420257944\n",
      "0.0015723270440251573\n",
      "0.0015718327569946558\n",
      "0.0015713387806411063\n",
      "0.0015708451146716933\n",
      "0.00157035175879397\n",
      "0.0015698587127158557\n",
      "0.001569365976145637\n",
      "0.0015688735487919673\n",
      "0.0015683814303638645\n",
      "0.0015678896205707118\n",
      "0.001567398119122257\n",
      "0.0015669069257286117\n",
      "0.0015664160401002505\n",
      "0.0015659254619480112\n",
      "0.0015654351909830933\n",
      "0.001564945226917058\n",
      "0.0015644555694618273\n",
      "0.0015639662183296842\n",
      "0.0015634771732332708\n",
      "0.0015629884338855893\n",
      "0.0015625\n",
      "0.001562011871290222\n",
      "0.001561524047470331\n",
      "0.0015610365282547611\n",
      "0.001560549313358302\n",
      "0.0015600624024961\n",
      "0.0015595757953836558\n",
      "0.0015590894917368258\n",
      "0.0015586034912718205\n",
      "0.0015581177937052041\n",
      "0.001557632398753894\n",
      "0.0015571473061351605\n",
      "0.001556662515566625\n",
      "0.001556178026766262\n",
      "0.0015556938394523958\n",
      "0.0015552099533437014\n",
      "0.001554726368159204\n",
      "0.001554243083618278\n",
      "0.0015537600994406464\n",
      "0.0015532774153463808\n",
      "0.0015527950310559005\n",
      "0.001552312946289972\n",
      "0.0015518311607697084\n",
      "0.0015513496742165685\n",
      "0.0015508684863523574\n",
      "0.0015503875968992248\n",
      "0.0015499070055796653\n",
      "0.0015494267121165168\n",
      "0.0015489467162329617\n",
      "0.001548467017652524\n",
      "0.0015479876160990713\n",
      "0.0015475085112968121\n",
      "0.001547029702970297\n",
      "0.001546551190844417\n",
      "0.0015460729746444033\n",
      "0.0015455950540958269\n",
      "0.0015451174289245982\n",
      "0.0015446400988569664\n",
      "0.0015441630636195182\n",
      "0.0015436863229391787\n",
      "0.0015432098765432098\n",
      "0.0015427337241592102\n",
      "0.0015422578655151142\n",
      "0.001541782300339192\n",
      "0.0015413070283600493\n",
      "0.0015408320493066256\n",
      "0.0015403573629081946\n",
      "0.001539882968894364\n",
      "0.001539408866995074\n",
      "0.0015389350569405972\n",
      "0.0015384615384615385\n",
      "0.0015379883112888342\n",
      "0.0015375153751537515\n",
      "0.001537042729787888\n",
      "0.0015365703749231714\n",
      "0.0015360983102918587\n",
      "0.0015356265356265355\n",
      "0.0015351550506601166\n",
      "0.001534683855125844\n",
      "0.0015342129487572874\n",
      "0.0015337423312883436\n",
      "0.0015332720024532351\n",
      "0.0015328019619865114\n",
      "0.0015323322096230463\n",
      "0.0015318627450980392\n",
      "0.0015313935681470138\n",
      "0.0015309246785058174\n",
      "0.0015304560759106215\n",
      "0.0015299877600979193\n",
      "0.0015295197308045274\n",
      "0.0015290519877675841\n",
      "0.001528584530724549\n",
      "0.001528117359413203\n",
      "0.0015276504735716467\n",
      "0.0015271838729383018\n",
      "0.0015267175572519084\n",
      "0.0015262515262515263\n",
      "0.0015257857796765334\n",
      "0.001525320317266626\n",
      "0.0015248551387618177\n",
      "0.001524390243902439\n",
      "0.0015239256324291375\n",
      "0.0015234613040828763\n",
      "0.0015229972586049345\n",
      "0.0015225334957369061\n",
      "0.0015220700152207\n",
      "0.0015216068167985392\n",
      "0.0015211439002129601\n",
      "0.0015206812652068127\n",
      "0.0015202189115232593\n",
      "0.001519756838905775\n",
      "0.0015192950470981465\n",
      "0.0015188335358444715\n",
      "0.0015183723048891589\n",
      "0.0015179113539769277\n",
      "0.0015174506828528073\n",
      "0.001516990291262136\n",
      "0.001516530178950561\n",
      "0.0015160703456640388\n",
      "0.001515610791148833\n",
      "0.0015151515151515152\n",
      "0.001514692517418964\n",
      "0.0015142337976983646\n",
      "0.0015137753557372085\n",
      "0.001513317191283293\n",
      "0.0015128593040847202\n",
      "0.0015124016938898972\n",
      "0.0015119443604475356\n",
      "0.0015114873035066505\n",
      "0.0015110305228165609\n",
      "0.0015105740181268882\n",
      "0.0015101177891875567\n",
      "0.0015096618357487923\n",
      "0.001509206157561123\n",
      "0.0015087507543753772\n",
      "0.0015082956259426848\n",
      "0.0015078407720144752\n",
      "0.0015073861923424782\n",
      "0.0015069318866787222\n",
      "0.0015064778547755348\n",
      "0.0015060240963855422\n",
      "0.0015055706112616681\n",
      "0.0015051173991571343\n",
      "0.001504664459825459\n",
      "0.0015042117930204573\n",
      "0.0015037593984962407\n",
      "0.001503307276007216\n",
      "0.0015028554253080854\n",
      "0.0015024038461538462\n",
      "0.0015019525382997897\n",
      "0.0015015015015015015\n",
      "0.0015010507355148605\n",
      "0.0015006002400960385\n",
      "0.0015001500150015\n",
      "0.0014997000599880025\n",
      "0.0014992503748125937\n",
      "0.001498800959232614\n",
      "0.0014983518130056938\n",
      "0.0014979029358897543\n",
      "0.001497454327643007\n",
      "0.0014970059880239522\n",
      "0.00149655791679138\n",
      "0.0014961101137043686\n",
      "0.0014956625785222854\n",
      "0.0014952153110047847\n",
      "0.0014947683109118087\n",
      "0.0014943215780035865\n",
      "0.0014938751120406335\n",
      "0.0014934289127837516\n",
      "0.001492982979994028\n",
      "0.0014925373134328358\n",
      "0.0014920919128618322\n",
      "0.0014916467780429594\n",
      "0.0014912019087384432\n",
      "0.0014907573047107932\n",
      "0.0014903129657228018\n",
      "0.0014898688915375446\n",
      "0.0014894250819183796\n",
      "0.0014889815366289458\n",
      "0.0014885382554331646\n",
      "0.001488095238095238\n",
      "0.001487652484379649\n",
      "0.00148720999405116\n",
      "0.0014867677668748143\n",
      "0.0014863258026159335\n",
      "0.0014858841010401188\n",
      "0.0014854426619132501\n",
      "0.001485001485001485\n",
      "0.0014845605700712589\n",
      "0.0014841199168892847\n",
      "0.001483679525222552\n",
      "0.0014832393948383269\n",
      "0.0014827995255041518\n",
      "0.0014823599169878447\n",
      "0.0014819205690574985\n",
      "0.0014814814814814814\n",
      "0.001481042654028436\n",
      "0.0014806040864672786\n",
      "0.0014801657785671995\n",
      "0.001479727730097662\n",
      "0.0014792899408284023\n",
      "0.0014788524105294291\n",
      "0.0014784151389710231\n",
      "0.0014779781259237363\n",
      "0.0014775413711583924\n",
      "0.0014771048744460858\n",
      "0.0014766686355581807\n",
      "0.0014762326542663124\n",
      "0.0014757969303423849\n",
      "0.0014753614635585719\n",
      "0.0014749262536873156\n",
      "0.001474491300501327\n",
      "0.001474056603773585\n",
      "0.0014736221632773356\n",
      "0.0014731879787860931\n",
      "0.0014727540500736377\n",
      "0.0014723203769140165\n",
      "0.0014718869590815426\n",
      "0.0014714537963507945\n",
      "0.0014710208884966167\n",
      "0.0014705882352941176\n",
      "0.001470155836518671\n",
      "0.0014697236919459142\n",
      "0.0014692918013517484\n",
      "0.0014688601645123384\n",
      "0.0014684287812041115\n",
      "0.001467997651203758\n",
      "0.0014675667742882301\n",
      "0.0014671361502347417\n",
      "0.0014667057788207685\n",
      "0.001466275659824047\n",
      "0.001465845793022574\n",
      "0.0014654161781946073\n",
      "0.001464986815118664\n",
      "0.0014645577035735209\n",
      "0.0014641288433382138\n",
      "0.0014637002341920376\n",
      "0.0014632718759145448\n",
      "0.001462843768285547\n",
      "0.0014624159110851126\n",
      "0.0014619883040935672\n",
      "0.0014615609470914938\n",
      "0.0014611338398597311\n",
      "0.001460706982179375\n",
      "0.0014602803738317756\n",
      "0.00145985401459854\n",
      "0.0014594279042615295\n",
      "0.0014590020426028597\n",
      "0.0014585764294049008\n",
      "0.0014581510644502771\n",
      "0.0014577259475218659\n",
      "0.001457301078402798\n",
      "0.001456876456876457\n",
      "0.0014564520827264782\n",
      "0.00145602795573675\n",
      "0.001455604075691412\n",
      "0.0014551804423748546\n",
      "0.0014547570555717194\n",
      "0.0014543339150668994\n",
      "0.0014539110206455365\n",
      "0.0014534883720930232\n",
      "0.0014530659691950015\n",
      "0.001452643811737362\n",
      "0.0014522218995062445\n",
      "0.0014518002322880372\n",
      "0.001451378809869376\n",
      "0.0014509576320371445\n",
      "0.001450536698578474\n",
      "0.0014501160092807424\n",
      "0.0014496955639315744\n",
      "0.0014492753623188406\n",
      "0.0014488554042306578\n",
      "0.0014484356894553883\n",
      "0.0014480162177816392\n",
      "0.0014475969889982628\n",
      "0.001447178002894356\n",
      "0.0014467592592592592\n",
      "0.0014463407578825572\n",
      "0.0014459224985540775\n",
      "0.0014455044810638912\n",
      "0.001445086705202312\n",
      "0.001444669170759896\n",
      "0.0014442518775274408\n",
      "0.0014438348252959862\n",
      "0.001443418013856813\n",
      "0.001443001443001443\n",
      "0.0014425851125216388\n",
      "0.001442169022209403\n",
      "0.0014417531718569781\n",
      "0.0014413375612568463\n",
      "0.001440922190201729\n",
      "0.0014405070584845865\n",
      "0.0014400921658986176\n",
      "0.0014396775122372588\n",
      "0.0014392630972941854\n",
      "0.0014388489208633094\n",
      "0.0014384349827387803\n",
      "0.0014380212827149843\n",
      "0.001437607820586544\n",
      "0.0014371945961483186\n",
      "0.0014367816091954023\n",
      "0.0014363688595231256\n",
      "0.0014359563469270534\n",
      "0.001435544071202986\n",
      "0.0014351320321469576\n",
      "0.0014347202295552368\n",
      "0.001434308663224326\n",
      "0.0014338973329509608\n",
      "0.0014334862385321102\n",
      "0.0014330753797649756\n",
      "0.0014326647564469914\n",
      "0.0014322543683758235\n",
      "0.0014318442153493699\n",
      "0.0014314342971657602\n",
      "0.0014310246136233543\n",
      "0.001430615164520744\n",
      "0.0014302059496567505\n",
      "0.0014297969688304261\n",
      "0.001429388221841052\n",
      "0.0014289797084881394\n",
      "0.0014285714285714286\n",
      "0.0014281633818908884\n",
      "0.0014277555682467161\n",
      "0.0014273479874393378\n",
      "0.0014269406392694063\n",
      "0.0014265335235378032\n",
      "0.001426126640045636\n",
      "0.00142571998859424\n",
      "0.0014253135689851768\n",
      "0.0014249073810202336\n",
      "0.0014245014245014246\n",
      "0.0014240956992309882\n",
      "0.0014236902050113896\n",
      "0.0014232849416453174\n",
      "0.0014228799089356858\n",
      "0.001422475106685633\n",
      "0.001422070534698521\n",
      "0.0014216661927779358\n",
      "0.0014212620807276862\n",
      "0.0014208581983518045\n",
      "0.0014204545454545455\n",
      "0.0014200511218403862\n",
      "0.0014196479273140261\n",
      "0.001419244961680386\n",
      "0.0014188422247446084\n",
      "0.0014184397163120568\n",
      "0.0014180374361883153\n",
      "0.001417635384179189\n",
      "0.001417233560090703\n",
      "0.0014168319637291016\n",
      "0.00141643059490085\n",
      "0.001416029453412631\n",
      "0.0014156285390713476\n",
      "0.001415227851684121\n",
      "0.0014148273910582908\n",
      "0.0014144271570014145\n",
      "0.001414027149321267\n",
      "0.0014136273678258412\n",
      "0.0014132278123233466\n",
      "0.0014128284826222096\n",
      "0.0014124293785310734\n",
      "0.001412030499858797\n",
      "0.001411631846414455\n",
      "0.0014112334180073384\n",
      "0.0014108352144469526\n",
      "0.0014104372355430183\n",
      "0.0014100394811054709\n",
      "0.00140964195094446\n",
      "0.0014092446448703494\n",
      "0.0014088475626937165\n",
      "0.0014084507042253522\n",
      "0.0014080540692762602\n",
      "0.0014076576576576576\n",
      "0.0014072614691809737\n",
      "0.0014068655036578502\n",
      "0.0014064697609001407\n",
      "0.00140607424071991\n",
      "0.0014056789429294349\n",
      "0.001405283867341203\n",
      "0.0014048890137679123\n",
      "0.0014044943820224719\n",
      "0.0014040999719180005\n",
      "0.001403705783267827\n",
      "0.0014033118158854898\n",
      "0.0014029180695847362\n",
      "0.001402524544179523\n",
      "0.0014021312394840158\n",
      "0.0014017381553125877\n",
      "0.0014013452914798206\n",
      "0.0014009526478005044\n",
      "0.0014005602240896359\n",
      "0.0014001680201624195\n",
      "0.0013997760358342665\n",
      "0.001399384270920795\n",
      "0.0013989927252378287\n",
      "0.0013986013986013986\n",
      "0.0013982102908277406\n",
      "0.0013978194017332962\n",
      "0.001397428731134712\n",
      "0.0013970382788488405\n",
      "0.0013966480446927375\n",
      "0.0013962580284836638\n",
      "0.0013958682300390843\n",
      "0.0013954786491766676\n",
      "0.0013950892857142857\n",
      "0.001394700139470014\n",
      "0.0013943112102621305\n",
      "0.0013939224979091162\n",
      "0.0013935340022296545\n",
      "0.0013931457230426303\n",
      "0.001392757660167131\n",
      "0.001392369813422445\n",
      "0.0013919821826280624\n",
      "0.0013915947676036739\n",
      "0.0013912075681691708\n",
      "0.0013908205841446453\n",
      "0.0013904338153503894\n",
      "0.0013900472616068947\n",
      "0.0013896609227348527\n",
      "0.0013892747985551543\n",
      "0.001388888888888889\n",
      "0.0013885031935573452\n",
      "0.00138811771238201\n",
      "0.0013877324451845685\n",
      "0.0013873473917869034\n",
      "0.0013869625520110957\n",
      "0.0013865779256794233\n",
      "0.0013861935126143609\n",
      "0.001385809312638581\n",
      "0.0013854253255749516\n",
      "0.0013850415512465374\n",
      "0.0013846579894765993\n",
      "0.0013842746400885937\n",
      "0.0013838915029061722\n",
      "0.001383508577753182\n",
      "0.0013831258644536654\n",
      "0.0013827433628318584\n",
      "0.0013823610727121925\n",
      "0.0013819789939192924\n",
      "0.0013815971262779773\n",
      "0.0013812154696132596\n",
      "0.0013808340237503453\n",
      "0.0013804527885146328\n",
      "0.001380071763731714\n",
      "0.0013796909492273732\n",
      "0.001379310344827586\n",
      "0.0013789299503585218\n",
      "0.0013785497656465398\n",
      "0.0013781697905181918\n",
      "0.0013777900248002205\n",
      "0.0013774104683195593\n",
      "0.0013770311209033324\n",
      "0.0013766519823788547\n",
      "0.0013762730525736307\n",
      "0.001375894331315355\n",
      "0.001375515818431912\n",
      "0.0013751375137513752\n",
      "0.0013747594171020072\n",
      "0.0013743815283122594\n",
      "0.0013740038472107722\n",
      "0.0013736263736263737\n",
      "0.0013732491073880802\n",
      "0.0013728720483250961\n",
      "0.001372495196266813\n",
      "0.0013721185510428102\n",
      "0.0013717421124828531\n",
      "0.0013713658804168952\n",
      "0.0013709898546750755\n",
      "0.0013706140350877192\n",
      "0.0013702384214853384\n",
      "0.0013698630136986301\n",
      "0.001369487811558477\n",
      "0.0013691128148959474\n",
      "0.001368738023542294\n",
      "0.0013683634373289546\n",
      "0.0013679890560875513\n",
      "0.0013676148796498905\n",
      "0.0013672409078479629\n",
      "0.001366867140513942\n",
      "0.001366493577480186\n",
      "0.001366120218579235\n",
      "0.0013657470636438131\n",
      "0.001365374112506827\n",
      "0.001365001365001365\n",
      "0.0013646288209606986\n",
      "0.001364256480218281\n",
      "0.001363884342607747\n",
      "0.0013635124079629125\n",
      "0.0013631406761177754\n",
      "0.001362769146906514\n",
      "0.0013623978201634877\n",
      "0.001362026695723236\n",
      "0.0013616557734204794\n",
      "0.001361285053090117\n",
      "0.0013609145345672292\n",
      "0.0013605442176870747\n",
      "0.0013601741022850925\n",
      "0.0013598041881968997\n",
      "0.0013594344752582926\n",
      "0.001359064963305246\n",
      "0.001358695652173913\n",
      "0.0013583265417006249\n",
      "0.0013579576317218902\n",
      "0.0013575889220743959\n",
      "0.0013572204125950054\n",
      "0.0013568521031207597\n",
      "0.0013564839934888768\n",
      "0.0013561160835367507\n",
      "0.0013557483731019523\n",
      "0.0013553808620222283\n",
      "0.0013550135501355014\n",
      "0.00135464643727987\n",
      "0.0013542795232936078\n",
      "0.0013539128080151638\n",
      "0.0013535462912831618\n",
      "0.0013531799729364006\n",
      "0.0013528138528138528\n",
      "0.001352447930754666\n",
      "0.0013520822065981612\n",
      "0.0013517166801838335\n",
      "0.0013513513513513514\n",
      "0.0013509862199405566\n",
      "0.001350621285791464\n",
      "0.0013502565487442614\n",
      "0.0013498920086393088\n",
      "0.001349527665317139\n",
      "0.0013491635186184566\n",
      "0.001348799568384138\n",
      "0.001348435814455232\n",
      "0.0013480722566729577\n",
      "0.0013477088948787063\n",
      "0.0013473457289140394\n",
      "0.0013469827586206897\n",
      "0.00134661998384056\n",
      "0.0013462574044157242\n",
      "0.0013458950201884253\n",
      "0.0013455328310010765\n",
      "0.0013451708366962604\n",
      "0.0013448090371167294\n",
      "0.0013444474321054048\n",
      "0.0013440860215053765\n",
      "0.0013437248051599033\n",
      "0.0013433637829124126\n",
      "0.0013430029546065002\n",
      "0.0013426423200859291\n",
      "0.0013422818791946308\n",
      "0.0013419216317767043\n",
      "0.0013415615776764154\n",
      "0.0013412017167381974\n",
      "0.0013408420488066506\n",
      "0.0013404825737265416\n",
      "0.0013401232913428035\n",
      "0.0013397642015005359\n",
      "0.001339405304045004\n",
      "0.001339046598821639\n",
      "0.0013386880856760374\n",
      "0.0013383297644539614\n",
      "0.001337971635001338\n",
      "0.001337613697164259\n",
      "0.001337255950788981\n",
      "0.001336898395721925\n",
      "0.0013365410318096765\n",
      "0.0013361838588989846\n",
      "0.0013358268768367619\n",
      "0.0013354700854700855\n",
      "0.0013351134846461949\n",
      "0.0013347570742124934\n",
      "0.0013344008540165466\n",
      "0.0013340448239060833\n",
      "0.0013336889837289945\n",
      "0.0013333333333333333\n",
      "0.0013329778725673154\n",
      "0.0013326226012793177\n",
      "0.001332267519317879\n",
      "0.0013319126265316996\n",
      "0.0013315579227696406\n",
      "0.0013312034078807242\n",
      "0.0013308490817141336\n",
      "0.0013304949441192123\n",
      "0.0013301409949454642\n",
      "0.0013297872340425532\n",
      "0.0013294336612603031\n",
      "0.0013290802764486975\n",
      "0.0013287270794578793\n",
      "0.001328374070138151\n",
      "0.0013280212483399733\n",
      "0.0013276686139139671\n",
      "0.0013273161667109105\n",
      "0.001326963906581741\n",
      "0.0013266118333775537\n",
      "0.001326259946949602\n",
      "0.0013259082471492973\n",
      "0.001325556733828208\n",
      "0.0013252054068380599\n",
      "0.0013248542660307366\n",
      "0.0013245033112582781\n",
      "0.0013241525423728813\n",
      "0.0013238019592268996\n",
      "0.0013234515616728428\n",
      "0.0013231013495633766\n",
      "0.0013227513227513227\n",
      "0.0013224014810896587\n",
      "0.0013220518244315177\n",
      "0.0013217023526301878\n",
      "0.001321353065539112\n",
      "0.001321003963011889\n",
      "0.0013206550449022716\n",
      "0.0013203063110641669\n",
      "0.0013199577613516368\n",
      "0.0013196093956188968\n",
      "0.0013192612137203166\n",
      "0.0013189132155104195\n",
      "0.0013185654008438818\n",
      "0.001318217769575534\n",
      "0.0013178703215603585\n",
      "0.0013175230566534915\n",
      "0.0013171759747102212\n",
      "0.001316829075585989\n",
      "0.0013164823591363876\n",
      "0.0013161358252171624\n",
      "0.0013157894736842105\n",
      "0.0013154433043935806\n",
      "0.0013150973172014729\n",
      "0.0013147515119642387\n",
      "0.0013144058885383807\n",
      "0.001314060446780552\n",
      "0.0013137151865475565\n",
      "0.001313370107696349\n",
      "0.0013130252100840337\n",
      "0.0013126804935678655\n",
      "0.0013123359580052493\n",
      "0.0013119916032537393\n",
      "0.0013116474291710388\n",
      "0.0013113034356150013\n",
      "0.0013109596224436288\n",
      "0.001310615989515072\n",
      "0.001310272536687631\n",
      "0.0013099292638197536\n",
      "0.0013095861707700367\n",
      "0.0013092432573972245\n",
      "0.0013089005235602095\n",
      "0.0013085579691180318\n",
      "0.0013082155939298796\n",
      "0.0013078733978550876\n",
      "0.001307531380753138\n",
      "0.00130718954248366\n",
      "0.0013068478829064297\n",
      "0.0013065064018813691\n",
      "0.0013061650992685476\n",
      "0.0013058239749281796\n",
      "0.0013054830287206266\n",
      "0.0013051422605063951\n",
      "0.0013048016701461378\n",
      "0.0013044612575006521\n",
      "0.0013041210224308817\n",
      "0.001303780964797914\n",
      "0.0013034410844629822\n",
      "0.0013031013812874641\n",
      "0.0013027618551328818\n",
      "0.0013024225058609013\n",
      "0.0013020833333333333\n",
      "0.0013017443374121322\n",
      "0.0013014055179593961\n",
      "0.0013010668748373666\n",
      "0.0013007284079084287\n",
      "0.0013003901170351106\n",
      "0.0013000520020800832\n",
      "0.0012997140629061607\n",
      "0.0012993762993762994\n",
      "0.0012990387113535984\n",
      "0.0012987012987012987\n",
      "0.0012983640612827837\n",
      "0.0012980269989615785\n",
      "0.0012976901116013497\n",
      "0.0012973533990659055\n",
      "0.0012970168612191958\n",
      "0.0012966804979253112\n",
      "0.0012963443090484833\n",
      "0.0012960082944530845\n",
      "0.001295672454003628\n",
      "0.0012953367875647669\n",
      "0.001295001295001295\n",
      "0.001294665976178146\n",
      "0.0012943308309603934\n",
      "0.0012939958592132505\n",
      "0.00129366106080207\n",
      "0.0012933264355923435\n",
      "0.0012929919834497026\n",
      "0.0012926577042399173\n",
      "0.0012923235978288964\n",
      "0.0012919896640826874\n",
      "0.0012916559028674762\n",
      "0.0012913223140495868\n",
      "0.0012909888974954814\n",
      "0.0012906556530717604\n",
      "0.0012903225806451613\n",
      "0.0012899896800825593\n",
      "0.0012896569512509672\n",
      "0.0012893243940175349\n",
      "0.001288992008249549\n",
      "0.001288659793814433\n",
      "0.0012883277505797476\n",
      "0.001287995878413189\n",
      "0.0012876641771825909\n",
      "0.0012873326467559218\n",
      "0.001287001287001287\n",
      "0.0012866700977869274\n",
      "0.0012863390789812194\n",
      "0.001286008230452675\n",
      "0.0012856775520699408\n",
      "0.0012853470437017994\n",
      "0.0012850167052171678\n",
      "0.0012846865364850976\n",
      "0.0012843565373747753\n",
      "0.0012840267077555213\n",
      "0.0012836970474967907\n",
      "0.0012833675564681724\n",
      "0.0012830382345393892\n",
      "0.0012827090815802976\n",
      "0.0012823800974608873\n",
      "0.001282051282051282\n",
      "0.001281722635221738\n",
      "0.0012813941568426447\n",
      "0.0012810658467845247\n",
      "0.0012807377049180327\n",
      "0.0012804097311139564\n",
      "0.0012800819252432156\n",
      "0.001279754287176862\n",
      "0.00127942681678608\n",
      "0.0012790995139421847\n",
      "0.0012787723785166241\n",
      "0.0012784454103809768\n",
      "0.001278118609406953\n",
      "0.001277791975466394\n",
      "0.0012774655084312723\n",
      "0.001277139208173691\n",
      "0.0012768130745658835\n",
      "0.0012764871074802144\n",
      "0.001276161306789178\n",
      "0.0012758356723653994\n",
      "0.0012755102040816326\n",
      "0.0012751849018107625\n",
      "0.0012748597654258032\n",
      "0.0012745347947998981\n",
      "0.0012742099898063201\n",
      "0.0012738853503184713\n",
      "0.0012735608762098828\n",
      "0.0012732365673542145\n",
      "0.0012729124236252546\n",
      "0.0012725884448969204\n",
      "0.001272264631043257\n",
      "0.0012719409819384382\n",
      "0.001271617497456765\n",
      "0.0012712941774726673\n",
      "0.0012709710218607015\n",
      "0.0012706480304955528\n",
      "0.0012703252032520325\n",
      "0.00127000254000508\n",
      "0.0012696800406297613\n",
      "0.0012693577050012694\n",
      "0.0012690355329949238\n",
      "0.001268713524486171\n",
      "0.0012683916793505834\n",
      "0.00126806999746386\n",
      "0.0012677484787018255\n",
      "0.0012674271229404308\n",
      "0.0012671059300557526\n",
      "0.001266784899923993\n",
      "0.0012664640324214793\n",
      "0.0012661433274246644\n",
      "0.0012658227848101266\n",
      "0.0012655024044545685\n",
      "0.0012651821862348178\n",
      "0.0012648621300278269\n",
      "0.0012645422357106728\n",
      "0.0012642225031605564\n",
      "0.0012639029322548028\n",
      "0.0012635835228708618\n",
      "0.0012632642748863063\n",
      "0.001262945188178833\n",
      "0.0012626262626262627\n",
      "0.0012623074981065387\n",
      "0.0012619888944977284\n",
      "0.0012616704516780217\n",
      "0.0012613521695257316\n",
      "0.0012610340479192938\n",
      "0.0012607160867372667\n",
      "0.0012603982858583312\n",
      "0.0012600806451612903\n",
      "0.0012597631645250692\n",
      "0.0012594458438287153\n",
      "0.0012591286829513977\n",
      "0.0012588116817724068\n",
      "0.0012584948401711553\n",
      "0.0012581781580271766\n",
      "0.0012578616352201257\n",
      "0.0012575452716297787\n",
      "0.001257229067136032\n",
      "0.001256913021618904\n",
      "0.0012565971349585323\n",
      "0.001256281407035176\n",
      "0.0012559658377292139\n",
      "0.0012556504269211452\n",
      "0.0012553351744915891\n",
      "0.0012550200803212851\n",
      "0.0012547051442910915\n",
      "0.001254390366281987\n",
      "0.001254075746175069\n",
      "0.0012537612838515546\n",
      "0.00125344697919278\n",
      "0.0012531328320802004\n",
      "0.0012528188423953897\n",
      "0.00125250501002004\n",
      "0.001252191334835963\n",
      "0.0012518778167250877\n",
      "0.0012515644555694619\n",
      "0.0012512512512512512\n",
      "0.0012509382036527395\n",
      "0.0012506253126563281\n",
      "0.001250312578144536\n",
      "0.00125\n",
      "0.0012496875781054736\n",
      "0.0012493753123438282\n",
      "0.0012490632025980515\n",
      "0.0012487512487512488\n",
      "0.0012484394506866417\n",
      "0.0012481278082875687\n",
      "0.0012478163214374844\n",
      "0.00124750499001996\n",
      "0.001247193813918683\n",
      "0.0012468827930174563\n",
      "0.0012465719272001994\n",
      "0.0012462612163509472\n",
      "0.00124595066035385\n",
      "0.001245640259093174\n",
      "0.0012453300124533001\n",
      "0.001245019920318725\n",
      "0.0012447099825740602\n",
      "0.0012444001991040318\n",
      "0.001244090569793481\n",
      "0.0012437810945273632\n",
      "0.0012434717731907485\n",
      "0.0012431626056688214\n",
      "0.0012428535918468805\n",
      "0.001242544731610338\n",
      "0.0012422360248447205\n",
      "0.0012419274714356682\n",
      "0.0012416190712689348\n",
      "0.0012413108242303873\n",
      "0.0012410027302060065\n",
      "0.0012406947890818859\n",
      "0.0012403870007442323\n",
      "0.001240079365079365\n",
      "0.001239771881973717\n",
      "0.0012394645513138325\n",
      "0.0012391573729863693\n",
      "0.001238850346878097\n",
      "0.0012385434728758979\n",
      "0.0012382367508667657\n",
      "0.0012379301807378064\n",
      "0.0012376237623762376\n",
      "0.0012373174956693887\n",
      "0.0012370113805047005\n",
      "0.0012367054167697256\n",
      "0.0012363996043521265\n",
      "0.0012360939431396785\n",
      "0.001235788433020267\n",
      "0.001235483073881888\n",
      "0.0012351778656126482\n",
      "0.0012348728081007657\n",
      "0.0012345679012345679\n",
      "0.0012342631449024932\n",
      "0.0012339585389930898\n",
      "0.001233654083395016\n",
      "0.00123334977799704\n",
      "0.0012330456226880395\n",
      "0.001232741617357002\n",
      "0.0012324377618930244\n",
      "0.0012321340561853129\n",
      "0.001231830500123183\n",
      "0.0012315270935960591\n",
      "0.0012312238364934746\n",
      "0.0012309207287050715\n",
      "0.0012306177701206006\n",
      "0.0012303149606299212\n",
      "0.0012300123001230013\n",
      "0.0012297097884899164\n",
      "0.0012294074256208507\n",
      "0.0012291052114060963\n",
      "0.001228803145736053\n",
      "0.0012285012285012285\n",
      "0.0012281994595922379\n",
      "0.0012278978388998035\n",
      "0.0012275963663147557\n",
      "0.0012272950417280314\n",
      "0.001226993865030675\n",
      "0.0012266928361138372\n",
      "0.0012263919548687761\n",
      "0.0012260912211868563\n",
      "0.001225790634959549\n",
      "0.0012254901960784314\n",
      "0.0012251899044351876\n",
      "0.001224889759921607\n",
      "0.0012245897624295861\n",
      "0.0012242899118511264\n",
      "0.0012239902080783353\n",
      "0.0012236906510034262\n",
      "0.001223391240518718\n",
      "0.001223091976516634\n",
      "0.001222792858889704\n",
      "0.0012224938875305623\n",
      "0.0012221950623319481\n",
      "0.0012218963831867058\n",
      "0.001221597849987784\n",
      "0.0012212994626282364\n",
      "0.001221001221001221\n",
      "0.001220703125\n",
      "0.00122040517451794\n",
      "0.0012201073694485115\n",
      "0.0012198097096852891\n",
      "0.0012195121951219512\n",
      "0.00121921482565228\n",
      "0.0012189176011701609\n",
      "0.0012186205215695832\n",
      "0.0012183235867446393\n",
      "0.001218026796589525\n",
      "0.0012177301509985387\n",
      "0.0012174336498660824\n",
      "0.0012171372930866603\n",
      "0.0012168410805548796\n",
      "0.0012165450121654502\n",
      "0.0012162490878131842\n",
      "0.0012159533073929961\n",
      "0.0012156576707999028\n",
      "0.0012153621779290229\n",
      "0.001215066828675577\n",
      "0.0012147716229348883\n",
      "0.0012144765606023804\n",
      "0.0012141816415735794\n",
      "0.0012138868657441126\n",
      "0.0012135922330097086\n",
      "0.0012132977432661976\n",
      "0.0012130033964095099\n",
      "0.001212709192335678\n",
      "0.0012124151309408342\n",
      "0.0012121212121212121\n",
      "0.0012118274357731458\n",
      "0.00121153380179307\n",
      "0.0012112403100775194\n",
      "0.001210946960523129\n",
      "0.0012106537530266344\n",
      "0.0012103606874848704\n",
      "0.0012100677637947724\n",
      "0.0012097749818533753\n",
      "0.0012094823415578133\n",
      "0.0012091898428053204\n",
      "0.0012088974854932303\n",
      "0.001208605269518975\n",
      "0.001208313194780087\n",
      "0.0012080212611741967\n",
      "0.0012077294685990338\n",
      "0.001207437816952427\n",
      "0.0012071463061323032\n",
      "0.0012068549360366883\n",
      "0.0012065637065637065\n",
      "0.0012062726176115801\n",
      "0.00120598166907863\n",
      "0.0012056908608632747\n",
      "0.0012054001928640309\n",
      "0.001205109664979513\n",
      "0.0012048192771084338\n",
      "0.0012045290291496024\n",
      "0.0012042389210019267\n",
      "0.0012039489525644113\n",
      "0.001203659123736158\n",
      "0.0012033694344163659\n",
      "0.001203079884504331\n",
      "0.0012027904738994466\n",
      "0.0012025012025012026\n",
      "0.0012022120702091848\n",
      "0.001201923076923077\n",
      "0.001201634222542658\n",
      "0.001201345506967804\n",
      "0.0012010569300984868\n",
      "0.0012007684918347744\n",
      "0.0012004801920768306\n",
      "0.001200192030724916\n",
      "0.0011999040076793857\n",
      "0.0011996161228406909\n",
      "0.0011993283761093788\n",
      "0.001199040767386091\n",
      "0.0011987532965715656\n",
      "0.0011984659635666348\n",
      "0.0011981787682722263\n",
      "0.0011978917105893627\n",
      "0.0011976047904191617\n",
      "0.0011973180076628352\n",
      "0.0011970313622216902\n",
      "0.0011967448539971278\n",
      "0.0011964584828906438\n",
      "0.0011961722488038277\n",
      "0.001195886151638364\n",
      "0.0011956001912960307\n",
      "0.0011953143676786994\n",
      "0.0011950286806883365\n",
      "0.0011947431302270011\n",
      "0.0011944577161968467\n",
      "0.0011941724385001193\n",
      "0.0011938872970391596\n",
      "0.0011936022917164002\n",
      "0.0011933174224343676\n",
      "0.0011930326890956812\n",
      "0.0011927480916030535\n",
      "0.0011924636298592892\n",
      "0.0011921793037672865\n",
      "0.0011918951132300357\n",
      "0.0011916110581506197\n",
      "0.0011913271384322134\n",
      "0.0011910433539780848\n",
      "0.0011907597046915933\n",
      "0.0011904761904761906\n",
      "0.00119019281123542\n",
      "0.0011899095668729176\n",
      "0.0011896264572924102\n",
      "0.0011893434823977164\n",
      "0.0011890606420927466\n",
      "0.0011887779362815027\n",
      "0.001188495364868077\n",
      "0.001188212927756654\n",
      "0.0011879306248515087\n",
      "0.0011876484560570072\n",
      "0.0011873664212776064\n",
      "0.0011870845204178537\n",
      "0.0011868027533823878\n",
      "0.0011865211200759373\n",
      "0.0011862396204033216\n",
      "0.0011859582542694497\n",
      "0.0011856770215793219\n",
      "0.0011853959222380276\n",
      "0.0011851149561507466\n",
      "0.001184834123222749\n",
      "0.0011845534233593934\n",
      "0.0011842728564661299\n",
      "0.0011839924224484964\n",
      "0.0011837121212121212\n",
      "0.001183431952662722\n",
      "0.001183151916706105\n",
      "0.0011828720132481666\n",
      "0.0011825922421948912\n",
      "0.0011823126034523528\n",
      "0.001182033096926714\n",
      "0.001181753722524226\n",
      "0.0011814744801512287\n",
      "0.0011811953697141507\n",
      "0.0011809163911195087\n",
      "0.0011806375442739079\n",
      "0.0011803588290840415\n",
      "0.001180080245456691\n",
      "0.0011798017932987258\n",
      "0.0011795234725171032\n",
      "0.0011792452830188679\n",
      "0.001178967224711153\n",
      "0.0011786892975011788\n",
      "0.0011784115012962526\n",
      "0.00117813383600377\n",
      "0.001177856301531213\n",
      "0.0011775788977861517\n",
      "0.0011773016246762421\n",
      "0.0011770244821092278\n",
      "0.0011767474699929394\n",
      "0.001176470588235294\n",
      "0.0011761938367442955\n",
      "0.0011759172154280338\n",
      "0.0011756407241946861\n",
      "0.0011753643629525152\n",
      "0.0011750881316098707\n",
      "0.001174812030075188\n",
      "0.0011745360582569885\n",
      "0.0011742602160638798\n",
      "0.0011739845034045551\n",
      "0.0011737089201877935\n",
      "0.0011734334663224596\n",
      "0.0011731581417175035\n",
      "0.001172882946281961\n",
      "0.0011726078799249532\n",
      "0.0011723329425556857\n",
      "0.0011720581340834506\n",
      "0.0011717834544176236\n",
      "0.0011715089034676663\n",
      "0.0011712344811431249\n",
      "0.00117096018735363\n",
      "0.0011706860220088973\n",
      "0.0011704119850187266\n",
      "0.0011701380762930026\n",
      "0.001169864295741694\n",
      "0.0011695906432748538\n",
      "0.0011693171188026192\n",
      "0.0011690437222352116\n",
      "0.0011687704534829358\n",
      "0.0011684973124561813\n",
      "0.0011682242990654205\n",
      "0.00116795141322121\n",
      "0.0011676786548341896\n",
      "0.0011674060238150829\n",
      "0.0011671335200746965\n",
      "0.0011668611435239206\n",
      "0.0011665888940737283\n",
      "0.001166316771635176\n",
      "0.0011660447761194029\n",
      "0.0011657729074376311\n",
      "0.0011655011655011655\n",
      "0.0011652295502213937\n",
      "0.0011649580615097856\n",
      "0.0011646866992778943\n",
      "0.0011644154634373545\n",
      "0.0011641443538998836\n",
      "0.0011638733705772813\n",
      "0.0011636025133814289\n",
      "0.0011633317822242904\n",
      "0.0011630611770179111\n",
      "0.0011627906976744186\n",
      "0.0011625203441060219\n",
      "0.0011622501162250117\n",
      "0.0011619800139437602\n",
      "0.0011617100371747212\n",
      "0.0011614401858304297\n",
      "0.0011611704598235022\n",
      "0.0011609008590666356\n",
      "0.001160631383472609\n",
      "0.0011603620329542817\n",
      "0.001160092807424594\n",
      "0.001159823706796567\n",
      "0.0011595547309833025\n",
      "0.001159285879897983\n",
      "0.0011590171534538712\n",
      "0.0011587485515643105\n",
      "0.0011584800741427247\n",
      "0.0011582117211026176\n",
      "0.001157943492357573\n",
      "0.0011576753878212549\n",
      "0.0011574074074074073\n",
      "0.0011571395510298543\n",
      "0.0011568718186024988\n",
      "0.0011566042100393246\n",
      "0.001156336725254394\n",
      "0.0011560693641618498\n",
      "0.001155802126675913\n",
      "0.0011555350127108851\n",
      "0.0011552680221811461\n",
      "0.001155001155001155\n",
      "0.0011547344110854503\n",
      "0.0011544677903486493\n",
      "0.0011542012927054479\n",
      "0.0011539349180706207\n",
      "0.0011536686663590216\n",
      "0.0011534025374855825\n",
      "0.0011531365313653136\n",
      "0.001152870647913304\n",
      "0.001152604887044721\n",
      "0.00115233924867481\n",
      "0.001152073732718894\n",
      "0.001151808339092375\n",
      "0.0011515430677107323\n",
      "0.0011512779184895234\n",
      "0.0011510128913443832\n",
      "0.0011507479861910242\n",
      "0.001150483202945237\n",
      "0.0011502185415228894\n",
      "0.0011499540018399263\n",
      "0.0011496895838123706\n",
      "0.0011494252873563218\n",
      "0.0011491611123879567\n",
      "0.0011488970588235295\n",
      "0.0011486331265793705\n",
      "0.0011483693155718878\n",
      "0.001148105625717566\n",
      "0.001147842056932966\n",
      "0.0011475786091347257\n",
      "0.0011473152822395595\n",
      "0.0011470520761642578\n",
      "0.0011467889908256881\n",
      "0.0011465260261407934\n",
      "0.0011462631820265932\n",
      "0.0011460004584001834\n",
      "0.001145737855178735\n",
      "0.001145475372279496\n",
      "0.0011452130096197893\n",
      "0.001144950767117014\n",
      "0.0011446886446886447\n",
      "0.0011444266422522317\n",
      "0.0011441647597254005\n",
      "0.0011439029970258523\n",
      "0.0011436413540713633\n",
      "0.001143379830779785\n",
      "0.0011431184270690445\n",
      "0.001142857142857143\n",
      "0.0011425959780621572\n",
      "0.001142334932602239\n",
      "0.0011420740063956144\n",
      "0.0011418131993605847\n",
      "0.001141552511415525\n",
      "0.0011412919424788862\n",
      "0.0011410314924691922\n",
      "0.0011407711613050423\n",
      "0.0011405109489051094\n",
      "0.0011402508551881414\n",
      "0.0011399908800729594\n",
      "0.0011397310234784591\n",
      "0.0011394712853236098\n",
      "0.001139211665527455\n",
      "0.0011389521640091116\n",
      "0.0011386927806877705\n",
      "0.001138433515482696\n",
      "0.0011381743683132257\n",
      "0.001137915339098771\n",
      "0.0011376564277588168\n",
      "0.0011373976342129207\n",
      "0.0011371389583807142\n",
      "0.001136880400181901\n",
      "0.0011366219595362582\n",
      "0.0011363636363636363\n",
      "0.0011361054305839581\n",
      "0.0011358473421172195\n",
      "0.0011355893708834886\n",
      "0.0011353315168029065\n",
      "0.0011350737797956867\n",
      "0.0011348161597821154\n",
      "0.0011345586566825505\n",
      "0.001134301270417423\n",
      "0.0011340440009072353\n",
      "0.0011337868480725624\n",
      "0.0011335298118340512\n",
      "0.0011332728921124207\n",
      "0.0011330160888284614\n",
      "0.0011327594019030357\n",
      "0.0011325028312570782\n",
      "0.0011322463768115942\n",
      "0.0011319900384876612\n",
      "0.0011317338162064282\n",
      "0.0011314777098891152\n",
      "0.0011312217194570137\n",
      "0.001130965844831486\n",
      "0.0011307100859339666\n",
      "0.0011304544426859599\n",
      "0.0011301989150090416\n",
      "0.0011299435028248588\n",
      "0.0011296882060551287\n",
      "0.00112943302462164\n",
      "0.001129177958446251\n",
      "0.001128923007450892\n",
      "0.001128668171557562\n",
      "0.0011284134506883321\n",
      "0.001128158844765343\n",
      "0.0011279043537108053\n",
      "0.0011276499774470004\n",
      "0.0011273957158962795\n",
      "0.001127141568981064\n",
      "0.001126887536623845\n",
      "0.0011266336187471834\n",
      "0.0011263798152737104\n",
      "0.0011261261261261261\n",
      "0.001125872551227201\n",
      "0.0011256190904997748\n",
      "0.0011253657438667567\n",
      "0.0011251125112511251\n",
      "0.0011248593925759281\n",
      "0.0011246063877642825\n",
      "0.001124353496739375\n",
      "0.0011241007194244604\n",
      "0.0011238480557428637\n",
      "0.0011235955056179776\n",
      "0.0011233430689732643\n",
      "0.0011230907457322552\n",
      "0.0011228385358185494\n",
      "0.001122586439155815\n",
      "0.001122334455667789\n",
      "0.0011220825852782765\n",
      "0.001121830827911151\n",
      "0.0011215791834903544\n",
      "0.001121327651939897\n",
      "0.0011210762331838565\n",
      "0.0011208249271463797\n",
      "0.0011205737337516809\n",
      "0.001120322652924042\n",
      "0.0011200716845878136\n",
      "0.0011198208286674132\n",
      "0.0011195700850873264\n",
      "0.0011193194537721066\n",
      "0.0011190689346463742\n",
      "0.0011188185276348177\n",
      "0.0011185682326621924\n",
      "0.0011183180496533215\n",
      "0.0011180679785330948\n",
      "0.0011178180192264698\n",
      "0.001117568171658471\n",
      "0.0011173184357541898\n",
      "0.0011170688114387846\n",
      "0.0011168192986374804\n",
      "0.0011165698972755694\n",
      "0.0011163206072784104\n",
      "0.0011160714285714285\n",
      "0.0011158223610801161\n",
      "0.0011155734047300313\n",
      "0.001115324559446799\n",
      "0.0011150758251561106\n",
      "0.0011148272017837235\n",
      "0.0011145786892554615\n",
      "0.0011143302874972142\n",
      "0.0011140819964349377\n",
      "0.0011138338159946536\n",
      "0.0011135857461024498\n",
      "0.00111333778668448\n",
      "0.0011130899376669634\n",
      "0.001112842198976185\n",
      "0.0011125945705384957\n",
      "0.0011123470522803114\n",
      "0.001112099644128114\n",
      "0.0011118523460084502\n",
      "0.0011116051578479323\n",
      "0.0011113580795732384\n",
      "0.0011111111111111111\n",
      "0.001110864252388358\n",
      "0.0011106175033318525\n",
      "0.0011103708638685321\n",
      "0.0011101243339253996\n",
      "0.0011098779134295228\n",
      "0.0011096316023080338\n",
      "0.0011093854004881295\n",
      "0.0011091393078970719\n",
      "0.0011088933244621868\n",
      "0.0011086474501108647\n",
      "0.0011084016847705607\n",
      "0.0011081560283687944\n",
      "0.0011079104808331486\n",
      "0.0011076650420912715\n",
      "0.0011074197120708748\n",
      "0.0011071744906997344\n",
      "0.0011069293779056896\n",
      "0.0011066843736166445\n",
      "0.0011064394777605664\n",
      "0.0011061946902654867\n",
      "0.0011059500110595002\n",
      "0.0011057054400707652\n",
      "0.001105460977227504\n",
      "0.0011052166224580018\n",
      "0.0011049723756906078\n",
      "0.001104728236853734\n",
      "0.001104484205875856\n",
      "0.0011042402826855124\n",
      "0.001103996467211305\n",
      "0.0011037527593818985\n",
      "0.0011035091591260207\n",
      "0.0011032656663724624\n",
      "0.0011030222810500773\n",
      "0.0011027790030877812\n",
      "0.0011025358324145535\n",
      "0.0011022927689594356\n",
      "0.001102049812651532\n",
      "0.0011018069634200088\n",
      "0.0011015642211940956\n",
      "0.0011013215859030838\n",
      "0.001101079057476327\n",
      "0.001100836635843241\n",
      "0.001100594320933304\n",
      "0.0011003521126760564\n",
      "0.0011001100110011\n",
      "0.0010998680158380994\n",
      "0.0010996261271167802\n",
      "0.0010993843447669306\n",
      "0.0010991426687183997\n",
      "0.001098901098901099\n",
      "0.001098659635245001\n",
      "0.0010984182776801407\n",
      "0.0010981770261366132\n",
      "0.0010979358805445762\n",
      "0.0010976948408342481\n",
      "0.0010974539069359087\n",
      "0.0010972130787798991\n",
      "0.0010969723562966214\n",
      "0.0010967317394165387\n",
      "0.0010964912280701754\n",
      "0.0010962508221881166\n",
      "0.0010960105217010083\n",
      "0.0010957703265395574\n",
      "0.0010955302366345311\n",
      "0.001095290251916758\n",
      "0.0010950503723171265\n",
      "0.0010948105977665863\n",
      "0.0010945709281961471\n",
      "0.001094331363536879\n",
      "0.0010940919037199124\n",
      "0.0010938525486764385\n",
      "0.0010936132983377078\n",
      "0.0010933741526350316\n",
      "0.0010931351114997813\n",
      "0.001092896174863388\n",
      "0.0010926573426573427\n",
      "0.0010924186148131964\n",
      "0.00109217999126256\n",
      "0.0010919414719371041\n",
      "0.001091703056768559\n",
      "0.0010914647456887142\n",
      "0.0010912265386294195\n",
      "0.0010909884355225835\n",
      "0.0010907504363001745\n",
      "0.0010905125408942203\n",
      "0.0010902747492368076\n",
      "0.0010900370612600828\n",
      "0.001089799476896251\n",
      "0.0010895619960775767\n",
      "0.0010893246187363835\n",
      "0.0010890873448050533\n",
      "0.0010888501742160278\n",
      "0.001088613106901807\n",
      "0.00108837614279495\n",
      "0.001088139281828074\n",
      "0.0010879025239338555\n",
      "0.0010876658690450293\n",
      "0.001087429317094389\n",
      "0.0010871928680147858\n",
      "0.0010869565217391304\n",
      "0.0010867202782003911\n",
      "0.0010864841373315949\n",
      "0.0010862480990658267\n",
      "0.0010860121633362294\n",
      "0.0010857763300760044\n",
      "0.0010855405992184109\n",
      "0.0010853049706967658\n",
      "0.0010850694444444445\n",
      "0.0010848340203948796\n",
      "0.0010845986984815619\n",
      "0.0010843634786380394\n",
      "0.0010841283607979184\n",
      "0.0010838933448948623\n",
      "0.001083658430862592\n",
      "0.0010834236186348862\n",
      "0.0010831889081455806\n",
      "0.0010829542993285683\n",
      "0.0010827197921178\n",
      "0.001082485386447283\n",
      "0.0010822510822510823\n",
      "0.0010820168794633195\n",
      "0.0010817827780181739\n",
      "0.001081548777849881\n",
      "0.0010813148788927337\n",
      "0.001081081081081081\n",
      "0.00108084738434933\n",
      "0.001080613788631943\n",
      "0.00108038029386344\n",
      "0.001080146899978397\n",
      "0.0010799136069114472\n",
      "0.0010796804145972792\n",
      "0.001079447322970639\n",
      "0.0010792143319663286\n",
      "0.0010789814415192059\n",
      "0.0010787486515641855\n",
      "0.0010785159620362382\n",
      "0.0010782833728703904\n",
      "0.0010780508840017248\n",
      "0.0010778184953653806\n",
      "0.0010775862068965517\n",
      "0.0010773540185304892\n",
      "0.001077121930202499\n",
      "0.001076889941847943\n",
      "0.0010766580534022395\n",
      "0.001076426264800861\n",
      "0.001076194575979337\n",
      "0.0010759629868732515\n",
      "0.0010757314974182443\n",
      "0.0010755001075500108\n",
      "0.001075268817204301\n",
      "0.0010750376263169211\n",
      "0.0010748065348237317\n",
      "0.001074575542660649\n",
      "0.0010743446497636442\n",
      "0.0010741138560687433\n",
      "0.0010738831615120276\n",
      "0.001073652566029633\n",
      "0.00107342206955775\n",
      "0.0010731916720326251\n",
      "0.001072961373390558\n",
      "0.001072731173567904\n",
      "0.0010725010725010724\n",
      "0.001072271070126528\n",
      "0.001072041166380789\n",
      "0.0010718113612004287\n",
      "0.0010715816545220746\n",
      "0.0010713520462824085\n",
      "0.0010711225364181663\n",
      "0.0010708931248661383\n",
      "0.0010706638115631692\n",
      "0.001070434596446157\n",
      "0.0010702054794520547\n",
      "0.0010699764605178687\n",
      "0.001069747539580659\n",
      "0.0010695187165775401\n",
      "0.00106928999144568\n",
      "0.0010690613641223007\n",
      "0.0010688328345446773\n",
      "0.0010686044026501388\n",
      "0.0010683760683760685\n",
      "0.0010681478316599017\n",
      "0.0010679196924391287\n",
      "0.001067691650651292\n",
      "0.001067463706233988\n",
      "0.0010672358591248667\n",
      "0.0010670081092616305\n",
      "0.0010667804565820354\n",
      "0.0010665529010238908\n",
      "0.0010663254425250586\n",
      "0.0010660980810234541\n",
      "0.0010658708164570454\n",
      "0.0010656436487638534\n",
      "0.001065416577881952\n",
      "0.0010651896037494673\n",
      "0.0010649627263045794\n",
      "0.0010647359454855196\n",
      "0.0010645092612305727\n",
      "0.0010642826734780758\n",
      "0.0010640561821664183\n",
      "0.0010638297872340426\n",
      "0.0010636034886194426\n",
      "0.0010633772862611655\n",
      "0.00106315118009781\n",
      "0.0010629251700680273\n",
      "0.0010626992561105207\n",
      "0.0010624734381640458\n",
      "0.0010622477161674102\n",
      "0.0010620220900594733\n",
      "0.0010617965597791463\n",
      "0.0010615711252653928\n",
      "0.0010613457864572277\n",
      "0.0010611205432937182\n",
      "0.0010608953957139827\n",
      "0.0010606703436571913\n",
      "0.0010604453870625664\n",
      "0.0010602205258693808\n",
      "0.00105999576001696\n",
      "0.00105977108944468\n",
      "0.0010595465140919686\n",
      "0.001059322033898305\n",
      "0.0010590976488032196\n",
      "0.0010588733587462938\n",
      "0.0010586491636671606\n",
      "0.0010584250635055038\n",
      "0.0010582010582010583\n",
      "0.0010579771476936098\n",
      "0.0010577533319229956\n",
      "0.0010575296108291032\n",
      "0.0010573059843518714\n",
      "0.0010570824524312897\n",
      "0.001056859015007398\n",
      "0.0010566356720202875\n",
      "0.0010564124234100994\n",
      "0.0010561892691170257\n",
      "0.0010559662090813093\n",
      "0.0010557432432432433\n",
      "0.0010555203715431707\n",
      "0.001055297593921486\n",
      "0.0010550749103186326\n",
      "0.0010548523206751054\n",
      "0.001054629824931449\n",
      "0.001054407423028258\n",
      "0.0010541851149061775\n",
      "0.0010539629005059021\n",
      "0.001053740779768177\n",
      "0.001053518752633797\n",
      "0.0010532968190436064\n",
      "0.0010530749789385003\n",
      "0.0010528532322594231\n",
      "0.0010526315789473684\n",
      "0.0010524100189433804\n",
      "0.0010521885521885522\n",
      "0.001051967178624027\n",
      "0.001051745898190997\n",
      "0.0010515247108307045\n",
      "0.0010513036164844407\n",
      "0.0010510826150935463\n",
      "0.0010508617065994115\n",
      "0.0010506408909434755\n",
      "0.0010504201680672268\n",
      "0.0010501995379122034\n",
      "0.0010499790004199917\n",
      "0.0010497585555322277\n",
      "0.0010495382031905961\n",
      "0.001049317943336831\n",
      "0.001049097775912715\n",
      "0.0010488777008600798\n",
      "0.0010486577181208054\n",
      "0.0010484378276368212\n",
      "0.0010482180293501049\n",
      "0.0010479983232026828\n",
      "0.0010477787091366304\n",
      "0.001047559187094071\n",
      "0.0010473397570171764\n",
      "0.0010471204188481676\n",
      "0.0010469011725293131\n",
      "0.0010466820180029307\n",
      "0.0010464629552113854\n",
      "0.0010462439840970914\n",
      "0.0010460251046025104\n",
      "0.0010458063166701526\n",
      "0.0010455876202425764\n",
      "0.0010453690152623877\n",
      "0.0010451505016722408\n",
      "0.0010449320794148381\n",
      "0.0010447137484329294\n",
      "0.0010444955086693127\n",
      "0.0010442773600668337\n",
      "0.0010440593025683859\n",
      "0.0010438413361169101\n",
      "0.0010436234606553956\n",
      "0.001043405676126878\n",
      "0.001043187982474442\n",
      "0.0010429703796412183\n",
      "0.0010427528675703858\n",
      "0.001042535446205171\n",
      "0.0010423181154888472\n",
      "0.0010421008753647354\n",
      "0.0010418837257762034\n",
      "0.0010416666666666667\n",
      "0.0010414496979795876\n",
      "0.0010412328196584756\n",
      "0.0010410160316468874\n",
      "0.0010407993338884263\n",
      "0.001040582726326743\n",
      "0.0010403662089055348\n",
      "0.001040149781568546\n",
      "0.0010399334442595673\n",
      "0.001039717196922437\n",
      "0.0010395010395010396\n",
      "0.0010392849719393059\n",
      "0.0010390689941812137\n",
      "0.0010388531061707874\n",
      "0.001038637307852098\n",
      "0.0010384215991692627\n",
      "0.0010382059800664453\n",
      "0.0010379904504878555\n",
      "0.0010377750103777502\n",
      "0.0010375596596804316\n",
      "0.001037344398340249\n",
      "0.0010371292263015972\n",
      "0.0010369141435089175\n",
      "0.0010366991499066972\n",
      "0.0010364842454394694\n",
      "0.0010362694300518134\n",
      "0.0010360547036883548\n",
      "0.0010358400662937642\n",
      "0.001035625517812759\n",
      "0.0010354110581901014\n",
      "0.0010351966873706005\n",
      "0.0010349824052991099\n",
      "0.0010347682119205299\n",
      "0.0010345541071798054\n",
      "0.001034340091021928\n",
      "0.001034126163391934\n",
      "0.0010339123242349049\n",
      "0.0010336985734959686\n",
      "0.0010334849111202976\n",
      "0.0010332713370531101\n",
      "0.0010330578512396695\n",
      "0.001032844453625284\n",
      "0.0010326311441553077\n",
      "0.0010324179227751394\n",
      "0.001032204789430223\n",
      "0.0010319917440660474\n",
      "0.0010317787866281469\n",
      "0.0010315659170621002\n",
      "0.0010313531353135313\n",
      "0.0010311404413281089\n",
      "0.0010309278350515464\n",
      "0.0010307153164296021\n",
      "0.001030502885408079\n",
      "0.0010302905419328251\n",
      "0.0010300782859497322\n",
      "0.0010298661174047373\n",
      "0.001029654036243822\n",
      "0.0010294420424130121\n",
      "0.0010292301358583778\n",
      "0.0010290183165260341\n",
      "0.00102880658436214\n",
      "0.0010285949393128986\n",
      "0.0010283833813245578\n",
      "0.0010281719103434094\n",
      "0.0010279605263157894\n",
      "0.0010277492291880781\n",
      "0.0010275380189066995\n",
      "0.001027326895418122\n",
      "0.001027115858668858\n",
      "0.0010269049086054631\n",
      "0.001026694045174538\n",
      "0.0010264832683227264\n",
      "0.001026272577996716\n",
      "0.0010260619741432383\n",
      "0.0010258514567090685\n",
      "0.0010256410256410256\n",
      "0.001025430680885972\n",
      "0.001025220422390814\n",
      "0.001025010250102501\n",
      "0.0010248001639680262\n",
      "0.0010245901639344263\n",
      "0.001024380249948781\n",
      "0.0010241704219582138\n",
      "0.0010239606799098914\n",
      "0.0010237510237510238\n",
      "0.0010235414534288639\n",
      "0.001023331968890708\n",
      "0.0010231225700838961\n",
      "0.0010229132569558102\n",
      "0.0010227040294538761\n",
      "0.0010224948875255625\n",
      "0.0010222858311183807\n",
      "0.0010220768601798855\n",
      "0.0010218679746576743\n",
      "0.001021659174499387\n",
      "0.0010214504596527069\n",
      "0.0010212418300653595\n",
      "0.0010210332856851133\n",
      "0.0010208248264597796\n",
      "0.0010206164523372118\n",
      "0.0010204081632653062\n",
      "0.0010201999591920017\n",
      "0.0010199918400652795\n",
      "0.0010197838058331635\n",
      "0.0010195758564437193\n",
      "0.0010193679918450561\n",
      "0.0010191602119853241\n",
      "0.0010189525168127166\n",
      "0.0010187449062754685\n",
      "0.001018537380321858\n",
      "0.0010183299389002036\n",
      "0.0010181225819588678\n",
      "0.001017915309446254\n",
      "0.0010177081213108082\n",
      "0.0010175010175010174\n",
      "0.001017293997965412\n",
      "0.0010170870626525631\n",
      "0.001016880211511084\n",
      "0.0010166734444896298\n",
      "0.0010164667615368977\n",
      "0.0010162601626016261\n",
      "0.001016053647632595\n",
      "0.0010158472165786266\n",
      "0.0010156408693885843\n",
      "0.0010154346060113728\n",
      "0.0010152284263959391\n",
      "0.0010150223304912708\n",
      "0.0010148163182463973\n",
      "0.0010146103896103895\n",
      "0.0010144045445323595\n",
      "0.0010141987829614604\n",
      "0.001013993104846887\n",
      "0.001013787510137875\n",
      "0.0010135819987837015\n",
      "0.0010133765707336846\n",
      "0.0010131712259371835\n",
      "0.001012965964343598\n",
      "0.0010127607859023698\n",
      "0.001012555690562981\n",
      "0.0010123506782749544\n",
      "0.0010121457489878543\n",
      "0.0010119409026512851\n",
      "0.0010117361392148927\n",
      "0.0010115314586283633\n",
      "0.0010113268608414239\n",
      "0.0010111223458038423\n",
      "0.0010109179134654266\n",
      "0.001010713563776026\n",
      "0.0010105092966855296\n",
      "0.0010103051121438675\n",
      "0.00101010101010101\n",
      "0.0010098969905069683\n",
      "0.0010096930533117932\n",
      "0.0010094891984655764\n",
      "0.0010092854259184498\n",
      "0.0010090817356205853\n",
      "0.0010088781275221952\n",
      "0.0010086746015735323\n",
      "0.001008471157724889\n",
      "0.001008267795926598\n",
      "0.0010080645161290322\n",
      "0.0010078613182826044\n",
      "0.001007658202337767\n",
      "0.0010074551682450132\n",
      "0.001007252215954875\n",
      "0.0010070493454179255\n",
      "0.0010068465565847766\n",
      "0.0010066438494060802\n",
      "0.001006441223832528\n",
      "0.001006238679814852\n",
      "0.001006036217303823\n",
      "0.0010058338362502514\n",
      "0.001005631536604988\n",
      "0.0010054293183189222\n",
      "0.0010052271813429834\n",
      "0.0010050251256281408\n",
      "0.0010048231511254019\n",
      "0.0010046212577858146\n",
      "0.001004419445560466\n",
      "0.001004217714400482\n",
      "0.001004016064257028\n",
      "0.001003814495081309\n",
      "0.0010036130068245685\n",
      "0.0010034115994380895\n",
      "0.0010032102728731941\n",
      "0.0010030090270812437\n",
      "0.0010028078620136383\n",
      "0.0010026067776218166\n",
      "0.0010024057738572574\n",
      "0.0010022048506714773\n",
      "0.001002004008016032\n",
      "0.0010018032458425166\n",
      "0.001001602564102564\n",
      "0.001001401962747847\n",
      "0.001001201441730076\n",
      "0.001001001001001001\n",
      "0.0010008006405124099\n",
      "0.0010006003602161296\n",
      "0.0010004001600640256\n",
      "0.0010002000400080016\n",
      "0.001\n",
      "0.0009998000399920016\n",
      "0.0009996001599360256\n",
      "0.0009994003597841295\n",
      "0.0009992006394884093\n",
      "0.000999000999000999\n",
      "0.000998801438274071\n",
      "0.0009986019572598363\n",
      "0.000998402555910543\n",
      "0.0009982032341784787\n",
      "0.000998003992015968\n",
      "0.000997804829375374\n",
      "0.0009976057462090981\n",
      "0.000997406742469579\n",
      "0.000997207818109294\n",
      "0.0009970089730807576\n",
      "0.000996810207336523\n",
      "0.000996611520829181\n",
      "0.0009964129135113591\n",
      "0.0009962143853357243\n",
      "0.00099601593625498\n",
      "0.0009958175662218682\n",
      "0.0009956192751891676\n",
      "0.0009954210631096954\n",
      "0.0009952229299363057\n",
      "0.0009950248756218905\n",
      "0.0009948269001193793\n",
      "0.0009946290033817386\n",
      "0.000994431185361973\n",
      "0.000994233446013124\n",
      "0.0009940357852882703\n",
      "0.0009938382031405286\n",
      "0.0009936406995230524\n",
      "0.0009934432743890324\n",
      "0.0009932459276916965\n",
      "0.0009930486593843098\n",
      "0.0009928514694201747\n",
      "0.0009926543577526306\n",
      "0.0009924573243350536\n",
      "0.0009922603691208574\n",
      "0.000992063492063492\n",
      "0.0009918666931164452\n",
      "0.0009916699722332407\n",
      "0.00099147332936744\n",
      "0.0009912767644726407\n",
      "0.0009910802775024777\n",
      "0.0009908838684106222\n",
      "0.0009906875371507827\n",
      "0.0009904912836767037\n",
      "0.0009902951079421667\n"
     ]
    }
   ],
   "source": [
    "thetha = np.random.rand(2,1) # random initialisation\n",
    "# m is number of data points\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(thetha) - yi)\n",
    "        eta = learning_schedule(epoch * m + i )\n",
    "        print(eta)\n",
    "        thetha = thetha - eta * gradients\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdd9855f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.16864259],\n",
       "       [2.90162127]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4945180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor(eta0=0.1, penalty=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SGDRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.SGDRegressor.html\">?<span>Documentation for SGDRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">loss&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">0.15</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shuffle',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shuffle&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('epsilon',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">epsilon&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;invscaling&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eta0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eta0&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('power_t',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">power_t&nbsp;</td>\n",
       "            <td class=\"value\">0.25</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_fraction&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter_no_change&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('average',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">average&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "SGDRegressor(eta0=0.1, penalty=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempting SGD using  Scikit learn\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg= SGDRegressor(penalty=None, eta0=0.1)\n",
    "\n",
    "sgd_reg.fit(X, y.ravel()) # automatically sets for bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d6c6de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.12251434])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7b142e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.88301866])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424881c",
   "metadata": {},
   "source": [
    "\n",
    "## Polynomial Regression\n",
    "\n",
    " Surprisingly,\n",
    " you can actually use a linear model to fit nonlinear data. A simple way to do this is to\n",
    " add powers of each feature as new features, then train a linear model on this extended\n",
    " set of features. This technique is called Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91009768",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m X\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m X \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(m,\u001b[38;5;241m1\u001b[39m ) \u001b[38;5;66;03m# plotting a quadratic equation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxlabel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, let’s generate some nonlinear data, based on a simple quadratic equation\n",
    "\n",
    "m = 100\n",
    "X = 6 * np.random.rand(m, 1) - 3\n",
    "y = 0.5 * X**2 + X + 2 + np.random.randn(m,1 ) # plotting a quadratic equation\n",
    "\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2ffe197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c6a9093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # 100 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "238786c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2965691]\n",
      "[1.2965691  1.68109142]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(X_poly[0]) #  X_poly now contains the original feature of X plus the square of this feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ba1b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.85850333] [[1.05239911 0.51233175]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, y)\n",
    "print(lin_reg.intercept_, lin_reg.coef_)\n",
    "\n",
    "\n",
    "y_predicted = lin_reg.predict(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c000ea5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X, y_predicted, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxlabel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(X, y_predicted, \"r.\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3aac5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we do three degree??\n",
    "\n",
    "three_deg_poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly_three_deg = three_deg_poly_features.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d45c4f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_deg_lin_reg = LinearRegression()\n",
    "three_deg_lin_reg.fit(X_poly_three_deg, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caa4e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_three_deg = three_deg_lin_reg.predict(X_poly_three_deg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2b981b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1651c96c5b0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(X, y_pred_three_deg, \"r.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15b6defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_two_deg = mean_squared_error(y, y_predicted)\n",
    "mse_three_deg = mean_squared_error(y, y_pred_three_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72f1dd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two deg error  1.1582043220768932\n",
      "three deg error  1.1565375295123934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._base.LinearRegression"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"two deg error \", mse_two_deg)\n",
    "print(\"three deg error \", mse_three_deg)\n",
    "LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5f82d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deciding on complexity of the model\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def plot_learning_curves(model, X: np.array, y: np.array, title: str): # training set = validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    \n",
    "    for m in range(1, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        \n",
    "        train_errors.append(rmse(y_train[:m], y_train_predict))\n",
    "        val_errors.append(rmse(y_val, y_val_predict))\n",
    "        \n",
    "        \n",
    "    plt.plot(train_errors, \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(val_errors, \"b-\", linewidth=3, label=\"val\")\n",
    "    plt.ylabel = \"RMSE\"\n",
    "    plt.xlabel = \"Training Set size\"\n",
    "    plt.title(title)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf39d816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "plot_learning_curves(lin_reg, X, y, \"Linear Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01348cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let’s look at the learning curves of a 10th-degree polynomial model on the same data\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "poly_regression = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=10, include_bias=False)),\n",
    "    (\"lin_reg\", LinearRegression())\n",
    "])\n",
    "\n",
    "plot_learning_curves(poly_regression, X, y, \"10 degree Polynomial Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f7f7a3",
   "metadata": {},
   "source": [
    "## One way to improve an overfitting model is to feed it more training\n",
    "## data until the validation error reaches the training error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e41b47",
   "metadata": {},
   "source": [
    "# Regularisation\n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    " adding a penalty term... means minimising the loss function and the values of weights also"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bcae3",
   "metadata": {},
   "source": [
    "#### in linear regression, you can perform Ridge regularisaation using\n",
    "1. closed form soln (like normal equation of linear regression)\n",
    "2. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e9ef3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.44213355])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Closed form Solution Ridge Regression\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg= Ridge(alpha=1, solver=\"cholesky\")\n",
    "ridge_reg.fit(X,y)\n",
    "ridge_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cce3654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.44704233])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Stochastic Gradient descent\n",
    "\n",
    "sgd_reg_with_ridge = SGDRegressor(penalty=\"l2\", max_iter=5000, eta0=0.01) # l2 means square of weights is added (ridge).. l1 means absolutbe weights are added (lasso)\n",
    "sgd_reg_with_ridge.fit(X, y.ravel())\n",
    "\n",
    "sgd_reg.predict([[1.5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66a37bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.70799179]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "sgd_reg = make_pipeline(\n",
    "    StandardScaler(),  # Feature scaling is crucial\n",
    "    SGDRegressor(\n",
    "        penalty=\"l2\",     # Ridge\n",
    "        alpha=1.0,        # Match alpha with Ridge\n",
    "        max_iter=5000,    # More iterations\n",
    "        tol=1e-5,         # Allow tighter convergence\n",
    "        # learning_rate='constant',\n",
    "        eta0=0.01,        # Learning rate\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "print(sgd_reg.predict([[1.5]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae21bdf",
   "metadata": {},
   "source": [
    "####  Lasso Regression automatically performs feature selection and outputs a sparse model (i.e., with few nonzero feature weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7c10296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.385411])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg  = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(X, y)\n",
    "\n",
    "lasso_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d5352",
   "metadata": {},
   "source": [
    " So when should you use plain Linear Regression (i.e., without any regularization),\n",
    " Ridge, Lasso, or Elastic Net? It is almost always preferable to have at least a little bit of\n",
    " regularization, so generally you should avoid plain Linear Regression. Ridge is a good\n",
    " default, but if you suspect that only a few features are actually useful, you should pre\n",
    "fer Lasso or Elastic Net since they tend to reduce the useless features’ weights down to\n",
    " zero as we have discussed. In general, Elastic Net is preferred over Lasso since Lasso\n",
    " may behave erratically when the number of features is greater than the number of\n",
    " training instances or when several features are strongly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19b41b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.39094628])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementing elastic net\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5) # alpha = a + b and l1_ratio = a / (a + b)\n",
    "elastic_net.fit(X, y)\n",
    "elastic_net.predict([[1.5]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0f674",
   "metadata": {},
   "source": [
    "## “beautiful free lunch.” or Early stopping\n",
    "\n",
    "jaise hi minimum RMSE aa jaye on validation dataset then rok doo!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6636b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# implementation of early stopping\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "poly_scaler = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=90, include_bias=False)),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "    \n",
    "])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "X_train_poly_scaled = poly_scaler.fit_transform(X_train)\n",
    "X_val_poly_scaled = poly_scaler.transform(X_val)\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=1, warm_start=True, penalty=None, learning_rate=\"constant\", eta0=0.0005)\n",
    "\n",
    "# When set to True, reuse the solution of the previous call to fit as\n",
    "#         initialization, otherwise, just erase the previous solution.\n",
    "\n",
    "minimum_val_error = float(\"inf\")\n",
    "best_epoch = None\n",
    "best_model = None\n",
    "for epoch in range(1000): ## 1000 baar train krke dekhein ?? \n",
    "    sgd_reg.fit(X_train_poly_scaled, y_train) # continues where it left off, maybe due to warm_start is true\n",
    "    y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
    "    val_error = mean_squared_error(y_val, y_val_predict)\n",
    "    \n",
    "    if val_error < minimum_val_error:\n",
    "        minimum_val_error = val_error\n",
    "        best_epoch = epoch\n",
    "        best_model = clone(sgd_reg)\n",
    "    \n",
    "\n",
    "#  Note that with warm_start=True, when the fit() method is called, it just continues\n",
    "#  training where it left off instead of restarting from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a1bd55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(sgd_reg, \"best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "607ec3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = joblib.load(\"best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c45c7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted = best_model.predict(X_val_poly_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7f12c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.9179691 ],\n",
       "       [3.39105158],\n",
       "       [1.73185468],\n",
       "       [3.78728581],\n",
       "       [2.17751153],\n",
       "       [3.37024214],\n",
       "       [1.5064665 ],\n",
       "       [1.723903  ],\n",
       "       [0.71468234],\n",
       "       [1.39714798],\n",
       "       [1.6330199 ],\n",
       "       [8.65984353],\n",
       "       [4.93360203],\n",
       "       [2.15790449],\n",
       "       [1.1063407 ],\n",
       "       [3.88115093],\n",
       "       [4.19479779],\n",
       "       [1.69604577],\n",
       "       [3.26672112],\n",
       "       [4.29822017]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28e9366e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8074488520755727"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_val, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e84a64",
   "metadata": {},
   "source": [
    "#### LOGiSTIC REGRESSION\n",
    "\n",
    "1. a regression which does classification\n",
    "2. calculates probabilty of belonging to a particular class\n",
    "3. just give predicted value (thetha transpose x) to sigmoid function and it will spit out a probabiltiy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f645a",
   "metadata": {},
   "source": [
    "#### cost function for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8f50417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "print(list(iris.keys()))\n",
    "\n",
    "# 4 features - sepal length, sepal width, petal length, petal width\n",
    "# classes - 0,1,2 --> iris setosa, iris versicolor, iris verginica\n",
    "\n",
    "## prob: train a logistic regression classifer to predict wether a flower is iris verginica or not\n",
    "\n",
    "X = iris[\"data\"][:, 3: ] # petal width only\n",
    "y= (iris[\"target\"] == 2).astype(np.int8)\n",
    "\n",
    "print(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0828b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61c4ff57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e6810bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Probability')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using matplotlib for visuallisation\n",
    "from importlib import reload\n",
    "plt =reload(plt)\n",
    "\n",
    "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y_prob = clf.predict_proba(X_new)\n",
    "plt.plot(X_new, y_prob[:, 1], \"g-\", label=\"virginica\")\n",
    "plt.plot(X_new, y_prob[:, 0], \"b--\", label=\"Non virginica\") \n",
    "\n",
    "plt.xlabel(\"Petal width(cm)\")\n",
    "plt.ylabel(\"Probability\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
