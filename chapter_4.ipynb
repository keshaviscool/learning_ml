{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d90fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12014f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Haha')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAALFtJREFUeJzt3QmQlMX5x/FnOQREQEQRkEOOVVQERdQSzd8VkFUJpZWKRguIIShEMYoHHlXxwCMcQYxYiKAoqBwhKh6JisohUVAU1CBeoJwiUl4cIqi777+e3sw6O+wx99vd7/dTNTU7s7Oz7zvv7L6/6X66uyAIgkAAAAAcVCvsDQAAAEgXQQYAADiLIAMAAJxFkAEAAM4iyAAAAGcRZAAAgLMIMgAAwFl1xHOlpaWyZcsWadSokRQUFIS9OQAAIAk6zd3OnTulVatWUqtWregGGQ0xbdq0CXszAABAGjZt2iStW7eObpDRlpjYC9G4ceOwNwcAACRhx44dpiEidh6PbJCJdSdpiCHIAADglprKQij2BQAAziLIAAAAZxFkAACAswgyAADAWQQZAADgLIIMAABwFkEGAAA4iyADAACcRZABAADOIsgAAABnEWQAAICzCDIAAETM5s0iixaVXbuOIAMAQIRMmybSrp1Ir15l13rbZQQZAAAiYvNmkaFDRUpLy27r9bBhbrfMEGQAAIhIV9CaNb+EmJiSEpG1a8VZBBkAACLSFVRYKFIr4cxfu7ZIp07iLIIMAAAR6Qpq3Vpk6tSy8KL0esqUsvtdVSfsDQAAAKl3BaUbPoYMESkuLnsObYlxOcQoggwAAJaKdQXFh5lsdAW1bu1+gImhawkAAEv52BWUbbTIAABgMd+6grKNIAMAgOV86grKNrqWAACAswgyAADAWQQZAADyyKcFG21AkAEAIE98W7DRBgQZAADywMcFG21AkAEAIA98XLDRBgQZAIgw6jXyx8cFG21AkAGAiKJeI7+YpTc3CoIgCMRjO3bskCZNmsj27dulcePGYW8OAFhBW2A0vCSu4bN+PSfWfLz2zNKbvfM3M/sCQATlYlVlJIdZerOLriUAiCDqNeALggwARBD1GvAFXUsAEFGsqgwfEGQAIMKo14Dr6FoCAADOIsgAAABnEWQAAICzCDIAAMBZBBkAAOAsggwAAHAWQQYAADiLIAMAAJxFkAEAABVW5160qOzaBaEGmSVLlkj//v2lVatWUlBQIE8//XSF7wdBILfccou0bNlSGjRoIH369JE1umQrAMBrrp1MfTFtmki7diK9epVd623bhRpkvv/+e+nWrZtMmjSp0u+PGzdOJk6cKA888IC8+eab0rBhQykuLpY9e/bkfVsBAPnh4snUB5s3iwwdKlJaWnZbr4cNsz9MFgTa7GEBbZGZN2+enHfeeea2bpa21Fx77bVy3XXXmfu2b98uhx56qEyfPl0uvPDCpJ53x44d0qRJE/OzjRs3zuk+AAAyoydNDS+xk2lsZe7161kTKtcWLSoLj5XdX1SU/+1J9vxtbY3MunXrZOvWraY7KUZ36OSTT5Zly5ZV+XN79+41Ox9/AQC4QasH4kOMKikpW6EbuVVYKFIrIRVoiNSV0W3uArQ2yGiIUdoCE09vx75XmdGjR5vAE7u0adMm59sKAAjvZIrs0BavqVPLXm+l11OmVN0SZksXoLVBJl033XSTaYaKXTZt2hT2JgEAcnQyRXYNGVLWjaetLHqtt22vp6kjlmrRooW5/vLLL82opRi9fdxxx1X5c/Xq1TMXAICb9ORZXFzWnaQtMYSY/GrduubXvLouwHwfL2tbZNq3b2/CzIIFC8rv03oXHb10yimnhLptAIDc0pOhFpgSYuxUaFEXYKhBZteuXfLuu++aS6zAV7/euHGjGcU0YsQIufPOO+XZZ5+VVatWye9//3szkik2sgkAAES7CzDU4deLFy+WM844Y5/7L774YjPEWjft1ltvlalTp8p3330np512mtx///1yxBFHJP07GH4NAEBuaE1MrroAkz1/WzOPTK4QZAAAcI/z88gAAJBNNsx5guwjyAAAvJfPOU8ITPlFkAEAeC2fc57YMklclBBkAABey9eyBzZNEhclBBkAgNfyNecJ60SFgyADAPBaunOepFrrYtMkcVFCkAEAeC/ZNYQyqXWxaZK4KGEeGQAA4mgLjIaX+G4iDSUagJIJJbmcJC5KdiR5/rZ20UgAAMKQ6YKIySy6mCubN5dtv3ZzRSVE0bUEAIAHtS7TIjr0myADAIDjtS6bIzz0m64lAAASaDFwcXH+al0y7RJak2F3mMtokQEAoBIaAIqKch8EkukSqmkoeKGj3WHZQJABAMDiLqFkgk5rB7vDsoUgAwBASGqaDTiV2pchKc6V4wtqZAAACEmsSyhxzppYl1CqtS+tQxz6HRZaZADAIalOmw+71dQlFOXal2QRZADAEVGdJ8R31XUJRbn2JVksUQAAEZg2H26L4rIHO1iiAAD8EeV5QhDN2pdk0bUEIG+o70j/9aFWAqgcQQZAXlDfkdrrM3JkxUBDrQRQOWpkAIRW37FsmciuXdFaqTfZ10cVFIg8+GDF4s8o1kogmnYkef6mRQZAaPUdJ59MC01Vr4/Sj5mJk5/la9p8wBUEGQA5V1l9h4q1B0dppd5UXp/EWV4B7IsgAyDnEus7KjtpR/mEnfj6xKOgF6geQQZA3if9euMNRuBU9fpcd90vrw0FvUjW5giPCCTIAMibWH3HiScyAqcyuv9/+5vIhg3RW/gP6ZsW8RGBjFoCEBpG4ACZ2ezxjM/M7AvAesxWCmRmDTM+07UEAICrCpnxmSADAGGIcnEmsqc1Mz4TZAAg36JenIncjQhcH8ECcYp9ASCPfC7O1H3Tmo2oLzmB7GCJAgBwrDjTZbQyISwEGQDIIx+LM7UlZujQXwJa1JecQH4RZAAgj3wszvS1lSmXKPbOHoIMAOSZb8WZPrYy5RLdcNlFkAGAEJdrsKElJtPWAR9bmXKFbrjsI8gAQIRlq3XAt1amXKEbLvsYfg0AEeXzUHBb8Zonj+HXAIBq0TqQf3TDZR+LRgJARMWKdBNbByjSzS3tdisuZuX3bKFFBgAiitaB8NhU7O06WmQAIMKSbR1g+YH84bVODS0yABBxNbUOMO9J/vBap45RSwCAKjHKJn94rSti1BIAIGOMbMofXuv0EGQAAFVi+YH84bVOD0EGAFAlRjblD691eqiRAQAkVb/BvCf5wWud2vmb4dcAgBrpCTXKJ9V84rVODV1LAAA4vgJ5lBFkAFiPf/LwGXPHZIYgA8Bq/JOHzzScDx36y7BrvR42jNCeCoIMAGvxTx6+t9Axd0zmCDIArMU/efjeQsfcMZkjyACwlo//5MNqTfChFcPHFjrmjskcQQaAtXz7Jx9Wa4IvrRi+ttDpCuS6npIGTb3W20geE+IBsJ4PE4SFtSCgTwsR+rQvqBmLRgLwhp6kioqqP1nZ3nUSVmuCT60YvrXQITsIMgCc50LXSVj1Ptn4vTaFRLphMrfZouOZDQQZAE5zpQA0360JsZOVyuT32hgSk2mh8/GEnQ3TLDyemaJGBoDT9ESl/5Qru19PdlGs99GTUyzcaWuMBpni4tR/r8s1KZW9BlFvvdns2PGkRgZAJLg2RDvZ1oRst1CpVH+vq/U1rrTS5dsaR49nTQgyAJxGAWjuTlaVhUT19ttiNV9P2FEL/ckiyABwHgWguTlZaRgcM2bf+2+80e7WDV9P2Jlq7WnoJ8gA8EIuu2xcKhrN9smqR49977O9dcPXE3Y2DPEw9FPsCwAeFo1mq6jYtQJR3yZSjLIdSZ6/CTIAMjpRaD2CNuX7eKJw+SSe7TCnxbLaEhNr3XAhzMFtXoxaKikpkZtvvlnat28vDRo0kI4dO8odd9whnmcvwAk+zkeRiKJRf7sjbOZSV6YN6ojFxo4dK5MnT5YZM2bIMcccI2+//bYMHjzYJLQrr7wy7M0DIquq4a06V4lPLRWxotHEFpkoFo3qcfXp2NrK1a7MMFndIrN06VI599xzpV+/fnL44YfLb3/7W+nbt68sX7487E0DIi0qLRUUjSKfmP/GwyDTs2dPWbBggXzyySfm9nvvvSevvfaanH322VX+zN69e02/WvwFQHZFaXgr3SrIl6h8QIhU19KNN95ogkjnzp2ldu3apmbmrrvukgEDBlT5M6NHj5ZRo0bldTuBqIm1VCQWgPraUkG3CvKBrkwPW2Tmzp0rM2fOlFmzZsnKlStNrcz48ePNdVVuuukmU+Ecu2zatCmv2wxEBS0VQHbRlZkeq4dft2nTxrTKDB8+vPy+O++8Ux5//HH56KOPknoOhl8DsInvQ9aROea/8Wj49e7du6VWQke8djGVJnYiAoADojBkHfYvLOobq2tk+vfvb2pi2rZta4Zfv/POOzJhwgT54x//GPamAUBKojJkHcg3q4PMfffdZybEu/zyy2Xbtm3SqlUrGTZsmNxyyy1hbxoAZG1ECkEG8LRGJhuokQFgA5Y7ACJYIwMAvmBEChDBriUA8IkOUdeamFyOSGFUFKKGFhkAcGxESlWLCjIqClFEkAE8xiq6/qkqrLBOD6KKIAN4ik/n/qkurLBOD6KKIAN4iE/nfqourERpIU8gHkEG8BCfzv1UXVhhVBSiiiADeIhP536qKaywkCeiiOHXgMcnPO1O0pYYPp1HZwi33uY4I0qY2RfwGKvoAvD9/E2LDOAxnz+dM/EbAEWNDADnMLQcQAxBBogY1yfJY2g5gHgEGSBCfGjJiMLQctfDJpBPBBkgInxpyfB9aLkPYRPIJ4IMEBGZtmTY0krg88RvvoRNIJ8IMkBEZNKSYVsrga8Tv0Wh2wzINoIMEBHptmTY2kqg211U5EdLTFS6zcJmS6sisosgA0RIOi0ZtBLkj8/dZmGzrVUR2cPMvgCqpZ9e9R9/fJjRE6wGIU6wucGMzNnFe9jv8zctMgCqRStB/vnYbRYmWhX9xhIFADJeqBBwofYosUWG2iM/0CIDICm0EsBVtCr6jRYZAID3aFX0F0EGABAJPq8GH2V0LQEAAGcRZOA1JsACAL8RZOAtJsCKDgIrEF0EGXjJ1mn1kX0EViDaCDLwEhNgRQOBFQBBBl5i8b1oILACyDjI7Nmzx6yHEH8BwsYEWNFAYAWQVpDZvXu3XHHFFdK8eXNp2LChNG3atMIFcHWl5yjxoUCWwOrvsQVyGmRGjhwpCxculMmTJ0u9evXkoYceklGjRkmrVq3k0UcfTecpgZxgWn3/C2SjHlgTQ4tPxxZIRkEQBIGkqG3btiawFBUVmaW1V65cKZ06dZLHHntMZs+eLc8//7y4tgw4EBV6wtMTXOICehoCshH49Pm1dkW7fQiQuaUhJVbsrF1sY8eK3HBD7o4tYOP5O60WmW+++UY6dOhgvtYn19vqtNNOkyVLlqS7zYBzzeU2blOYBbK0BoQ7YisxxCR7bF18HwMZBRkNMevWrTNfd+7cWebOnWu+fu655+TAAw9M5ykB506QudqmXJ9UclUgy1Do8AOp3i4oSO3Y2vi3BeQ8yAwePFjee+898/WNN94okyZNkvr168vVV19t6meAbLLxBJmrbcrHSSVXBbIMhc6vqgKpdi8le2xt/NsC8lIjk2jDhg2yYsUKUyfTtWtXsQk1Mu7T1gk9sVd2vxby+rJNua5dqez3acjQT+vZqo3J5/ajLOhq8NDAGAstWuyc7LG18W8LSPX8XUeyoF27duYC5PKTZ+IJMsy5QnKxTdW1aOQiCOhzZvN5Yy09iSdWQkzuaGgpLt43tCR7bG382wJSlXaQWbBggbls27ZNShP++z788MPpPi2wDxtPkLnYJh9OKlWdWJE7mQRSG/+2gLx0LemcMbfffrv06NFDWrZsKQUJ1WXz5s0TW9C15I9sd4XYuE1VdRXAfi4PO7fxbwvYkeT5O60go+Fl3LhxMmjQILEdQQau4aTi/nwu2spBAAUsDjLNmjWT5cuXS8eOHcV2BBkAuUSRM+DghHiXXHKJzJo1K5PtA5BFTGgWHoadA44U+15zzTXlX2tx79SpU+WVV14xw63r1q1b4bETJkzI7lYCOeByTYPr3Rq+vPa+FGkDLku6a+mMM85I7gkLCsyCkragawm+nPx96dbw5bWPR5E24FiNjEsIMvDh5O/LhGY+vfaJKNIGHJ4QD3BJvieeyyXXujV8eu1zPcEggOSkHWTefvtts1jkxo0b5ccff6zwvaeeeirdpwVyzrWTv20TmmVS3+LTaw/ADmmNWpozZ4707NlTPvzwQzP53U8//SSrV682tTHaDATYLFeLJoZFazG0a0a7k/Q6l7UZmS5q6dtrDyB8adXI6EilYcOGyfDhw6VRo0ZmJez27dub+3SyPJ351xbUyMCFmgYXRvFks77FptfeJi68DwAv5pH59NNPpV+/fubr/fbbT77//nszWunqq682w7IBF+iJQgtiwz5hZNrK4eJ8Kba89jZx5X0A2CatINO0aVPZuXOn+fqwww6T999/33z93Xffye7du7O7hZ5iAjMoPf6xochKr7Xexcb3Ray+JR71LdF7HwBeBJn/+7//k5dfftl8ff7558tVV10ll156qVx00UXSu3fvbG+jd/jkBRdnhaW+JXdceh8AXtTIfPPNN7Jnzx5p1aqVmeVXF5BcunSpFBYWyl/+8hfTYmML22pkfJ5HA9F4P1Dfkn0uvg8AJ+eR0Sc1P1SnjhxwwAHlty+//HJzQbTn0YAbw6czxXwp2efi+wBwskWmVq1apqi3JiX6l2gJWmTgwqgUWjmgeB8AOW6RWaTVqf+j+eecc86Rhx56yBT8Ijl88oqu6tYYopUDivcBkLqM1lqKzSHToUMHsZVtLTIxfPKKFlriACA1rLVkOT55RQu1UQBg0fBrRA/z3mSGOVgAwNIgk0zxL9zGvDeZYw4WALCgRuY3v/lNhdvPPfec9OrVSxo2bGjt6te21si4wvXaDtvWrvGhNsq21xSAn3JSI5O4svXAgQPT30I4weXajupGCYXF9dooG19TANGW0aglF9AiE80WGVe322a8pgC8Wf0a0eFqbQdr12QfrykAGzH8GjXSroPiYrdqO2KjhBJbDxgllD5eUwA2okUGSdHwUlTkRohxuSXJZrymAGxEjQy8HjHjwygh2/CaAsgHb2pkPv/8czM6qlmzZtKgQQM59thj5e233w57s+DIfDb5bkmKwsSBrrXOAfCb1UHm22+/lVNPPVXq1q0rL7zwgnzwwQdy9913S9OmTcPeNOSZBoPYsF+l17rwpk2BIdWgFYXQAwCRLvYdO3astGnTRh555JHy+9q3bx/qNiEcts9nU1XQ0iLpyraP+VgAIAItMs8++6z06NFDzj//fGnevLkcf/zx8uCDD1b7M3v37jX9avEXuM/2tYpSGZrsQusSALjC6iDz2WefyeTJk6WwsFDmz58vl112mVx55ZUyY8aMKn9m9OjRpjgodtEWHbjP9hEzqQQt5mMBgIiMWtpvv/1Mi8zSpUvL79Mg89Zbb8myZcuqbJHRS4y2yGiYYdSSH7TVQg+9vmt79rQnyMS6i7RlRUNJLGhV1l3EDLkAEJFRSy1btpSjjz66wn1HHXWUbNy4scqfqVevntnh+Av8MX++yIUXivzud/atxK2hRcOIFvDqdVU1L7a3LgGAS6wu9tURSx9//HGF+z755BNpp2cwRE6qBbU2Lwrp4mzJAGAjq4PM1VdfLT179pS//vWvcsEFF8jy5ctl6tSp5oLosX3kUtRWwgYAG1jdtXTiiSfKvHnzZPbs2dKlSxe544475O9//7sMGDAg7E1DCGwfuQQAyD+ri32zgSUK/JJsQa3tSycAACJQ7AukW1Cbz9lz01k6AQCQHbTIwFv5mD2XodQAkBu0yCDS8jV7LpPbAUC4CDLwUr4CBgXIABAuggy8lK+AweR2ABAuggy8lM+AkWoBMgAgeyj2hde0JobZcwHA3/O31TP7Apli9lwA8BtdSwAAwFkEGQAA4CyCjMfyMastAABhIsh4Gk6YNh8AEAUEGYckG07yNastAABhI8g4IpVwwrT5AICoIMg4IpVwwrT5AICoIMg4IpVwwrT5AICoIMg4ItVwwrT5AIAoYIkCxzDlPgAgCnawRIGfmHIfAIBf0LUEAACcRZABAADOIsgAAABnEWQAAICzCDIAAMBZBBkAAOAsggwAAHAWQQYAADiLIAPv6OzHujRDZSuDAwD8QpCBV6ZNE2nXTqRXr7JrvQ0A8BdBBt7QFpihQ0VKS8tu6/WwYbTMAIDPCDJpovvCPmvW/BJiYkpKyhbZBAD4iSCTBrov7AyQhYUitRLe0bVrl60UXtPPAgDcRJBJEd0X9gZIXRV86tSy8KL0esqUsvsJnwDgp4IgCALx2I4dO6RJkyayfft2ady4ccbPp5/o9WRY2f1FRRk/PaqgQVEDSHzXkQaV9evLgkriY7U7SVti9Hup/CwAwK3zNy0yKaqp+wLh179oONFQGQsp1M5Uje42AK4jyKSouu4L2BkgCZ+Vo7sNgA8IMmkYMqSsW0I/yeq13k4Wn4DzHyAJn/ui1guAL6iRySP9xBs7eWgLgZ5cUwlB6dKTk3avaMtEZSfvmr5vk8T6l3z9rG+o9QJgO2pkLBPWJ+Caug9c615IrH/J18/6hu42AL4gyORJGAWnNYUnuheii+42AL4gyHj8Cbim8MRonmjLpNYLAGxBkPH4E3BN4YnuBdDdBsB1BBmPPwHXFJ7oXgAAuI5RSxFQ02gdRvMAAFw9f9fJ61YhFBpOqgsoNX0fAABb0bUEAACcRZABAADOIsgAlWApCQBwA0HGc5yQU+fabMcAEGUEGY9xQk4dsx0DgFsIMp7ihJweZjsGALcQZDzFCTk9zHYMAG4hyHiKE3J6mO0YANxCkPGUjSdkVwqPWUwRANzBEgWes2X5AS00jtXsaEuRhiwCAgAg0/M3QQZ5CVM6aiq+ZkdbiLS1gy4bAEAm52+6lpBzFB4DAHKFIIOco/AYAJArBBnLuFIQ63rhMQDADwQZi/g8Ey8jgQAAuUCxb8QLYvX3ag2Ldv/QQgIAsAXFvo51BYVREOtzCxAAIBoIMpYEgXwXxLIWEwDABwQZS4JAvgtiGRINAPBBnbA3wFXVBYF0w4cWwBYX52cm3lgLUGJNDkOiAQAuoUUmi11B6q23MnteDS9FRbkvvGVINADAB4xaysD48SIjR1a8z7Wp921ZiwkAgHTO33QtZeCEE/a9L9PupXzT7XRlWwEASETXUgaYeh8AgHARZDJAnQkAAOFyKsiMGTNGCgoKZMSIEWILpt4HACA8ztTIvPXWWzJlyhTp2rWruFZnwjIAAABEuEVm165dMmDAAHnwwQeladOm4hKWAQAAIOJBZvjw4dKvXz/p06dPjY/du3evGbIVfwkLywAAABDxIDNnzhxZuXKljB49OqnH6+N03Hns0qZNGwkLywAAABDhILNp0ya56qqrZObMmVK/fv2kfuamm24yk+fELvocYWF4NgAAEQ4yK1askG3btkn37t2lTp065vLqq6/KxIkTzdcl2ryRoF69emYGwPhLWBieDQBAhEct9e7dW1atWlXhvsGDB0vnzp3lhhtukNqxhGCh2EglXQRSh2WzDAAAABELMo0aNZIuXbpUuK9hw4bSrFmzfe63iY5MihX5ateStsowvwwAABHrWnJRrkcq6fPo5HuMfAIAwPIWmcosXrxYbFbdSKVMu5Vo6QEAoCJaZBwZqcScNAAA7Isg48hIJeakAQDAg64lF2h3j45WyuZIpVhLT3yYYU4aAEDU0SKTIxpeioqyN9yaOWkAANgXLTIetPSwujYAIKpokXG8pYfVtQEAUUaQcRgjmQAAUUeQcRgjmQAAUUeQcRirawMAoo4g4zBGMgEAoo5RS47LxZw1AAC4giDjAQ0vBBgAQBTRtQQAAJxFkAEAAM4iyAAAAGcRZAAAgLMIMgAAwFkEGQAA4CyCDAAAcBZBBgAAOIsgAwAAnEWQAQAAziLIAAAAZxFkAACAswgyAADAWQQZAADgLIIMAABwFkHGE5s3iyxaVHYNAEBUEGQ8MG2aSLt2Ir16lV3rbQAAooAg4zhtgRk6VKS0tOy2Xg8bRssMACAaCDKOW7PmlxATU1IisnZtWFsEAED+EGQcV1goUivhKNauLdKpU1hbBABA/hBkHNe6tcjUqWXhRen1lCll9wMA4Ls6YW8AMjdkiEhxcVl3krbEuBhitKZHu8m0hcnF7QcAhIMWGU/oyb+oyM0QwKgrAEC6CDIIFaOuAACZIMggVIy6AgBkgiCDUDHqCgCQCYIMQsWoKwBAJhi1hND5MOoKABAOggysoOGFAAMASBVdSwAAwFkEGQAA4CyCDAAAcBZBBgAAOIsgAwAAnEWQAQAAziLIAAAAZxFkQqQLIy5axAKJAACkiyATkmnTRNq1E+nVq+xabwMAgNQQZEKgLTBDh/6y6rNeDxtGywwAAKkiyIRgzZpfQkxMSUnZWkMAACB5BJkQFBaK1Ep45XXVZ10wEQAAJI8gEwJdHHHq1LLwovR6yhQWTQQAIFWsfh2SIUNEiovLupO0JYYQAwBA6ggyIdLwQoABACB9dC0BAABnEWQAAICzCDIAAMBZBBkAAOAsggwAAHAWQQYAADiLIAMAAJxFkAEAAM4iyAAAAGcRZAAAgLMIMgAAwFner7UUBIG53rFjR9ibAgAAkhQ7b8fO45ENMjt37jTXbdq0CXtTAABAGufxJk2aVPn9gqCmqOO40tJS2bJlizRq1EgKCgqylhI1GG3atEkaN24sPmIf/cA++oF99AP7mBqNJxpiWrVqJbVq1Ypui4zufOvWrXPy3HqQfH0zxrCPfmAf/cA++oF9TF51LTExFPsCAABnEWQAAICzCDJpqFevntx6663m2lfsox/YRz+wj35gH3PD+2JfAADgL1pkAACAswgyAADAWQQZAADgLIIMAABwFkHmfyZNmiSHH3641K9fX04++WRZvnx5tY//5z//KZ07dzaPP/bYY+X555+v8H2tob7lllukZcuW0qBBA+nTp4+sWbNGXNnHBx98UH71q19J06ZNzUW3P/Hxf/jDH8xsyfGXs846S1zZx+nTp++z/fpzPh3HoqKiffZRL/369bPyOC5ZskT69+9vZvLU7Xj66adr/JnFixdL9+7dzSiJTp06meOa6d+3Tfv41FNPyZlnnimHHHKImWDslFNOkfnz51d4zG233bbPMdT/T67sox7Dyt6nW7du9eY4VvZ3ppdjjjnG2uM4evRoOfHEE83M+M2bN5fzzjtPPv744xp/Lt/nR4KMiPzjH/+Qa665xgwZW7lypXTr1k2Ki4tl27ZtlT5+6dKlctFFF8mQIUPknXfeMQdXL++//375Y8aNGycTJ06UBx54QN58801p2LChec49e/aIC/uo/1h0HxctWiTLli0zU0737dtXPv/88wqP0xPeF198UX6ZPXu2hCXVfVR6Yojf/g0bNlT4vuvHUU+C8fun79HatWvL+eefb+Vx/P77780+6QkrGevWrTOh7IwzzpB3331XRowYIZdcckmFE3067wub9lFPmBpk9GSwYsUKs696AtX/PfH0hBh/DF977TUJS6r7GKMnyfh90JOnL8fx3nvvrbBvOoX/QQcdtM/fok3H8dVXX5Xhw4fLG2+8IS+//LL89NNP5jyg+16VUM6POvw66k466aRg+PDh5bdLSkqCVq1aBaNHj6708RdccEHQr1+/CvedfPLJwbBhw8zXpaWlQYsWLYK//e1v5d//7rvvgnr16gWzZ88OXNjHRD///HPQqFGjYMaMGeX3XXzxxcG5554b2CLVfXzkkUeCJk2aVPl8Ph7He+65xxzHXbt2WXscY/Tf07x586p9zPXXXx8cc8wxFe773e9+FxQXF2ftNQt7Hytz9NFHB6NGjSq/feuttwbdunULbJTMPi5atMg87ttvv63yMb4dR318QUFBsH79eieOo9q2bZvZ11dffTWoShjnx8i3yPz444/mU442bcWvz6S3tSWiMnp//OOVpsnY4/VTojaJxj9G14vQptCqntO2fUy0e/duk8b1E0Riy41+ajryyCPlsssuk6+//jrr25/Lfdy1a5e0a9fOtDide+65snr16vLv+Xgcp02bJhdeeKH5BGTjcUxVTX+L2XjNbFwIVxfSS/xb1KZ57ebo0KGDDBgwQDZu3CiuOe6440x3g7ZAvf766+X3+3gc9W9Rt1///7hyHLdv326uE997YZ8fIx9kvvrqKykpKZFDDz20wv16O7F/Nkbvr+7xsetUntO2fUx0ww03mD+u+Defdkc8+uijsmDBAhk7dqxphjz77LPN73JhH/Wk/fDDD8szzzwjjz/+uDlB9OzZUzZv3uzlcdR6Am3e1a6XeDYdx1RV9beoK/D+8MMPWXnv22b8+PEmgF9wwQXl9+lJQGuDXnzxRZk8ebI5WWiNmwYeF2h40W6GJ5980lz0g4XWd2kXkvLtOG7ZskVeeOGFff4WbT6OpaWlpuv21FNPlS5dulT5uDDOj96vfo3MjRkzRubMmWM+tccXw+on+xgt6Oratat07NjRPK53795iOy2a1EuMhpijjjpKpkyZInfccYf4Rj8B6nE66aSTKtzv+nGMklmzZsmoUaNM+I6vH9HgGaPHT0+I+kl/7ty5plbBdvqhQi/xf4uffvqp3HPPPfLYY4+Jb2bMmCEHHnigqR2JZ/NxHD58uPkgFGbNTlUi3yJz8MEHm+LHL7/8ssL9ertFixaV/ozeX93jY9epPKdt+xj/6U+DzEsvvWT+sKqjTaH6u9auXSsu7WNM3bp15fjjjy/ffp+OoxbnaRhN5p9hmMcxVVX9LWoRt46GyMb7whZ6/PQTvJ7UEpvuE+lJ8ogjjnDiGFZFA3ds+306jlpSoy3BgwYNkv3228+J43jFFVfIv/71LzP4o3Xr1tU+NozzY+SDjL6RTjjhBNOsHt+EprfjP63H0/vjH6+0ojv2+Pbt25sDEv8YberW6uyqntO2fYxVlmvLhDZz9ujRo8bfo10yWluhzcSu7GM8bbpetWpV+fb7chxjwyH37t0rAwcOtPo4pqqmv8VsvC9soKPIBg8ebK7jh85XRbuetEXDhWNYFR2FFtt+X46j0q5bDSbJfKgI+zgGQWBCzLx582ThwoXmf2JNQjk/plUi7Jk5c+aYiunp06cHH3zwQTB06NDgwAMPDLZu3Wq+P2jQoODGG28sf/zrr78e1KlTJxg/fnzw4YcfmkrzunXrBqtWrSp/zJgxY8xzPPPMM8F///tfMyqkffv2wQ8//ODEPur277fffsETTzwRfPHFF+WXnTt3mu/r9XXXXRcsW7YsWLduXfDKK68E3bt3DwoLC4M9e/Y4sY866mP+/PnBp59+GqxYsSK48MILg/r16werV6/25jjGnHbaaWY0TyLbjqNuzzvvvGMu+u9pwoQJ5usNGzaY7+u+6T7GfPbZZ8H+++8fjBw50vwtTpo0Kahdu3bw4osvJv2a2b6PM2fONP9vdN/i/xZ1pEfMtddeGyxevNgcQ/3/1KdPn+Dggw82o0xc2EcdTff0008Ha9asMf9Hr7rqqqBWrVrm/ejLcYwZOHCgGcVTGduO42WXXWZGduo2xb/3du/eXf4YG86PBJn/ue+++4K2bduak7cO83vjjTfKv3f66aebIarx5s6dGxxxxBHm8Tr889///neF7+sQs5tvvjk49NBDzR9f7969g48//jhwZR/btWtn/jgTL/qmVPpG7tu3b3DIIYeYN6k+/tJLLw3tn0o6+zhixIjyx+pxOuecc4KVK1d6dRzVRx99ZI7dSy+9tM9z2XYcY8NwEy+xfdJr3cfEnznuuOPM69GhQwczrD6V18z2fdSvq3u80pDasmVLs3+HHXaYub127drAlX0cO3Zs0LFjR/NB4qCDDgqKioqChQsXenUclYbPBg0aBFOnTq30OW07jlLJ/ukl/m/MhvNjwf82FgAAwDmRr5EBAADuIsgAAABnEWQAAICzCDIAAMBZBBkAAOAsggwAAHAWQQYAADiLIAMAAJxFkAGQN0VFRTJixIi0f3769OlmIT0AiCHIAIiUb775Rv785z/LkUceaVbIbtu2rVx55ZWyffv2sDcNQBrqpPNDAOCqLVu2mMv48ePl6KOPlg0bNsif/vQnc98TTzwR9uYBSBEtMgDyqrS0VK6//no56KCDpEWLFnLbbbeVf2/ChAly7LHHSsOGDaVNmzZy+eWXy65du/Z5jvnz58tRRx0lBxxwgJx11lnyxRdflH/vrbfekjPPPFMOPvhgadKkiZx++umycuXK8u936dJFnnzySenfv7907NhRevXqJXfddZc899xz8vPPP+fhFQCQTQQZAHk1Y8YME1TefPNNGTdunNx+++3y8ssvm+/VqlVLJk6cKKtXrzaPW7hwoQk98Xbv3m1aUx577DFZsmSJbNy4Ua677rry7+/cuVMuvvhiee211+SNN96QwsJCOeecc8z9VdFupcaNG0udOjRSA65h9WsAeS32LSkpkf/85z/l95100kmmVWTMmDH7PF67erTb56uvviov9h08eLCsXbvWtKao+++/34ShrVu3VtkCpAXCs2bNkl//+tf7fF+f+4QTTpCBAwealhkAbqFFBkBede3atcLtli1byrZt28zXr7zyivTu3VsOO+wwadSokQwaNEi+/vpr0woTs//++5eHmMSfV19++aVceumlpiVGu5a0pUW7p7TlJtGOHTukX79+plYmvosLgDsIMgDyqm7duhVuFxQUmFaT9evXmxYTDTpaw7JixQqZNGmSecyPP/5Y7c/HNyxrt9K7774r9957ryxdutR83axZswrPobSrSetrNDDNmzdvn+cF4AY6hAFYQYOLBpq7777b1MqouXPnpvw8r7/+uulu0roYtWnTpvKuqfiWmOLiYqlXr548++yzUr9+/SztBYB8I8gAsEKnTp3kp59+kvvuu8+MKNJA8sADD6T8PNqlpIXAPXr0MIFl5MiRZr6YGL2vb9++prvq8ccfN7f1og455BCpXbt2VvcLQG7RtQTACt26dTPDr8eOHWuGSM+cOVNGjx6d8vNMmzZNvv32W+nevbupsdHJ7po3b17+fR2KrSOmVq1aZcKT1tjELtp6A8AtjFoCAADOokUGAAA4iyADAACcRZABAADOIsgAAABnEWQAAICzCDIAAMBZBBkAAOAsggwAAHAWQQYAADiLIAMAAJxFkAEAAOKq/wcnJ78bDue8hQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"haha2\")\n",
    "plt.ylabel(\"Haha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f913e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100,1)), X] # just to increase the nuumber of features for demo purposes ig\n",
    "thetha_best = np.linalg.pinv(X_b.T.dot(X_b)).dot(X_b.T).dot(y) ## you can also use pinv... why??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48a03cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.35454578],\n",
       "       [2.92981439]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetha_best ## LEARN SVD and EigenValues and MOORE Penrose Inverse later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7ce1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2,1 )), X_new]\n",
    "\n",
    "y_predict = np.dot(X_new_b, thetha_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c9ae609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.35454578],\n",
       "       [10.21417457]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3723da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel = \"X\"\n",
    "plt.ylabel = \"Y\"\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5107101e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using scikit learn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca15e0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.35454578])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f7dd570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.92981439]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a97c2b",
   "metadata": {},
   "source": [
    " Now we will look at very different ways to train a Linear Regression model, better\n",
    " suited for cases where there are a large number of features, or too many training\n",
    " instances to fit in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4cf39",
   "metadata": {},
   "source": [
    "Suppose you are lost in the mountains in a dense fog; you can only feel the slope of\n",
    " the ground below your feet. A good strategy to get to the bottom of the valley quickly\n",
    " is to go downhill in the direction of the steepest slope. This is exactly what Gradient\n",
    " Descent does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bff386a",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf26776",
   "metadata": {},
   "source": [
    "### important\n",
    "\n",
    " When using Gradient Descent, you should ensure that all features\n",
    " have a similar scale (e.g., using Scikit-Learn’s StandardScaler\n",
    " class), or else it will take much longer to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5856bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# np.random.rand gives only between 0 and 1\n",
    "# np.random.randint gives only integers\n",
    "# np.random.randn gives maybe float values with no restriction??\n",
    "thetha = np.random.randn(2,1) # random intialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93ebd10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1 # learning rate\n",
    "n_iterations = 1000000 # also called, epochs\n",
    "m = 100 # number of data points (X)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(thetha) - y)\n",
    "\n",
    "    thetha = thetha - eta * gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f07dbc",
   "metadata": {},
   "source": [
    "To find a good learning rate, you can use Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b3b83",
   "metadata": {},
   "source": [
    "## Stochiastic (Random) Gradient Descent\n",
    "\n",
    "Therefore randomness is good to escape from local optima, but bad because it means\n",
    " that the algorithm can never settle at the minimum. One solution to this dilemma is\n",
    " to gradually reduce the learning rate. The steps start out large (which helps make\n",
    " quick progress and escape local minima), then get smaller and smaller, allowing the\n",
    " algorithm to settle at the global minimum. This process is called simulated annealing,\n",
    " because it resembles the process of annealing in metallurgy where molten metal is\n",
    " slowly cooled down. The function that determines the learning rate at each iteration\n",
    " is called the learning schedule. If the learning rate is reduced too quickly, you may get\n",
    " stuck in a local minimum, or even end up frozen halfway to the minimum. If the\n",
    " learning rate is reduced too slowly, you may jump around the minimum for a long\n",
    " time and end up with a suboptimal solution if you halt training too early."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31dbda",
   "metadata": {},
   "source": [
    "# implementing SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d0f6d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "t0, t1 = 5, 50 #learning schedule hyperparameters\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0/ (t+t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40cd59c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.09803921568627451\n",
      "0.09615384615384616\n",
      "0.09433962264150944\n",
      "0.09259259259259259\n",
      "0.09090909090909091\n",
      "0.08928571428571429\n",
      "0.08771929824561403\n",
      "0.08620689655172414\n",
      "0.0847457627118644\n",
      "0.08333333333333333\n",
      "0.08196721311475409\n",
      "0.08064516129032258\n",
      "0.07936507936507936\n",
      "0.078125\n",
      "0.07692307692307693\n",
      "0.07575757575757576\n",
      "0.07462686567164178\n",
      "0.07352941176470588\n",
      "0.07246376811594203\n",
      "0.07142857142857142\n",
      "0.07042253521126761\n",
      "0.06944444444444445\n",
      "0.0684931506849315\n",
      "0.06756756756756757\n",
      "0.06666666666666667\n",
      "0.06578947368421052\n",
      "0.06493506493506493\n",
      "0.0641025641025641\n",
      "0.06329113924050633\n",
      "0.0625\n",
      "0.06172839506172839\n",
      "0.06097560975609756\n",
      "0.060240963855421686\n",
      "0.05952380952380952\n",
      "0.058823529411764705\n",
      "0.05813953488372093\n",
      "0.05747126436781609\n",
      "0.056818181818181816\n",
      "0.056179775280898875\n",
      "0.05555555555555555\n",
      "0.054945054945054944\n",
      "0.05434782608695652\n",
      "0.053763440860215055\n",
      "0.05319148936170213\n",
      "0.05263157894736842\n",
      "0.052083333333333336\n",
      "0.05154639175257732\n",
      "0.05102040816326531\n",
      "0.050505050505050504\n",
      "0.05\n",
      "0.04950495049504951\n",
      "0.049019607843137254\n",
      "0.04854368932038835\n",
      "0.04807692307692308\n",
      "0.047619047619047616\n",
      "0.04716981132075472\n",
      "0.04672897196261682\n",
      "0.046296296296296294\n",
      "0.045871559633027525\n",
      "0.045454545454545456\n",
      "0.04504504504504504\n",
      "0.044642857142857144\n",
      "0.04424778761061947\n",
      "0.043859649122807015\n",
      "0.043478260869565216\n",
      "0.04310344827586207\n",
      "0.042735042735042736\n",
      "0.0423728813559322\n",
      "0.04201680672268908\n",
      "0.041666666666666664\n",
      "0.04132231404958678\n",
      "0.040983606557377046\n",
      "0.04065040650406504\n",
      "0.04032258064516129\n",
      "0.04\n",
      "0.03968253968253968\n",
      "0.03937007874015748\n",
      "0.0390625\n",
      "0.03875968992248062\n",
      "0.038461538461538464\n",
      "0.03816793893129771\n",
      "0.03787878787878788\n",
      "0.03759398496240601\n",
      "0.03731343283582089\n",
      "0.037037037037037035\n",
      "0.03676470588235294\n",
      "0.0364963503649635\n",
      "0.036231884057971016\n",
      "0.03597122302158273\n",
      "0.03571428571428571\n",
      "0.03546099290780142\n",
      "0.035211267605633804\n",
      "0.03496503496503497\n",
      "0.034722222222222224\n",
      "0.034482758620689655\n",
      "0.03424657534246575\n",
      "0.034013605442176874\n",
      "0.033783783783783786\n",
      "0.03355704697986577\n",
      "0.03333333333333333\n",
      "0.033112582781456956\n",
      "0.03289473684210526\n",
      "0.032679738562091505\n",
      "0.032467532467532464\n",
      "0.03225806451612903\n",
      "0.03205128205128205\n",
      "0.03184713375796178\n",
      "0.03164556962025317\n",
      "0.031446540880503145\n",
      "0.03125\n",
      "0.031055900621118012\n",
      "0.030864197530864196\n",
      "0.03067484662576687\n",
      "0.03048780487804878\n",
      "0.030303030303030304\n",
      "0.030120481927710843\n",
      "0.029940119760479042\n",
      "0.02976190476190476\n",
      "0.029585798816568046\n",
      "0.029411764705882353\n",
      "0.029239766081871343\n",
      "0.029069767441860465\n",
      "0.028901734104046242\n",
      "0.028735632183908046\n",
      "0.02857142857142857\n",
      "0.028409090909090908\n",
      "0.02824858757062147\n",
      "0.028089887640449437\n",
      "0.027932960893854747\n",
      "0.027777777777777776\n",
      "0.027624309392265192\n",
      "0.027472527472527472\n",
      "0.0273224043715847\n",
      "0.02717391304347826\n",
      "0.02702702702702703\n",
      "0.026881720430107527\n",
      "0.026737967914438502\n",
      "0.026595744680851064\n",
      "0.026455026455026454\n",
      "0.02631578947368421\n",
      "0.02617801047120419\n",
      "0.026041666666666668\n",
      "0.025906735751295335\n",
      "0.02577319587628866\n",
      "0.02564102564102564\n",
      "0.025510204081632654\n",
      "0.025380710659898477\n",
      "0.025252525252525252\n",
      "0.02512562814070352\n",
      "0.025\n",
      "0.024875621890547265\n",
      "0.024752475247524754\n",
      "0.024630541871921183\n",
      "0.024509803921568627\n",
      "0.024390243902439025\n",
      "0.024271844660194174\n",
      "0.024154589371980676\n",
      "0.02403846153846154\n",
      "0.023923444976076555\n",
      "0.023809523809523808\n",
      "0.023696682464454975\n",
      "0.02358490566037736\n",
      "0.023474178403755867\n",
      "0.02336448598130841\n",
      "0.023255813953488372\n",
      "0.023148148148148147\n",
      "0.02304147465437788\n",
      "0.022935779816513763\n",
      "0.0228310502283105\n",
      "0.022727272727272728\n",
      "0.02262443438914027\n",
      "0.02252252252252252\n",
      "0.02242152466367713\n",
      "0.022321428571428572\n",
      "0.022222222222222223\n",
      "0.022123893805309734\n",
      "0.022026431718061675\n",
      "0.021929824561403508\n",
      "0.021834061135371178\n",
      "0.021739130434782608\n",
      "0.021645021645021644\n",
      "0.021551724137931036\n",
      "0.02145922746781116\n",
      "0.021367521367521368\n",
      "0.02127659574468085\n",
      "0.0211864406779661\n",
      "0.02109704641350211\n",
      "0.02100840336134454\n",
      "0.02092050209205021\n",
      "0.020833333333333332\n",
      "0.02074688796680498\n",
      "0.02066115702479339\n",
      "0.0205761316872428\n",
      "0.020491803278688523\n",
      "0.02040816326530612\n",
      "0.02032520325203252\n",
      "0.020242914979757085\n",
      "0.020161290322580645\n",
      "0.020080321285140562\n",
      "0.02\n",
      "0.0199203187250996\n",
      "0.01984126984126984\n",
      "0.019762845849802372\n",
      "0.01968503937007874\n",
      "0.0196078431372549\n",
      "0.01953125\n",
      "0.019455252918287938\n",
      "0.01937984496124031\n",
      "0.019305019305019305\n",
      "0.019230769230769232\n",
      "0.019157088122605363\n",
      "0.019083969465648856\n",
      "0.019011406844106463\n",
      "0.01893939393939394\n",
      "0.018867924528301886\n",
      "0.018796992481203006\n",
      "0.018726591760299626\n",
      "0.018656716417910446\n",
      "0.01858736059479554\n",
      "0.018518518518518517\n",
      "0.01845018450184502\n",
      "0.01838235294117647\n",
      "0.018315018315018316\n",
      "0.01824817518248175\n",
      "0.01818181818181818\n",
      "0.018115942028985508\n",
      "0.018050541516245487\n",
      "0.017985611510791366\n",
      "0.017921146953405017\n",
      "0.017857142857142856\n",
      "0.017793594306049824\n",
      "0.01773049645390071\n",
      "0.0176678445229682\n",
      "0.017605633802816902\n",
      "0.017543859649122806\n",
      "0.017482517482517484\n",
      "0.017421602787456445\n",
      "0.017361111111111112\n",
      "0.01730103806228374\n",
      "0.017241379310344827\n",
      "0.01718213058419244\n",
      "0.017123287671232876\n",
      "0.017064846416382253\n",
      "0.017006802721088437\n",
      "0.01694915254237288\n",
      "0.016891891891891893\n",
      "0.016835016835016835\n",
      "0.016778523489932886\n",
      "0.016722408026755852\n",
      "0.016666666666666666\n",
      "0.016611295681063124\n",
      "0.016556291390728478\n",
      "0.0165016501650165\n",
      "0.01644736842105263\n",
      "0.01639344262295082\n",
      "0.016339869281045753\n",
      "0.016286644951140065\n",
      "0.016233766233766232\n",
      "0.016181229773462782\n",
      "0.016129032258064516\n",
      "0.01607717041800643\n",
      "0.016025641025641024\n",
      "0.01597444089456869\n",
      "0.01592356687898089\n",
      "0.015873015873015872\n",
      "0.015822784810126583\n",
      "0.015772870662460567\n",
      "0.015723270440251572\n",
      "0.01567398119122257\n",
      "0.015625\n",
      "0.01557632398753894\n",
      "0.015527950310559006\n",
      "0.015479876160990712\n",
      "0.015432098765432098\n",
      "0.015384615384615385\n",
      "0.015337423312883436\n",
      "0.01529051987767584\n",
      "0.01524390243902439\n",
      "0.015197568389057751\n",
      "0.015151515151515152\n",
      "0.015105740181268883\n",
      "0.015060240963855422\n",
      "0.015015015015015015\n",
      "0.014970059880239521\n",
      "0.014925373134328358\n",
      "0.01488095238095238\n",
      "0.01483679525222552\n",
      "0.014792899408284023\n",
      "0.014749262536873156\n",
      "0.014705882352941176\n",
      "0.01466275659824047\n",
      "0.014619883040935672\n",
      "0.014577259475218658\n",
      "0.014534883720930232\n",
      "0.014492753623188406\n",
      "0.014450867052023121\n",
      "0.01440922190201729\n",
      "0.014367816091954023\n",
      "0.014326647564469915\n",
      "0.014285714285714285\n",
      "0.014245014245014245\n",
      "0.014204545454545454\n",
      "0.014164305949008499\n",
      "0.014124293785310734\n",
      "0.014084507042253521\n",
      "0.014044943820224719\n",
      "0.014005602240896359\n",
      "0.013966480446927373\n",
      "0.013927576601671309\n",
      "0.013888888888888888\n",
      "0.013850415512465374\n",
      "0.013812154696132596\n",
      "0.013774104683195593\n",
      "0.013736263736263736\n",
      "0.0136986301369863\n",
      "0.01366120218579235\n",
      "0.013623978201634877\n",
      "0.01358695652173913\n",
      "0.013550135501355014\n",
      "0.013513513513513514\n",
      "0.013477088948787063\n",
      "0.013440860215053764\n",
      "0.013404825737265416\n",
      "0.013368983957219251\n",
      "0.013333333333333334\n",
      "0.013297872340425532\n",
      "0.013262599469496022\n",
      "0.013227513227513227\n",
      "0.013192612137203167\n",
      "0.013157894736842105\n",
      "0.013123359580052493\n",
      "0.013089005235602094\n",
      "0.013054830287206266\n",
      "0.013020833333333334\n",
      "0.012987012987012988\n",
      "0.012953367875647668\n",
      "0.012919896640826873\n",
      "0.01288659793814433\n",
      "0.012853470437017995\n",
      "0.01282051282051282\n",
      "0.01278772378516624\n",
      "0.012755102040816327\n",
      "0.01272264631043257\n",
      "0.012690355329949238\n",
      "0.012658227848101266\n",
      "0.012626262626262626\n",
      "0.012594458438287154\n",
      "0.01256281407035176\n",
      "0.012531328320802004\n",
      "0.0125\n",
      "0.012468827930174564\n",
      "0.012437810945273632\n",
      "0.01240694789081886\n",
      "0.012376237623762377\n",
      "0.012345679012345678\n",
      "0.012315270935960592\n",
      "0.012285012285012284\n",
      "0.012254901960784314\n",
      "0.012224938875305624\n",
      "0.012195121951219513\n",
      "0.012165450121654502\n",
      "0.012135922330097087\n",
      "0.012106537530266344\n",
      "0.012077294685990338\n",
      "0.012048192771084338\n",
      "0.01201923076923077\n",
      "0.011990407673860911\n",
      "0.011961722488038277\n",
      "0.011933174224343675\n",
      "0.011904761904761904\n",
      "0.011876484560570071\n",
      "0.011848341232227487\n",
      "0.01182033096926714\n",
      "0.01179245283018868\n",
      "0.011764705882352941\n",
      "0.011737089201877934\n",
      "0.0117096018735363\n",
      "0.011682242990654205\n",
      "0.011655011655011656\n",
      "0.011627906976744186\n",
      "0.01160092807424594\n",
      "0.011574074074074073\n",
      "0.011547344110854504\n",
      "0.01152073732718894\n",
      "0.011494252873563218\n",
      "0.011467889908256881\n",
      "0.011441647597254004\n",
      "0.01141552511415525\n",
      "0.011389521640091117\n",
      "0.011363636363636364\n",
      "0.011337868480725623\n",
      "0.011312217194570135\n",
      "0.011286681715575621\n",
      "0.01126126126126126\n",
      "0.011235955056179775\n",
      "0.011210762331838564\n",
      "0.011185682326621925\n",
      "0.011160714285714286\n",
      "0.011135857461024499\n",
      "0.011111111111111112\n",
      "0.011086474501108648\n",
      "0.011061946902654867\n",
      "0.011037527593818985\n",
      "0.011013215859030838\n",
      "0.01098901098901099\n",
      "0.010964912280701754\n",
      "0.010940919037199124\n",
      "0.010917030567685589\n",
      "0.010893246187363835\n",
      "0.010869565217391304\n",
      "0.010845986984815618\n",
      "0.010822510822510822\n",
      "0.01079913606911447\n",
      "0.010775862068965518\n",
      "0.010752688172043012\n",
      "0.01072961373390558\n",
      "0.010706638115631691\n",
      "0.010683760683760684\n",
      "0.010660980810234541\n",
      "0.010638297872340425\n",
      "0.010615711252653927\n",
      "0.01059322033898305\n",
      "0.010570824524312896\n",
      "0.010548523206751054\n",
      "0.010526315789473684\n",
      "0.01050420168067227\n",
      "0.010482180293501049\n",
      "0.010460251046025104\n",
      "0.010438413361169102\n",
      "0.010416666666666666\n",
      "0.010395010395010396\n",
      "0.01037344398340249\n",
      "0.010351966873706004\n",
      "0.010330578512396695\n",
      "0.010309278350515464\n",
      "0.0102880658436214\n",
      "0.01026694045174538\n",
      "0.010245901639344262\n",
      "0.010224948875255624\n",
      "0.01020408163265306\n",
      "0.010183299389002037\n",
      "0.01016260162601626\n",
      "0.010141987829614604\n",
      "0.010121457489878543\n",
      "0.010101010101010102\n",
      "0.010080645161290322\n",
      "0.01006036217303823\n",
      "0.010040160642570281\n",
      "0.01002004008016032\n",
      "0.01\n",
      "0.00998003992015968\n",
      "0.0099601593625498\n",
      "0.009940357852882704\n",
      "0.00992063492063492\n",
      "0.009900990099009901\n",
      "0.009881422924901186\n",
      "0.009861932938856016\n",
      "0.00984251968503937\n",
      "0.009823182711198428\n",
      "0.00980392156862745\n",
      "0.009784735812133072\n",
      "0.009765625\n",
      "0.009746588693957114\n",
      "0.009727626459143969\n",
      "0.009708737864077669\n",
      "0.009689922480620155\n",
      "0.009671179883945842\n",
      "0.009652509652509652\n",
      "0.009633911368015413\n",
      "0.009615384615384616\n",
      "0.009596928982725527\n",
      "0.009578544061302681\n",
      "0.009560229445506692\n",
      "0.009541984732824428\n",
      "0.009523809523809525\n",
      "0.009505703422053232\n",
      "0.009487666034155597\n",
      "0.00946969696969697\n",
      "0.00945179584120983\n",
      "0.009433962264150943\n",
      "0.009416195856873822\n",
      "0.009398496240601503\n",
      "0.009380863039399626\n",
      "0.009363295880149813\n",
      "0.009345794392523364\n",
      "0.009328358208955223\n",
      "0.00931098696461825\n",
      "0.00929368029739777\n",
      "0.00927643784786642\n",
      "0.009259259259259259\n",
      "0.009242144177449169\n",
      "0.00922509225092251\n",
      "0.009208103130755065\n",
      "0.009191176470588236\n",
      "0.009174311926605505\n",
      "0.009157509157509158\n",
      "0.009140767824497258\n",
      "0.009124087591240875\n",
      "0.009107468123861567\n",
      "0.00909090909090909\n",
      "0.009074410163339383\n",
      "0.009057971014492754\n",
      "0.009041591320072333\n",
      "0.009025270758122744\n",
      "0.009009009009009009\n",
      "0.008992805755395683\n",
      "0.008976660682226212\n",
      "0.008960573476702509\n",
      "0.008944543828264758\n",
      "0.008928571428571428\n",
      "0.008912655971479501\n",
      "0.008896797153024912\n",
      "0.008880994671403197\n",
      "0.008865248226950355\n",
      "0.008849557522123894\n",
      "0.0088339222614841\n",
      "0.008818342151675485\n",
      "0.008802816901408451\n",
      "0.008787346221441126\n",
      "0.008771929824561403\n",
      "0.008756567425569177\n",
      "0.008741258741258742\n",
      "0.008726003490401396\n",
      "0.008710801393728223\n",
      "0.008695652173913044\n",
      "0.008680555555555556\n",
      "0.008665511265164644\n",
      "0.00865051903114187\n",
      "0.008635578583765112\n",
      "0.008620689655172414\n",
      "0.008605851979345954\n",
      "0.00859106529209622\n",
      "0.008576329331046312\n",
      "0.008561643835616438\n",
      "0.008547008547008548\n",
      "0.008532423208191127\n",
      "0.008517887563884156\n",
      "0.008503401360544218\n",
      "0.008488964346349746\n",
      "0.00847457627118644\n",
      "0.008460236886632826\n",
      "0.008445945945945946\n",
      "0.008431703204047217\n",
      "0.008417508417508417\n",
      "0.008403361344537815\n",
      "0.008389261744966443\n",
      "0.008375209380234505\n",
      "0.008361204013377926\n",
      "0.008347245409015025\n",
      "0.008333333333333333\n",
      "0.008319467554076539\n",
      "0.008305647840531562\n",
      "0.008291873963515755\n",
      "0.008278145695364239\n",
      "0.008264462809917356\n",
      "0.00825082508250825\n",
      "0.008237232289950576\n",
      "0.008223684210526315\n",
      "0.008210180623973728\n",
      "0.00819672131147541\n",
      "0.008183306055646482\n",
      "0.008169934640522876\n",
      "0.008156606851549755\n",
      "0.008143322475570033\n",
      "0.008130081300813009\n",
      "0.008116883116883116\n",
      "0.008103727714748784\n",
      "0.008090614886731391\n",
      "0.008077544426494346\n",
      "0.008064516129032258\n",
      "0.008051529790660225\n",
      "0.008038585209003215\n",
      "0.008025682182985553\n",
      "0.008012820512820512\n",
      "0.008\n",
      "0.007987220447284345\n",
      "0.007974481658692184\n",
      "0.007961783439490446\n",
      "0.00794912559618442\n",
      "0.007936507936507936\n",
      "0.00792393026941363\n",
      "0.007911392405063292\n",
      "0.007898894154818325\n",
      "0.007886435331230283\n",
      "0.007874015748031496\n",
      "0.007861635220125786\n",
      "0.007849293563579277\n",
      "0.007836990595611285\n",
      "0.00782472613458529\n",
      "0.0078125\n",
      "0.0078003120124804995\n",
      "0.00778816199376947\n",
      "0.007776049766718507\n",
      "0.007763975155279503\n",
      "0.007751937984496124\n",
      "0.007739938080495356\n",
      "0.0077279752704791345\n",
      "0.007716049382716049\n",
      "0.007704160246533128\n",
      "0.007692307692307693\n",
      "0.007680491551459293\n",
      "0.007668711656441718\n",
      "0.007656967840735069\n",
      "0.00764525993883792\n",
      "0.007633587786259542\n",
      "0.007621951219512195\n",
      "0.0076103500761035\n",
      "0.007598784194528876\n",
      "0.007587253414264037\n",
      "0.007575757575757576\n",
      "0.007564296520423601\n",
      "0.0075528700906344415\n",
      "0.007541478129713424\n",
      "0.007530120481927711\n",
      "0.007518796992481203\n",
      "0.0075075075075075074\n",
      "0.0074962518740629685\n",
      "0.0074850299401197605\n",
      "0.007473841554559043\n",
      "0.007462686567164179\n",
      "0.007451564828614009\n",
      "0.00744047619047619\n",
      "0.007429420505200594\n",
      "0.00741839762611276\n",
      "0.007407407407407408\n",
      "0.0073964497041420114\n",
      "0.007385524372230428\n",
      "0.007374631268436578\n",
      "0.007363770250368188\n",
      "0.007352941176470588\n",
      "0.007342143906020558\n",
      "0.007331378299120235\n",
      "0.007320644216691069\n",
      "0.007309941520467836\n",
      "0.0072992700729927005\n",
      "0.007288629737609329\n",
      "0.00727802037845706\n",
      "0.007267441860465116\n",
      "0.00725689404934688\n",
      "0.007246376811594203\n",
      "0.00723589001447178\n",
      "0.0072254335260115606\n",
      "0.007215007215007215\n",
      "0.007204610951008645\n",
      "0.007194244604316547\n",
      "0.007183908045977011\n",
      "0.007173601147776184\n",
      "0.0071633237822349575\n",
      "0.00715307582260372\n",
      "0.007142857142857143\n",
      "0.007132667617689016\n",
      "0.007122507122507123\n",
      "0.007112375533428165\n",
      "0.007102272727272727\n",
      "0.0070921985815602835\n",
      "0.007082152974504249\n",
      "0.007072135785007072\n",
      "0.007062146892655367\n",
      "0.007052186177715092\n",
      "0.007042253521126761\n",
      "0.007032348804500703\n",
      "0.007022471910112359\n",
      "0.0070126227208976155\n",
      "0.0070028011204481795\n",
      "0.006993006993006993\n",
      "0.006983240223463687\n",
      "0.00697350069735007\n",
      "0.006963788300835654\n",
      "0.006954102920723227\n",
      "0.006944444444444444\n",
      "0.006934812760055479\n",
      "0.006925207756232687\n",
      "0.006915629322268326\n",
      "0.006906077348066298\n",
      "0.006896551724137931\n",
      "0.006887052341597796\n",
      "0.0068775790921595595\n",
      "0.006868131868131868\n",
      "0.006858710562414266\n",
      "0.00684931506849315\n",
      "0.006839945280437756\n",
      "0.006830601092896175\n",
      "0.0068212824010914054\n",
      "0.006811989100817439\n",
      "0.006802721088435374\n",
      "0.006793478260869565\n",
      "0.0067842605156037995\n",
      "0.006775067750677507\n",
      "0.006765899864682003\n",
      "0.006756756756756757\n",
      "0.006747638326585695\n",
      "0.006738544474393531\n",
      "0.006729475100942127\n",
      "0.006720430107526882\n",
      "0.006711409395973154\n",
      "0.006702412868632708\n",
      "0.006693440428380187\n",
      "0.0066844919786096255\n",
      "0.006675567423230975\n",
      "0.006666666666666667\n",
      "0.006657789613848202\n",
      "0.006648936170212766\n",
      "0.006640106241699867\n",
      "0.006631299734748011\n",
      "0.006622516556291391\n",
      "0.006613756613756613\n",
      "0.0066050198150594455\n",
      "0.006596306068601583\n",
      "0.006587615283267457\n",
      "0.006578947368421052\n",
      "0.006570302233902759\n",
      "0.006561679790026247\n",
      "0.00655307994757536\n",
      "0.006544502617801047\n",
      "0.006535947712418301\n",
      "0.006527415143603133\n",
      "0.00651890482398957\n",
      "0.006510416666666667\n",
      "0.006501950585175552\n",
      "0.006493506493506494\n",
      "0.00648508430609598\n",
      "0.006476683937823834\n",
      "0.00646830530401035\n",
      "0.006459948320413436\n",
      "0.0064516129032258064\n",
      "0.006443298969072165\n",
      "0.006435006435006435\n",
      "0.006426735218508998\n",
      "0.006418485237483954\n",
      "0.00641025641025641\n",
      "0.006402048655569782\n",
      "0.00639386189258312\n",
      "0.006385696040868455\n",
      "0.006377551020408163\n",
      "0.006369426751592357\n",
      "0.006361323155216285\n",
      "0.0063532401524777635\n",
      "0.006345177664974619\n",
      "0.0063371356147021544\n",
      "0.006329113924050633\n",
      "0.006321112515802781\n",
      "0.006313131313131313\n",
      "0.006305170239596469\n",
      "0.006297229219143577\n",
      "0.006289308176100629\n",
      "0.00628140703517588\n",
      "0.006273525721455458\n",
      "0.006265664160401002\n",
      "0.006257822277847309\n",
      "0.00625\n",
      "0.006242197253433208\n",
      "0.006234413965087282\n",
      "0.0062266500622665\n",
      "0.006218905472636816\n",
      "0.006211180124223602\n",
      "0.00620347394540943\n",
      "0.006195786864931847\n",
      "0.006188118811881188\n",
      "0.006180469715698393\n",
      "0.006172839506172839\n",
      "0.006165228113440197\n",
      "0.006157635467980296\n",
      "0.006150061500615006\n",
      "0.006142506142506142\n",
      "0.006134969325153374\n",
      "0.006127450980392157\n",
      "0.006119951040391677\n",
      "0.006112469437652812\n",
      "0.006105006105006105\n",
      "0.006097560975609756\n",
      "0.0060901339829476245\n",
      "0.006082725060827251\n",
      "0.006075334143377886\n",
      "0.006067961165048544\n",
      "0.006060606060606061\n",
      "0.006053268765133172\n",
      "0.006045949214026602\n",
      "0.006038647342995169\n",
      "0.006031363088057901\n",
      "0.006024096385542169\n",
      "0.006016847172081829\n",
      "0.006009615384615385\n",
      "0.006002400960384154\n",
      "0.005995203836930456\n",
      "0.005988023952095809\n",
      "0.005980861244019139\n",
      "0.005973715651135006\n",
      "0.0059665871121718375\n",
      "0.0059594755661501785\n",
      "0.005952380952380952\n",
      "0.005945303210463734\n",
      "0.0059382422802850355\n",
      "0.005931198102016607\n",
      "0.005924170616113744\n",
      "0.005917159763313609\n",
      "0.00591016548463357\n",
      "0.0059031877213695395\n",
      "0.00589622641509434\n",
      "0.005889281507656066\n",
      "0.0058823529411764705\n",
      "0.005875440658049354\n",
      "0.005868544600938967\n",
      "0.005861664712778429\n",
      "0.00585480093676815\n",
      "0.005847953216374269\n",
      "0.005841121495327103\n",
      "0.005834305717619603\n",
      "0.005827505827505828\n",
      "0.005820721769499418\n",
      "0.005813953488372093\n",
      "0.005807200929152149\n",
      "0.00580046403712297\n",
      "0.005793742757821553\n",
      "0.005787037037037037\n",
      "0.005780346820809248\n",
      "0.005773672055427252\n",
      "0.0057670126874279125\n",
      "0.00576036866359447\n",
      "0.005753739930955121\n",
      "0.005747126436781609\n",
      "0.0057405281285878304\n",
      "0.005733944954128441\n",
      "0.0057273768613974796\n",
      "0.005720823798627002\n",
      "0.005714285714285714\n",
      "0.005707762557077625\n",
      "0.005701254275940707\n",
      "0.0056947608200455585\n",
      "0.005688282138794084\n",
      "0.005681818181818182\n",
      "0.0056753688989784334\n",
      "0.005668934240362812\n",
      "0.0056625141562853904\n",
      "0.005656108597285068\n",
      "0.005649717514124294\n",
      "0.0056433408577878106\n",
      "0.005636978579481398\n",
      "0.00563063063063063\n",
      "0.00562429696287964\n",
      "0.0056179775280898875\n",
      "0.005611672278338945\n",
      "0.005605381165919282\n",
      "0.005599104143337066\n",
      "0.005592841163310962\n",
      "0.00558659217877095\n",
      "0.005580357142857143\n",
      "0.005574136008918618\n",
      "0.005567928730512249\n",
      "0.0055617352614015575\n",
      "0.005555555555555556\n",
      "0.005549389567147614\n",
      "0.005543237250554324\n",
      "0.005537098560354375\n",
      "0.0055309734513274336\n",
      "0.0055248618784530384\n",
      "0.005518763796909493\n",
      "0.005512679162072767\n",
      "0.005506607929515419\n",
      "0.005500550055005501\n",
      "0.005494505494505495\n",
      "0.005488474204171241\n",
      "0.005482456140350877\n",
      "0.00547645125958379\n",
      "0.005470459518599562\n",
      "0.00546448087431694\n",
      "0.0054585152838427945\n",
      "0.0054525627044711015\n",
      "0.0054466230936819175\n",
      "0.00544069640914037\n",
      "0.005434782608695652\n",
      "0.0054288816503800215\n",
      "0.005422993492407809\n",
      "0.005417118093174431\n",
      "0.005411255411255411\n",
      "0.005405405405405406\n",
      "0.005399568034557235\n",
      "0.005393743257820928\n",
      "0.005387931034482759\n",
      "0.005382131324004306\n",
      "0.005376344086021506\n",
      "0.0053705692803437165\n",
      "0.00536480686695279\n",
      "0.0053590568060021436\n",
      "0.0053533190578158455\n",
      "0.0053475935828877\n",
      "0.005341880341880342\n",
      "0.005336179295624333\n",
      "0.005330490405117271\n",
      "0.005324813631522897\n",
      "0.005319148936170213\n",
      "0.005313496280552604\n",
      "0.005307855626326964\n",
      "0.005302226935312832\n",
      "0.005296610169491525\n",
      "0.005291005291005291\n",
      "0.005285412262156448\n",
      "0.005279831045406547\n",
      "0.005274261603375527\n",
      "0.005268703898840885\n",
      "0.005263157894736842\n",
      "0.005257623554153523\n",
      "0.005252100840336135\n",
      "0.005246589716684155\n",
      "0.005241090146750524\n",
      "0.005235602094240838\n",
      "0.005230125523012552\n",
      "0.00522466039707419\n",
      "0.005219206680584551\n",
      "0.005213764337851929\n",
      "0.005208333333333333\n",
      "0.005202913631633715\n",
      "0.005197505197505198\n",
      "0.005192107995846314\n",
      "0.005186721991701245\n",
      "0.0051813471502590676\n",
      "0.005175983436853002\n",
      "0.005170630816959669\n",
      "0.005165289256198347\n",
      "0.005159958720330237\n",
      "0.005154639175257732\n",
      "0.005149330587023687\n",
      "0.0051440329218107\n",
      "0.0051387461459403904\n",
      "0.00513347022587269\n",
      "0.005128205128205128\n",
      "0.005122950819672131\n",
      "0.00511770726714432\n",
      "0.005112474437627812\n",
      "0.005107252298263534\n",
      "0.00510204081632653\n",
      "0.0050968399592252805\n",
      "0.0050916496945010185\n",
      "0.00508646998982706\n",
      "0.00508130081300813\n",
      "0.005076142131979695\n",
      "0.005070993914807302\n",
      "0.005065856129685917\n",
      "0.005060728744939271\n",
      "0.005055611729019211\n",
      "0.005050505050505051\n",
      "0.005045408678102927\n",
      "0.005040322580645161\n",
      "0.005035246727089627\n",
      "0.005030181086519115\n",
      "0.005025125628140704\n",
      "0.0050200803212851405\n",
      "0.0050150451354062184\n",
      "0.00501002004008016\n",
      "0.005005005005005005\n",
      "0.005\n",
      "0.004995004995004995\n",
      "0.00499001996007984\n",
      "0.004985044865403789\n",
      "0.0049800796812749\n",
      "0.004975124378109453\n",
      "0.004970178926441352\n",
      "0.004965243296921549\n",
      "0.00496031746031746\n",
      "0.004955401387512388\n",
      "0.0049504950495049506\n",
      "0.004945598417408506\n",
      "0.004940711462450593\n",
      "0.004935834155972359\n",
      "0.004930966469428008\n",
      "0.0049261083743842365\n",
      "0.004921259842519685\n",
      "0.004916420845624385\n",
      "0.004911591355599214\n",
      "0.004906771344455349\n",
      "0.004901960784313725\n",
      "0.004897159647404506\n",
      "0.004892367906066536\n",
      "0.004887585532746823\n",
      "0.0048828125\n",
      "0.004878048780487805\n",
      "0.004873294346978557\n",
      "0.004868549172346641\n",
      "0.0048638132295719845\n",
      "0.004859086491739553\n",
      "0.0048543689320388345\n",
      "0.004849660523763337\n",
      "0.0048449612403100775\n",
      "0.00484027105517909\n",
      "0.004835589941972921\n",
      "0.004830917874396135\n",
      "0.004826254826254826\n",
      "0.0048216007714561235\n",
      "0.004816955684007707\n",
      "0.004812319538017324\n",
      "0.004807692307692308\n",
      "0.004803073967339097\n",
      "0.0047984644913627635\n",
      "0.004793863854266539\n",
      "0.004789272030651341\n",
      "0.004784688995215311\n",
      "0.004780114722753346\n",
      "0.004775549188156638\n",
      "0.004770992366412214\n",
      "0.004766444232602479\n",
      "0.004761904761904762\n",
      "0.004757373929590866\n",
      "0.004752851711026616\n",
      "0.004748338081671415\n",
      "0.004743833017077799\n",
      "0.004739336492890996\n",
      "0.004734848484848485\n",
      "0.004730368968779565\n",
      "0.004725897920604915\n",
      "0.004721435316336166\n",
      "0.0047169811320754715\n",
      "0.00471253534401508\n",
      "0.004708097928436911\n",
      "0.004703668861712135\n",
      "0.004699248120300752\n",
      "0.004694835680751174\n",
      "0.004690431519699813\n",
      "0.004686035613870665\n",
      "0.0046816479400749065\n",
      "0.004677268475210477\n",
      "0.004672897196261682\n",
      "0.004668534080298786\n",
      "0.0046641791044776115\n",
      "0.004659832246039142\n",
      "0.004655493482309125\n",
      "0.004651162790697674\n",
      "0.004646840148698885\n",
      "0.004642525533890436\n",
      "0.00463821892393321\n",
      "0.004633920296570899\n",
      "0.004629629629629629\n",
      "0.004625346901017576\n",
      "0.0046210720887245845\n",
      "0.0046168051708217915\n",
      "0.004612546125461255\n",
      "0.004608294930875576\n",
      "0.004604051565377533\n",
      "0.004599816007359705\n",
      "0.004595588235294118\n",
      "0.004591368227731864\n",
      "0.0045871559633027525\n",
      "0.00458295142071494\n",
      "0.004578754578754579\n",
      "0.004574565416285453\n",
      "0.004570383912248629\n",
      "0.0045662100456621\n",
      "0.004562043795620438\n",
      "0.004557885141294439\n",
      "0.004553734061930784\n",
      "0.004549590536851683\n",
      "0.004545454545454545\n",
      "0.004541326067211626\n",
      "0.004537205081669692\n",
      "0.004533091568449683\n",
      "0.004528985507246377\n",
      "0.004524886877828055\n",
      "0.0045207956600361665\n",
      "0.004516711833785004\n",
      "0.004512635379061372\n",
      "0.004508566275924256\n",
      "0.0045045045045045045\n",
      "0.004500450045004501\n",
      "0.0044964028776978415\n",
      "0.004492362982929021\n",
      "0.004488330341113106\n",
      "0.004484304932735426\n",
      "0.004480286738351254\n",
      "0.004476275738585497\n",
      "0.004472271914132379\n",
      "0.004468275245755138\n",
      "0.004464285714285714\n",
      "0.0044603033006244425\n",
      "0.004456327985739751\n",
      "0.004452359750667854\n",
      "0.004448398576512456\n",
      "0.0044444444444444444\n",
      "0.004440497335701598\n",
      "0.0044365572315882874\n",
      "0.004432624113475178\n",
      "0.0044286979627989375\n",
      "0.004424778761061947\n",
      "0.004420866489832007\n",
      "0.00441696113074205\n",
      "0.00441306266548985\n",
      "0.004409171075837742\n",
      "0.004405286343612335\n",
      "0.0044014084507042256\n",
      "0.0043975373790677225\n",
      "0.004393673110720563\n",
      "0.004389815627743635\n",
      "0.0043859649122807015\n",
      "0.0043821209465381246\n",
      "0.0043782837127845885\n",
      "0.004374453193350831\n",
      "0.004370629370629371\n",
      "0.004366812227074236\n",
      "0.004363001745200698\n",
      "0.004359197907585004\n",
      "0.004355400696864111\n",
      "0.004351610095735422\n",
      "0.004347826086956522\n",
      "0.004344048653344918\n",
      "0.004340277777777778\n",
      "0.004336513443191674\n",
      "0.004332755632582322\n",
      "0.004329004329004329\n",
      "0.004325259515570935\n",
      "0.00432152117545376\n",
      "0.004317789291882556\n",
      "0.004314063848144953\n",
      "0.004310344827586207\n",
      "0.004306632213608958\n",
      "0.004302925989672977\n",
      "0.004299226139294927\n",
      "0.00429553264604811\n",
      "0.004291845493562232\n",
      "0.004288164665523156\n",
      "0.004284490145672665\n",
      "0.004280821917808219\n",
      "0.00427715996578272\n",
      "0.004273504273504274\n",
      "0.004269854824935952\n",
      "0.004266211604095563\n",
      "0.004262574595055414\n",
      "0.004258943781942078\n",
      "0.00425531914893617\n",
      "0.004251700680272109\n",
      "0.004248088360237893\n",
      "0.004244482173174873\n",
      "0.004240882103477523\n",
      "0.00423728813559322\n",
      "0.004233700254022015\n",
      "0.004230118443316413\n",
      "0.00422654268808115\n",
      "0.004222972972972973\n",
      "0.004219409282700422\n",
      "0.0042158516020236085\n",
      "0.004212299915754001\n",
      "0.004208754208754209\n",
      "0.004205214465937763\n",
      "0.004201680672268907\n",
      "0.0041981528127623844\n",
      "0.0041946308724832215\n",
      "0.004191114836546521\n",
      "0.0041876046901172526\n",
      "0.0041841004184100415\n",
      "0.004180602006688963\n",
      "0.004177109440267335\n",
      "0.004173622704507512\n",
      "0.004170141784820684\n",
      "0.004166666666666667\n",
      "0.004163197335553705\n",
      "0.004159733777038269\n",
      "0.004156275976724855\n",
      "0.004152823920265781\n",
      "0.004149377593360996\n",
      "0.0041459369817578775\n",
      "0.004142502071251036\n",
      "0.0041390728476821195\n",
      "0.0041356492969396195\n",
      "0.004132231404958678\n",
      "0.004128819157720892\n",
      "0.004125412541254125\n",
      "0.004122011541632316\n",
      "0.004118616144975288\n",
      "0.00411522633744856\n",
      "0.004111842105263158\n",
      "0.004108463434675432\n",
      "0.004105090311986864\n",
      "0.004101722723543888\n",
      "0.004098360655737705\n",
      "0.004095004095004095\n",
      "0.004091653027823241\n",
      "0.004088307440719542\n",
      "0.004084967320261438\n",
      "0.004081632653061225\n",
      "0.004078303425774877\n",
      "0.004074979625101874\n",
      "0.004071661237785016\n",
      "0.0040683482506102524\n",
      "0.0040650406504065045\n",
      "0.004061738424045491\n",
      "0.004058441558441558\n",
      "0.0040551500405515\n",
      "0.004051863857374392\n",
      "0.004048582995951417\n",
      "0.0040453074433656954\n",
      "0.004042037186742118\n",
      "0.004038772213247173\n",
      "0.004035512510088781\n",
      "0.004032258064516129\n",
      "0.0040290088638195\n",
      "0.004025764895330112\n",
      "0.004022526146419952\n",
      "0.0040192926045016075\n",
      "0.004016064257028112\n",
      "0.0040128410914927765\n",
      "0.00400962309542903\n",
      "0.004006410256410256\n",
      "0.0040032025620496394\n",
      "0.004\n",
      "0.003996802557953637\n",
      "0.003993610223642172\n",
      "0.0039904229848363925\n",
      "0.003987240829346092\n",
      "0.00398406374501992\n",
      "0.003980891719745223\n",
      "0.003977724741447892\n",
      "0.00397456279809221\n",
      "0.003971405877680699\n",
      "0.003968253968253968\n",
      "0.003965107057890563\n",
      "0.003961965134706815\n",
      "0.00395882818685669\n",
      "0.003955696202531646\n",
      "0.003952569169960474\n",
      "0.0039494470774091624\n",
      "0.003946329913180742\n",
      "0.003943217665615142\n",
      "0.003940110323089046\n",
      "0.003937007874015748\n",
      "0.003933910306845004\n",
      "0.003930817610062893\n",
      "0.003927729772191673\n",
      "0.003924646781789639\n",
      "0.00392156862745098\n",
      "0.003918495297805642\n",
      "0.003915426781519186\n",
      "0.003912363067292645\n",
      "0.003909304143862392\n",
      "0.00390625\n",
      "0.0039032006245121\n",
      "0.0039001560062402497\n",
      "0.003897116134060795\n",
      "0.003894080996884735\n",
      "0.0038910505836575876\n",
      "0.0038880248833592537\n",
      "0.003885003885003885\n",
      "0.0038819875776397515\n",
      "0.003878975950349108\n",
      "0.003875968992248062\n",
      "0.0038729666924864447\n",
      "0.003869969040247678\n",
      "0.0038669760247486465\n",
      "0.0038639876352395673\n",
      "0.003861003861003861\n",
      "0.0038580246913580245\n",
      "0.0038550501156515036\n",
      "0.003852080123266564\n",
      "0.003849114703618168\n",
      "0.0038461538461538464\n",
      "0.003843197540353574\n",
      "0.0038402457757296467\n",
      "0.003837298541826554\n",
      "0.003834355828220859\n",
      "0.0038314176245210726\n",
      "0.0038284839203675345\n",
      "0.0038255547054322878\n",
      "0.00382262996941896\n",
      "0.0038197097020626434\n",
      "0.003816793893129771\n",
      "0.0038138825324180014\n",
      "0.0038109756097560975\n",
      "0.003808073115003808\n",
      "0.00380517503805175\n",
      "0.0038022813688212928\n",
      "0.003799392097264438\n",
      "0.0037965072133637054\n",
      "0.0037936267071320183\n",
      "0.0037907505686125853\n",
      "0.003787878787878788\n",
      "0.003785011355034065\n",
      "0.0037821482602118004\n",
      "0.003779289493575208\n",
      "0.0037764350453172208\n",
      "0.0037735849056603774\n",
      "0.003770739064856712\n",
      "0.0037678975131876413\n",
      "0.0037650602409638554\n",
      "0.003762227238525207\n",
      "0.0037593984962406013\n",
      "0.003756574004507889\n",
      "0.0037537537537537537\n",
      "0.0037509377344336083\n",
      "0.0037481259370314842\n",
      "0.003745318352059925\n",
      "0.0037425149700598802\n",
      "0.0037397157816005983\n",
      "0.0037369207772795215\n",
      "0.0037341299477221808\n",
      "0.0037313432835820895\n",
      "0.0037285607755406414\n",
      "0.0037257824143070045\n",
      "0.0037230081906180195\n",
      "0.003720238095238095\n",
      "0.0037174721189591076\n",
      "0.003714710252600297\n",
      "0.003711952487008166\n",
      "0.00370919881305638\n",
      "0.0037064492216456633\n",
      "0.003703703703703704\n",
      "0.003700962250185048\n",
      "0.0036982248520710057\n",
      "0.003695491500369549\n",
      "0.003692762186115214\n",
      "0.0036900369003690036\n",
      "0.003687315634218289\n",
      "0.0036845983787767134\n",
      "0.003681885125184094\n",
      "0.003679175864606328\n",
      "0.003676470588235294\n",
      "0.0036737692872887582\n",
      "0.003671071953010279\n",
      "0.003668378576669112\n",
      "0.0036656891495601175\n",
      "0.003663003663003663\n",
      "0.0036603221083455345\n",
      "0.0036576444769568397\n",
      "0.003654970760233918\n",
      "0.003652300949598247\n",
      "0.0036496350364963502\n",
      "0.0036469730123997084\n",
      "0.0036443148688046646\n",
      "0.003641660597232338\n",
      "0.00363901018922853\n",
      "0.0036363636363636364\n",
      "0.003633720930232558\n",
      "0.0036310820624546117\n",
      "0.00362844702467344\n",
      "0.0036258158085569255\n",
      "0.0036231884057971015\n",
      "0.003620564808110065\n",
      "0.00361794500723589\n",
      "0.0036153289949385392\n",
      "0.0036127167630057803\n",
      "0.0036101083032490976\n",
      "0.0036075036075036075\n",
      "0.003604902667627974\n",
      "0.0036023054755043226\n",
      "0.003599712023038157\n",
      "0.0035971223021582736\n",
      "0.0035945363048166786\n",
      "0.0035919540229885057\n",
      "0.003589375448671931\n",
      "0.003586800573888092\n",
      "0.0035842293906810036\n",
      "0.0035816618911174787\n",
      "0.0035790980672870437\n",
      "0.00357653791130186\n",
      "0.0035739814152966403\n",
      "0.0035714285714285713\n",
      "0.0035688793718772305\n",
      "0.003566333808844508\n",
      "0.003563791874554526\n",
      "0.0035612535612535613\n",
      "0.0035587188612099642\n",
      "0.0035561877667140826\n",
      "0.0035536602700781805\n",
      "0.0035511363636363635\n",
      "0.0035486160397444995\n",
      "0.0035460992907801418\n",
      "0.003543586109142452\n",
      "0.0035410764872521247\n",
      "0.003538570417551309\n",
      "0.003536067892503536\n",
      "0.0035335689045936395\n",
      "0.0035310734463276836\n",
      "0.0035285815102328866\n",
      "0.003526093088857546\n",
      "0.0035236081747709656\n",
      "0.0035211267605633804\n",
      "0.003518648838845883\n",
      "0.0035161744022503515\n",
      "0.0035137034434293743\n",
      "0.0035112359550561797\n",
      "0.0035087719298245615\n",
      "0.0035063113604488078\n",
      "0.00350385423966363\n",
      "0.0035014005602240898\n",
      "0.0034989503149055285\n",
      "0.0034965034965034965\n",
      "0.0034940600978336828\n",
      "0.0034916201117318434\n",
      "0.0034891835310537334\n",
      "0.003486750348675035\n",
      "0.003484320557491289\n",
      "0.003481894150417827\n",
      "0.003479471120389701\n",
      "0.0034770514603616135\n",
      "0.0034746351633078527\n",
      "0.003472222222222222\n",
      "0.0034698126301179735\n",
      "0.0034674063800277394\n",
      "0.003465003465003465\n",
      "0.0034626038781163434\n",
      "0.0034602076124567475\n",
      "0.003457814661134163\n",
      "0.0034554250172771253\n",
      "0.003453038674033149\n",
      "0.003450655624568668\n",
      "0.0034482758620689655\n",
      "0.0034458993797381117\n",
      "0.003443526170798898\n",
      "0.0034411562284927736\n",
      "0.0034387895460797797\n",
      "0.003436426116838488\n",
      "0.003434065934065934\n",
      "0.0034317089910775567\n",
      "0.003429355281207133\n",
      "0.003427004797806717\n",
      "0.003424657534246575\n",
      "0.0034223134839151265\n",
      "0.003419972640218878\n",
      "0.003417634996582365\n",
      "0.0034153005464480873\n",
      "0.0034129692832764505\n",
      "0.0034106412005457027\n",
      "0.0034083162917518746\n",
      "0.0034059945504087193\n",
      "0.0034036759700476512\n",
      "0.003401360544217687\n",
      "0.003399048266485384\n",
      "0.0033967391304347825\n",
      "0.0033944331296673455\n",
      "0.0033921302578018998\n",
      "0.003389830508474576\n",
      "0.0033875338753387536\n",
      "0.003385240352064997\n",
      "0.0033829499323410014\n",
      "0.0033806626098715348\n",
      "0.0033783783783783786\n",
      "0.00337609723160027\n",
      "0.0033738191632928477\n",
      "0.0033715441672285905\n",
      "0.0033692722371967657\n",
      "0.003367003367003367\n",
      "0.0033647375504710633\n",
      "0.0033624747814391394\n",
      "0.003360215053763441\n",
      "0.0033579583613163196\n",
      "0.003355704697986577\n",
      "0.00335345405767941\n",
      "0.003351206434316354\n",
      "0.003348961821835231\n",
      "0.0033467202141900937\n",
      "0.0033444816053511705\n",
      "0.0033422459893048127\n",
      "0.0033400133600534404\n",
      "0.0033377837116154874\n",
      "0.00333555703802535\n",
      "0.0033333333333333335\n",
      "0.0033311125916055963\n",
      "0.003328894806924101\n",
      "0.00332667997338656\n",
      "0.003324468085106383\n",
      "0.0033222591362126247\n",
      "0.0033200531208499337\n",
      "0.0033178500331785005\n",
      "0.0033156498673740055\n",
      "0.0033134526176275677\n",
      "0.0033112582781456954\n",
      "0.0033090668431502318\n",
      "0.0033068783068783067\n",
      "0.003304692663582287\n",
      "0.0033025099075297227\n",
      "0.0033003300330033004\n",
      "0.0032981530343007917\n",
      "0.0032959789057350032\n",
      "0.0032938076416337285\n",
      "0.0032916392363396972\n",
      "0.003289473684210526\n",
      "0.003287310979618672\n",
      "0.0032851511169513796\n",
      "0.003282994090610637\n",
      "0.0032808398950131233\n",
      "0.003278688524590164\n",
      "0.00327653997378768\n",
      "0.0032743942370661427\n",
      "0.0032722513089005235\n",
      "0.0032701111837802484\n",
      "0.0032679738562091504\n",
      "0.0032658393207054214\n",
      "0.0032637075718015664\n",
      "0.0032615786040443573\n",
      "0.003259452411994785\n",
      "0.003257328990228013\n",
      "0.0032552083333333335\n",
      "0.0032530904359141183\n",
      "0.003250975292587776\n",
      "0.003248862897985705\n",
      "0.003246753246753247\n",
      "0.003244646333549643\n",
      "0.00324254215304799\n",
      "0.0032404406999351912\n",
      "0.003238341968911917\n",
      "0.003236245954692557\n",
      "0.003234152652005175\n",
      "0.003232062055591467\n",
      "0.003229974160206718\n",
      "0.0032278889606197547\n",
      "0.0032258064516129032\n",
      "0.003223726627981947\n",
      "0.0032216494845360823\n",
      "0.003219575016097875\n",
      "0.0032175032175032173\n",
      "0.003215434083601286\n",
      "0.003213367609254499\n",
      "0.0032113037893384713\n",
      "0.003209242618741977\n",
      "0.003207184092366902\n",
      "0.003205128205128205\n",
      "0.0032030749519538757\n",
      "0.003201024327784891\n",
      "0.003198976327575176\n",
      "0.00319693094629156\n",
      "0.003194888178913738\n",
      "0.0031928480204342275\n",
      "0.003190810465858328\n",
      "0.0031887755102040817\n",
      "0.0031867431485022306\n",
      "0.0031847133757961785\n",
      "0.003182686187141948\n",
      "0.0031806615776081423\n",
      "0.003178639542275906\n",
      "0.0031766200762388818\n",
      "0.0031746031746031746\n",
      "0.0031725888324873096\n",
      "0.0031705770450221942\n",
      "0.0031685678073510772\n",
      "0.0031665611146295125\n",
      "0.0031645569620253164\n",
      "0.0031625553447185324\n",
      "0.0031605562579013905\n",
      "0.003158559696778269\n",
      "0.0031565656565656565\n",
      "0.0031545741324921135\n",
      "0.0031525851197982345\n",
      "0.00315059861373661\n",
      "0.0031486146095717885\n",
      "0.0031466331025802393\n",
      "0.0031446540880503146\n",
      "0.0031426775612822125\n",
      "0.00314070351758794\n",
      "0.003138731952291274\n",
      "0.003136762860727729\n",
      "0.003134796238244514\n",
      "0.003132832080200501\n",
      "0.0031308703819661866\n",
      "0.0031289111389236545\n",
      "0.0031269543464665416\n",
      "0.003125\n",
      "0.003123048094940662\n",
      "0.003121098626716604\n",
      "0.0031191515907673115\n",
      "0.003117206982543641\n",
      "0.003115264797507788\n",
      "0.00311332503113325\n",
      "0.0031113876789047915\n",
      "0.003109452736318408\n",
      "0.003107520198881293\n",
      "0.003105590062111801\n",
      "0.0031036623215394167\n",
      "0.003101736972704715\n",
      "0.0030998140111593306\n",
      "0.0030978934324659233\n",
      "0.0030959752321981426\n",
      "0.003094059405940594\n",
      "0.0030921459492888066\n",
      "0.0030902348578491965\n",
      "0.0030883261272390363\n",
      "0.0030864197530864196\n",
      "0.0030845157310302285\n",
      "0.0030826140567200987\n",
      "0.0030807147258163892\n",
      "0.003078817733990148\n",
      "0.003076923076923077\n",
      "0.003075030750307503\n",
      "0.003073140749846343\n",
      "0.003071253071253071\n",
      "0.003069367710251688\n",
      "0.003067484662576687\n",
      "0.0030656039239730227\n",
      "0.0030637254901960784\n",
      "0.003061849357011635\n",
      "0.0030599755201958386\n",
      "0.0030581039755351682\n",
      "0.003056234718826406\n",
      "0.0030543677458766036\n",
      "0.0030525030525030525\n",
      "0.003050640634533252\n",
      "0.003048780487804878\n",
      "0.0030469226081657527\n",
      "0.0030450669914738123\n",
      "0.0030432136335970784\n",
      "0.0030413625304136255\n",
      "0.00303951367781155\n",
      "0.003037667071688943\n",
      "0.0030358227079538553\n",
      "0.003033980582524272\n",
      "0.0030321406913280777\n",
      "0.0030303030303030303\n",
      "0.0030284675953967293\n",
      "0.003026634382566586\n",
      "0.0030248033877797943\n",
      "0.003022974607013301\n",
      "0.0030211480362537764\n",
      "0.0030193236714975845\n",
      "0.0030175015087507543\n",
      "0.0030156815440289505\n",
      "0.0030138637733574444\n",
      "0.0030120481927710845\n",
      "0.0030102347983142685\n",
      "0.0030084235860409147\n",
      "0.003006614552014432\n",
      "0.0030048076923076925\n",
      "0.003003003003003003\n",
      "0.003001200480192077\n",
      "0.002999400119976005\n",
      "0.002997601918465228\n",
      "0.0029958058717795086\n",
      "0.0029940119760479044\n",
      "0.002992220227408737\n",
      "0.0029904306220095694\n",
      "0.002988643156007173\n",
      "0.002986857825567503\n",
      "0.0029850746268656717\n",
      "0.0029832935560859188\n",
      "0.0029815146094215863\n",
      "0.0029797377830750892\n",
      "0.0029779630732578916\n",
      "0.002976190476190476\n",
      "0.00297441998810232\n",
      "0.002972651605231867\n",
      "0.0029708853238265003\n",
      "0.0029691211401425177\n",
      "0.002967359050445104\n",
      "0.0029655990510083037\n",
      "0.002963841138114997\n",
      "0.002962085308056872\n",
      "0.002960331557134399\n",
      "0.0029585798816568047\n",
      "0.0029568302779420462\n",
      "0.002955082742316785\n",
      "0.0029533372711163615\n",
      "0.0029515938606847697\n",
      "0.0029498525073746312\n",
      "0.00294811320754717\n",
      "0.0029463759575721863\n",
      "0.002944640753828033\n",
      "0.002942907592701589\n",
      "0.0029411764705882353\n",
      "0.0029394473838918285\n",
      "0.002937720329024677\n",
      "0.002935995302407516\n",
      "0.0029342723004694834\n",
      "0.002932551319648094\n",
      "0.0029308323563892145\n",
      "0.0029291154071470417\n",
      "0.002927400468384075\n",
      "0.002925687536571094\n",
      "0.0029239766081871343\n",
      "0.0029222676797194622\n",
      "0.0029205607476635513\n",
      "0.002918855808523059\n",
      "0.0029171528588098016\n",
      "0.0029154518950437317\n",
      "0.002913752913752914\n",
      "0.0029120559114735\n",
      "0.002910360884749709\n",
      "0.0029086678301337987\n",
      "0.0029069767441860465\n",
      "0.002905287623474724\n",
      "0.0029036004645760743\n",
      "0.002901915264074289\n",
      "0.002900232018561485\n",
      "0.002898550724637681\n",
      "0.0028968713789107765\n",
      "0.0028951939779965257\n",
      "0.0028935185185185184\n",
      "0.002891844997108155\n",
      "0.002890173410404624\n",
      "0.0028885037550548816\n",
      "0.002886836027713626\n",
      "0.0028851702250432777\n",
      "0.0028835063437139563\n",
      "0.002881844380403458\n",
      "0.002880184331797235\n",
      "0.0028785261945883708\n",
      "0.0028768699654775605\n",
      "0.002875215641173088\n",
      "0.0028735632183908046\n",
      "0.002871912693854107\n",
      "0.0028702640642939152\n",
      "0.002868617326448652\n",
      "0.0028669724770642203\n",
      "0.0028653295128939827\n",
      "0.0028636884306987398\n",
      "0.0028620492272467086\n",
      "0.002860411899313501\n",
      "0.002858776443682104\n",
      "0.002857142857142857\n",
      "0.0028555111364934323\n",
      "0.0028538812785388126\n",
      "0.002852253280091272\n",
      "0.0028506271379703536\n",
      "0.002849002849002849\n",
      "0.0028473804100227792\n",
      "0.0028457598178713715\n",
      "0.002844141069397042\n",
      "0.0028425241614553724\n",
      "0.002840909090909091\n",
      "0.0028392958546280523\n",
      "0.0028376844494892167\n",
      "0.0028360748723766306\n",
      "0.002834467120181406\n",
      "0.0028328611898017\n",
      "0.0028312570781426952\n",
      "0.0028296547821165816\n",
      "0.002828054298642534\n",
      "0.002826455624646693\n",
      "0.002824858757062147\n",
      "0.00282326369282891\n",
      "0.0028216704288939053\n",
      "0.0028200789622109417\n",
      "0.002818489289740699\n",
      "0.0028169014084507044\n",
      "0.002815315315315315\n",
      "0.0028137310073157004\n",
      "0.00281214848143982\n",
      "0.002810567734682406\n",
      "0.0028089887640449437\n",
      "0.002807411566535654\n",
      "0.0028058361391694723\n",
      "0.0028042624789680315\n",
      "0.002802690582959641\n",
      "0.0028011204481792717\n",
      "0.002799552071668533\n",
      "0.0027979854504756574\n",
      "0.002796420581655481\n",
      "0.002794857462269424\n",
      "0.002793296089385475\n",
      "0.0027917364600781687\n",
      "0.0027901785714285715\n",
      "0.002788622420524261\n",
      "0.002787068004459309\n",
      "0.002785515320334262\n",
      "0.0027839643652561247\n",
      "0.0027824151363383415\n",
      "0.0027808676307007787\n",
      "0.0027793218454697055\n",
      "0.002777777777777778\n",
      "0.00277623542476402\n",
      "0.002774694783573807\n",
      "0.0027731558513588465\n",
      "0.002771618625277162\n",
      "0.002770083102493075\n",
      "0.0027685492801771874\n",
      "0.002767017155506364\n",
      "0.0027654867256637168\n",
      "0.002763957987838585\n",
      "0.0027624309392265192\n",
      "0.0027609055770292656\n",
      "0.0027593818984547464\n",
      "0.0027578599007170436\n",
      "0.0027563395810363835\n",
      "0.0027548209366391185\n",
      "0.0027533039647577094\n",
      "0.00275178866263071\n",
      "0.0027502750275027505\n",
      "0.002748763056624519\n",
      "0.0027472527472527475\n",
      "0.0027457440966501922\n",
      "0.0027442371020856204\n",
      "0.0027427317608337905\n",
      "0.0027412280701754384\n",
      "0.0027397260273972603\n",
      "0.002738225629791895\n",
      "0.002736726874657909\n",
      "0.002735229759299781\n",
      "0.002733734281027884\n",
      "0.00273224043715847\n",
      "0.002730748225013654\n",
      "0.0027292576419213972\n",
      "0.002727768685215494\n",
      "0.0027262813522355507\n",
      "0.0027247956403269754\n",
      "0.0027233115468409588\n",
      "0.0027218290691344584\n",
      "0.002720348204570185\n",
      "0.0027188689505165853\n",
      "0.002717391304347826\n",
      "0.0027159152634437804\n",
      "0.0027144408251900108\n",
      "0.0027129679869777536\n",
      "0.0027114967462039045\n",
      "0.0027100271002710027\n",
      "0.0027085590465872156\n",
      "0.0027070925825663237\n",
      "0.0027056277056277055\n",
      "0.0027041644131963224\n",
      "0.002702702702702703\n",
      "0.002701242571582928\n",
      "0.0026997840172786176\n",
      "0.002698327037236913\n",
      "0.002696871628910464\n",
      "0.0026954177897574125\n",
      "0.0026939655172413795\n",
      "0.0026925148088314485\n",
      "0.002691065662002153\n",
      "0.0026896180742334587\n",
      "0.002688172043010753\n",
      "0.0026867275658248252\n",
      "0.0026852846401718583\n",
      "0.0026838432635534087\n",
      "0.002682403433476395\n",
      "0.002680965147453083\n",
      "0.0026795284030010718\n",
      "0.002678093197643278\n",
      "0.0026766595289079227\n",
      "0.002675227394328518\n",
      "0.00267379679144385\n",
      "0.002672367717797969\n",
      "0.002670940170940171\n",
      "0.0026695141484249867\n",
      "0.0026680896478121665\n",
      "0.0026666666666666666\n",
      "0.0026652452025586353\n",
      "0.002663825253063399\n",
      "0.0026624068157614484\n",
      "0.0026609898882384245\n",
      "0.0026595744680851063\n",
      "0.002658160552897395\n",
      "0.002656748140276302\n",
      "0.0026553372278279343\n",
      "0.002653927813163482\n",
      "0.002652519893899204\n",
      "0.002651113467656416\n",
      "0.002649708532061473\n",
      "0.0026483050847457626\n",
      "0.0026469031233456856\n",
      "0.0026455026455026454\n",
      "0.0026441036488630354\n",
      "0.002642706131078224\n",
      "0.002641310089804543\n",
      "0.0026399155227032735\n",
      "0.002638522427440633\n",
      "0.0026371308016877636\n",
      "0.002635740643120717\n",
      "0.0026343519494204425\n",
      "0.0026329647182727752\n",
      "0.002631578947368421\n",
      "0.0026301946344029457\n",
      "0.0026288117770767614\n",
      "0.002627430373095113\n",
      "0.0026260504201680674\n",
      "0.0026246719160104987\n",
      "0.0026232948583420775\n",
      "0.0026219192448872575\n",
      "0.002620545073375262\n",
      "0.0026191723415400735\n",
      "0.002617801047120419\n",
      "0.0026164311878597592\n",
      "0.002615062761506276\n",
      "0.0026136957658128594\n",
      "0.002612330198537095\n",
      "0.0026109660574412533\n",
      "0.0026096033402922755\n",
      "0.0026082420448617634\n",
      "0.0026068821689259644\n",
      "0.0026055237102657635\n",
      "0.0026041666666666665\n",
      "0.0026028110359187923\n",
      "0.0026014568158168575\n",
      "0.0026001040041601664\n",
      "0.002598752598752599\n",
      "0.0025974025974025974\n",
      "0.002596053997923157\n",
      "0.002594706798131811\n",
      "0.0025933609958506223\n",
      "0.002592016588906169\n",
      "0.0025906735751295338\n",
      "0.002589331952356292\n",
      "0.002587991718426501\n",
      "0.002586652871184687\n",
      "0.0025853154084798345\n",
      "0.002583979328165375\n",
      "0.0025826446280991736\n",
      "0.002581311306143521\n",
      "0.0025799793601651187\n",
      "0.0025786487880350697\n",
      "0.002577319587628866\n",
      "0.002575991756826378\n",
      "0.0025746652935118436\n",
      "0.0025733401955738548\n",
      "0.00257201646090535\n",
      "0.002570694087403599\n",
      "0.0025693730729701952\n",
      "0.0025680534155110425\n",
      "0.002566735112936345\n",
      "0.002565418163160595\n",
      "0.002564102564102564\n",
      "0.0025627883136852894\n",
      "0.0025614754098360654\n",
      "0.002560163850486431\n",
      "0.00255885363357216\n",
      "0.0025575447570332483\n",
      "0.002556237218813906\n",
      "0.0025549310168625446\n",
      "0.002553626149131767\n",
      "0.002552322613578356\n",
      "0.002551020408163265\n",
      "0.0025497195308516064\n",
      "0.0025484199796126403\n",
      "0.0025471217524197657\n",
      "0.0025458248472505093\n",
      "0.002544529262086514\n",
      "0.00254323499491353\n",
      "0.002541942043721403\n",
      "0.002540650406504065\n",
      "0.0025393600812595226\n",
      "0.0025380710659898475\n",
      "0.0025367833587011668\n",
      "0.002535496957403651\n",
      "0.002534211860111505\n",
      "0.0025329280648429585\n",
      "0.002531645569620253\n",
      "0.0025303643724696357\n",
      "0.0025290844714213456\n",
      "0.0025278058645096056\n",
      "0.0025265285497726125\n",
      "0.0025252525252525255\n",
      "0.002523977788995457\n",
      "0.0025227043390514633\n",
      "0.0025214321734745334\n",
      "0.0025201612903225806\n",
      "0.0025188916876574307\n",
      "0.0025176233635448137\n",
      "0.0025163563160543532\n",
      "0.0025150905432595573\n",
      "0.002513826043237808\n",
      "0.002512562814070352\n",
      "0.0025113008538422904\n",
      "0.0025100401606425703\n",
      "0.002508780732563974\n",
      "0.0025075225677031092\n",
      "0.002506265664160401\n",
      "0.00250501002004008\n",
      "0.0025037556334501754\n",
      "0.0025025025025025025\n",
      "0.0025012506253126563\n",
      "0.0025\n",
      "0.0024987506246876563\n",
      "0.0024975024975024975\n",
      "0.0024962556165751375\n",
      "0.00249500998003992\n",
      "0.0024937655860349127\n",
      "0.0024925224327018943\n",
      "0.002491280518186348\n",
      "0.00249003984063745\n",
      "0.0024888003982080635\n",
      "0.0024875621890547263\n",
      "0.002486325211337643\n",
      "0.002485089463220676\n",
      "0.0024838549428713363\n",
      "0.0024826216484607746\n",
      "0.0024813895781637717\n",
      "0.00248015873015873\n",
      "0.002478929102627665\n",
      "0.002477700693756194\n",
      "0.0024764735017335313\n",
      "0.0024752475247524753\n",
      "0.002474022761009401\n",
      "0.002472799208704253\n",
      "0.002471576866040534\n",
      "0.0024703557312252965\n",
      "0.0024691358024691358\n",
      "0.0024679170779861796\n",
      "0.00246669955599408\n",
      "0.002465483234714004\n",
      "0.0024642681123706258\n",
      "0.0024630541871921183\n",
      "0.002461841457410143\n",
      "0.0024606299212598425\n",
      "0.002459419576979833\n",
      "0.0024582104228121925\n",
      "0.002457002457002457\n",
      "0.002455795677799607\n",
      "0.002454590083456063\n",
      "0.0024533856722276743\n",
      "0.0024521824423737125\n",
      "0.0024509803921568627\n",
      "0.002449779519843214\n",
      "0.002448579823702253\n",
      "0.0024473813020068525\n",
      "0.002446183953033268\n",
      "0.0024449877750611247\n",
      "0.0024437927663734115\n",
      "0.002442598925256473\n",
      "0.00244140625\n",
      "0.002440214738897023\n",
      "0.0024390243902439024\n",
      "0.0024378352023403218\n",
      "0.0024366471734892786\n",
      "0.0024354603019970775\n",
      "0.0024342745861733205\n",
      "0.0024330900243309003\n",
      "0.0024319066147859923\n",
      "0.0024307243558580457\n",
      "0.0024295432458697765\n",
      "0.0024283632831471587\n",
      "0.0024271844660194173\n",
      "0.0024260067928190197\n",
      "0.0024248302618816685\n",
      "0.0024236548715462916\n",
      "0.0024224806201550387\n",
      "0.002421307506053269\n",
      "0.002420135527589545\n",
      "0.0024189646831156266\n",
      "0.0024177949709864605\n",
      "0.002416626389560174\n",
      "0.0024154589371980675\n",
      "0.0024142926122646064\n",
      "0.002413127413127413\n",
      "0.00241196333815726\n",
      "0.0024108003857280617\n",
      "0.0024096385542168677\n",
      "0.0024084778420038534\n",
      "0.002407318247472316\n",
      "0.002406159769008662\n",
      "0.002405002405002405\n",
      "0.002403846153846154\n",
      "0.002402691013935608\n",
      "0.0024015369836695487\n",
      "0.002400384061449832\n",
      "0.0023992322456813818\n",
      "0.002398081534772182\n",
      "0.0023969319271332696\n",
      "0.0023957834211787254\n",
      "0.0023946360153256703\n",
      "0.0023934897079942556\n",
      "0.0023923444976076554\n",
      "0.0023912003825920613\n",
      "0.002390057361376673\n",
      "0.0023889154323936935\n",
      "0.002387774594078319\n",
      "0.002386634844868735\n",
      "0.002385496183206107\n",
      "0.002384358607534573\n",
      "0.0023832221163012394\n",
      "0.0023820867079561697\n",
      "0.002380952380952381\n",
      "0.002379819133745835\n",
      "0.002378686964795433\n",
      "0.0023775558725630053\n",
      "0.002376425855513308\n",
      "0.0023752969121140144\n",
      "0.0023741690408357074\n",
      "0.0023730422401518746\n",
      "0.0023719165085388993\n",
      "0.002370791844476055\n",
      "0.002369668246445498\n",
      "0.0023685457129322598\n",
      "0.0023674242424242425\n",
      "0.00236630383341221\n",
      "0.0023651844843897824\n",
      "0.002364066193853428\n",
      "0.0023629489603024575\n",
      "0.0023618327822390174\n",
      "0.002360717658168083\n",
      "0.0023596035865974517\n",
      "0.0023584905660377358\n",
      "0.0023573785950023575\n",
      "0.00235626767200754\n",
      "0.0023551577955723034\n",
      "0.0023540489642184556\n",
      "0.002352941176470588\n",
      "0.0023518344308560675\n",
      "0.0023507287259050304\n",
      "0.002349624060150376\n",
      "0.0023485204321277596\n",
      "0.002347417840375587\n",
      "0.002346316283435007\n",
      "0.0023452157598499064\n",
      "0.0023441162681669013\n",
      "0.0023430178069353325\n",
      "0.00234192037470726\n",
      "0.0023408239700374533\n",
      "0.002339728591483388\n",
      "0.0023386342376052385\n",
      "0.0023375409069658717\n",
      "0.002336448598130841\n",
      "0.002335357309668379\n",
      "0.002334267040149393\n",
      "0.0023331777881474567\n",
      "0.0023320895522388058\n",
      "0.002331002331002331\n",
      "0.002329916123019571\n",
      "0.002328830926874709\n",
      "0.0023277467411545625\n",
      "0.002326663564448581\n",
      "0.002325581395348837\n",
      "0.0023245002324500234\n",
      "0.0023234200743494425\n",
      "0.0023223409196470044\n",
      "0.002321262766945218\n",
      "0.002320185614849188\n",
      "0.002319109461966605\n",
      "0.0023180343069077423\n",
      "0.0023169601482854493\n",
      "0.002315886984715146\n",
      "0.0023148148148148147\n",
      "0.0023137436372049976\n",
      "0.002312673450508788\n",
      "0.002311604253351826\n",
      "0.0023105360443622922\n",
      "0.0023094688221709007\n",
      "0.0023084025854108957\n",
      "0.0023073373327180432\n",
      "0.0023062730627306273\n",
      "0.002305209774089442\n",
      "0.002304147465437788\n",
      "0.0023030861354214646\n",
      "0.0023020257826887663\n",
      "0.002300966405890474\n",
      "0.0022999080036798527\n",
      "0.0022988505747126436\n",
      "0.002297794117647059\n",
      "0.0022967386311437757\n",
      "0.002295684113865932\n",
      "0.002294630564479119\n",
      "0.0022935779816513763\n",
      "0.0022925263640531865\n",
      "0.00229147571035747\n",
      "0.0022904260192395786\n",
      "0.0022893772893772895\n",
      "0.002288329519450801\n",
      "0.0022872827081427266\n",
      "0.002286236854138089\n",
      "0.0022851919561243145\n",
      "0.0022841480127912287\n",
      "0.00228310502283105\n",
      "0.0022820629849383844\n",
      "0.002281021897810219\n",
      "0.002279981760145919\n",
      "0.0022789425706472195\n",
      "0.002277904328018223\n",
      "0.002276867030965392\n",
      "0.002275830678197542\n",
      "0.0022747952684258415\n",
      "0.002273760800363802\n",
      "0.0022727272727272726\n",
      "0.002271694684234439\n",
      "0.002270663033605813\n",
      "0.0022696323195642307\n",
      "0.002268602540834846\n",
      "0.0022675736961451248\n",
      "0.0022665457842248413\n",
      "0.0022655188038060714\n",
      "0.0022644927536231885\n",
      "0.0022634676324128564\n",
      "0.0022624434389140274\n",
      "0.002261420171867933\n",
      "0.0022603978300180833\n",
      "0.0022593764121102574\n",
      "0.002258355916892502\n",
      "0.002257336343115124\n",
      "0.002256317689530686\n",
      "0.0022552999548940008\n",
      "0.002254283137962128\n",
      "0.002253267237494367\n",
      "0.0022522522522522522\n",
      "0.0022512381809995496\n",
      "0.0022502250225022503\n",
      "0.002249212775528565\n",
      "0.0022482014388489208\n",
      "0.0022471910112359553\n",
      "0.0022461814914645105\n",
      "0.00224517287831163\n",
      "0.002244165170556553\n",
      "0.0022431583669807087\n",
      "0.002242152466367713\n",
      "0.0022411474675033617\n",
      "0.002240143369175627\n",
      "0.0022391401701746527\n",
      "0.0022381378692927483\n",
      "0.0022371364653243847\n",
      "0.0022361359570661895\n",
      "0.002235136343316942\n",
      "0.002234137622877569\n",
      "0.0022331397945511387\n",
      "0.002232142857142857\n",
      "0.0022311468094600626\n",
      "0.0022301516503122213\n",
      "0.002229157378510923\n",
      "0.0022281639928698753\n",
      "0.0022271714922048997\n",
      "0.002226179875333927\n",
      "0.0022251891410769915\n",
      "0.002224199288256228\n",
      "0.0022232103156958646\n",
      "0.0022222222222222222\n",
      "0.002221235006663705\n",
      "0.002220248667850799\n",
      "0.0022192632046160675\n",
      "0.0022182786157941437\n",
      "0.0022172949002217295\n",
      "0.002216312056737589\n",
      "0.002215330084182543\n",
      "0.0022143489813994687\n",
      "0.002213368747233289\n",
      "0.0022123893805309734\n",
      "0.0022114108801415304\n",
      "0.0022104332449160036\n",
      "0.002209456473707468\n",
      "0.002208480565371025\n",
      "0.002207505518763797\n",
      "0.002206531332744925\n",
      "0.0022055580061755625\n",
      "0.002204585537918871\n",
      "0.0022036139268400176\n",
      "0.0022026431718061676\n",
      "0.002201673271686482\n",
      "0.0022007042253521128\n",
      "0.002199736031676199\n",
      "0.0021987686895338612\n",
      "0.002197802197802198\n",
      "0.0021968365553602814\n",
      "0.0021958717610891525\n",
      "0.0021949078138718174\n",
      "0.002193944712593243\n",
      "0.0021929824561403508\n",
      "0.0021920210434020165\n",
      "0.0021910604732690623\n",
      "0.002190100744634253\n",
      "0.0021891418563922942\n",
      "0.002188183807439825\n",
      "0.0021872265966754157\n",
      "0.0021862702229995625\n",
      "0.0021853146853146855\n",
      "0.00218435998252512\n",
      "0.002183406113537118\n",
      "0.002182453077258839\n",
      "0.002181500872600349\n",
      "0.002180549498473615\n",
      "0.002179598953792502\n",
      "0.002178649237472767\n",
      "0.0021777003484320556\n",
      "0.0021767522855899\n",
      "0.002175805047867711\n",
      "0.002174858634188778\n",
      "0.002173913043478261\n",
      "0.0021729682746631897\n",
      "0.002172024326672459\n",
      "0.0021710811984368217\n",
      "0.002170138888888889\n",
      "0.0021691973969631237\n",
      "0.002168256721595837\n",
      "0.002167316861725184\n",
      "0.002166377816291161\n",
      "0.0021654395842356\n",
      "0.0021645021645021645\n",
      "0.0021635655560363477\n",
      "0.0021626297577854673\n",
      "0.00216169476869866\n",
      "0.00216076058772688\n",
      "0.0021598272138228943\n",
      "0.002158894645941278\n",
      "0.0021579628830384117\n",
      "0.0021570319240724763\n",
      "0.0021561017680034496\n",
      "0.0021551724137931034\n",
      "0.002154243860404998\n",
      "0.002153316106804479\n",
      "0.002152389151958674\n",
      "0.0021514629948364886\n",
      "0.002150537634408602\n",
      "0.0021496130696474634\n",
      "0.0021486892995272885\n",
      "0.002147766323024055\n",
      "0.0021468441391155\n",
      "0.002145922746781116\n",
      "0.002145002145002145\n",
      "0.002144082332761578\n",
      "0.0021431633090441492\n",
      "0.0021422450728363325\n",
      "0.0021413276231263384\n",
      "0.0021404109589041095\n",
      "0.002139495079161318\n",
      "0.00213857998289136\n",
      "0.0021376656690893546\n",
      "0.002136752136752137\n",
      "0.0021358393848782574\n",
      "0.002134927412467976\n",
      "0.002134016218523261\n",
      "0.0021331058020477816\n",
      "0.0021321961620469083\n",
      "0.002131287297527707\n",
      "0.0021303792074989347\n",
      "0.002129471890971039\n",
      "0.0021285653469561515\n",
      "0.002127659574468085\n",
      "0.002126754572522331\n",
      "0.0021258503401360546\n",
      "0.0021249468763280916\n",
      "0.0021240441801189465\n",
      "0.0021231422505307855\n",
      "0.0021222410865874364\n",
      "0.0021213406873143827\n",
      "0.0021204410517387615\n",
      "0.00211954217888936\n",
      "0.00211864406779661\n",
      "0.0021177467174925877\n",
      "0.0021168501270110076\n",
      "0.0021159542953872196\n",
      "0.0021150592216582064\n",
      "0.0021141649048625794\n",
      "0.002113271344040575\n",
      "0.0021123785382340513\n",
      "0.0021114864864864866\n",
      "0.002110595187842972\n",
      "0.002109704641350211\n",
      "0.002108814846056516\n",
      "0.0021079258010118043\n",
      "0.002107037505267594\n",
      "0.0021061499578770007\n",
      "0.002105263157894737\n",
      "0.0021043771043771043\n",
      "0.002103491796381994\n",
      "0.0021026072329688814\n",
      "0.002101723413198823\n",
      "0.0021008403361344537\n",
      "0.0020999580008399833\n",
      "0.0020990764063811922\n",
      "0.00209819555182543\n",
      "0.0020973154362416107\n",
      "0.0020964360587002098\n",
      "0.0020955574182732607\n",
      "0.0020946795140343527\n",
      "0.0020938023450586263\n",
      "0.002092925910422771\n",
      "0.0020920502092050207\n",
      "0.002091175240485153\n",
      "0.0020903010033444815\n",
      "0.002089427496865859\n",
      "0.0020885547201336674\n",
      "0.0020876826722338203\n",
      "0.002086811352253756\n",
      "0.0020859407592824365\n",
      "0.002085070892410342\n",
      "0.0020842017507294707\n",
      "0.0020833333333333333\n",
      "0.0020824656393169513\n",
      "0.0020815986677768525\n",
      "0.0020807324178110697\n",
      "0.0020798668885191347\n",
      "0.002079002079002079\n",
      "0.0020781379883624274\n",
      "0.002077274615704196\n",
      "0.0020764119601328905\n",
      "0.0020755500207555004\n",
      "0.002074688796680498\n",
      "0.002073828287017835\n",
      "0.0020729684908789387\n",
      "0.0020721094073767096\n",
      "0.002071251035625518\n",
      "0.002070393374741201\n",
      "0.0020695364238410598\n",
      "0.002068680182043856\n",
      "0.0020678246484698098\n",
      "0.002066969822240595\n",
      "0.002066115702479339\n",
      "0.0020652622883106154\n",
      "0.002064409578860446\n",
      "0.0020635575732562937\n",
      "0.0020627062706270625\n",
      "0.002061855670103093\n",
      "0.002061005770816158\n",
      "0.0020601565718994645\n",
      "0.002059308072487644\n",
      "0.0020584602717167557\n",
      "0.00205761316872428\n",
      "0.0020567667626491155\n",
      "0.002055921052631579\n",
      "0.002055076037813399\n",
      "0.002054231717337716\n",
      "0.002053388090349076\n",
      "0.002052545155993432\n",
      "0.002051702913418137\n",
      "0.002050861361771944\n",
      "0.002050020500205002\n",
      "0.0020491803278688526\n",
      "0.0020483408439164277\n",
      "0.0020475020475020475\n",
      "0.002046663937781416\n",
      "0.0020458265139116204\n",
      "0.002044989775051125\n",
      "0.002044153720359771\n",
      "0.002043318348998774\n",
      "0.002042483660130719\n",
      "0.002041649652919559\n",
      "0.0020408163265306124\n",
      "0.002039983680130559\n",
      "0.0020391517128874386\n",
      "0.0020383204239706482\n",
      "0.002037489812550937\n",
      "0.002036659877800407\n",
      "0.002035830618892508\n",
      "0.002035002035002035\n",
      "0.0020341741253051262\n",
      "0.0020333468889792597\n",
      "0.0020325203252032522\n",
      "0.0020316944331572532\n",
      "0.0020308692120227455\n",
      "0.0020300446609825416\n",
      "0.002029220779220779\n",
      "0.002028397565922921\n",
      "0.00202757502027575\n",
      "0.002026753141467369\n",
      "0.002025931928687196\n",
      "0.002025111381125962\n",
      "0.0020242914979757085\n",
      "0.0020234722784297854\n",
      "0.0020226537216828477\n",
      "0.0020218358269308533\n",
      "0.002021018593371059\n",
      "0.00202020202020202\n",
      "0.0020193861066235864\n",
      "0.0020185708518368995\n",
      "0.0020177562550443904\n",
      "0.002016942315449778\n",
      "0.0020161290322580645\n",
      "0.002015316404675534\n",
      "0.00201450443190975\n",
      "0.002013693113169553\n",
      "0.002012882447665056\n",
      "0.002012072434607646\n",
      "0.002011263073209976\n",
      "0.002010454362685967\n",
      "0.0020096463022508037\n",
      "0.002008838891120932\n",
      "0.002008032128514056\n",
      "0.002007226013649137\n",
      "0.0020064205457463883\n",
      "0.0020056157240272766\n",
      "0.002004811547714515\n",
      "0.002004008016032064\n",
      "0.002003205128205128\n",
      "0.002002402883460152\n",
      "0.0020016012810248197\n",
      "0.0020008003201280513\n",
      "0.002\n",
      "0.001999200319872051\n",
      "0.0019984012789768186\n",
      "0.001997602876548142\n",
      "0.001996805111821086\n",
      "0.001996007984031936\n",
      "0.0019952114924181963\n",
      "0.001994415636218588\n",
      "0.001993620414673046\n",
      "0.0019928258270227183\n",
      "0.00199203187250996\n",
      "0.001991238550378335\n",
      "0.0019904458598726115\n",
      "0.0019896538002387586\n",
      "0.001988862370723946\n",
      "0.0019880715705765406\n",
      "0.001987281399046105\n",
      "0.001986491855383393\n",
      "0.0019857029388403494\n",
      "0.001984914648670107\n",
      "0.001984126984126984\n",
      "0.0019833399444664813\n",
      "0.0019825535289452814\n",
      "0.0019817677368212444\n",
      "0.0019809825673534074\n",
      "0.0019801980198019802\n",
      "0.001979414093428345\n",
      "0.0019786307874950534\n",
      "0.001977848101265823\n",
      "0.0019770660340055358\n",
      "0.001976284584980237\n",
      "0.0019755037534571317\n",
      "0.0019747235387045812\n",
      "0.0019739439399921043\n",
      "0.001973164956590371\n",
      "0.0019723865877712033\n",
      "0.001971608832807571\n",
      "0.001970831690973591\n",
      "0.001970055161544523\n",
      "0.0019692792437967705\n",
      "0.001968503937007874\n",
      "0.0019677292404565133\n",
      "0.001966955153422502\n",
      "0.001966181675186787\n",
      "0.0019654088050314465\n",
      "0.0019646365422396855\n",
      "0.0019638648860958365\n",
      "0.0019630938358853552\n",
      "0.0019623233908948193\n",
      "0.001961553550411926\n",
      "0.00196078431372549\n",
      "0.001960015680125441\n",
      "0.001959247648902821\n",
      "0.0019584802193497847\n",
      "0.001957713390759593\n",
      "0.0019569471624266144\n",
      "0.0019561815336463224\n",
      "0.0019554165037152915\n",
      "0.001954652071931196\n",
      "0.0019538882375928096\n",
      "0.001953125\n",
      "0.001952362358453729\n",
      "0.00195160031225605\n",
      "0.0019508388607101053\n",
      "0.0019500780031201249\n",
      "0.001949317738791423\n",
      "0.0019485580670303975\n",
      "0.0019477989871445266\n",
      "0.0019470404984423676\n",
      "0.001946282600233554\n",
      "0.0019455252918287938\n",
      "0.0019447685725398677\n",
      "0.0019440124416796269\n",
      "0.00194325689856199\n",
      "0.0019425019425019425\n",
      "0.001941747572815534\n",
      "0.0019409937888198758\n",
      "0.0019402405898331393\n",
      "0.001939487975174554\n",
      "0.0019387359441644049\n",
      "0.001937984496124031\n",
      "0.0019372336303758234\n",
      "0.0019364833462432224\n",
      "0.0019357336430507162\n",
      "0.001934984520123839\n",
      "0.0019342359767891683\n",
      "0.0019334880123743233\n",
      "0.001932740626207963\n",
      "0.0019319938176197836\n",
      "0.0019312475859405175\n",
      "0.0019305019305019305\n",
      "0.0019297568506368198\n",
      "0.0019290123456790122\n",
      "0.0019282684149633628\n",
      "0.0019275250578257518\n",
      "0.0019267822736030828\n",
      "0.001926040061633282\n",
      "0.0019252984212552945\n",
      "0.001924557351809084\n",
      "0.001923816852635629\n",
      "0.0019230769230769232\n",
      "0.0019223375624759708\n",
      "0.001921598770176787\n",
      "0.001920860545524395\n",
      "0.0019201228878648233\n",
      "0.0019193857965451055\n",
      "0.001918649270913277\n",
      "0.0019179133103183737\n",
      "0.0019171779141104294\n",
      "0.0019164430816404753\n",
      "0.0019157088122605363\n",
      "0.0019149751053236309\n",
      "0.0019142419601837673\n",
      "0.0019135093761959434\n",
      "0.0019127773527161439\n",
      "0.0019120458891013384\n",
      "0.00191131498470948\n",
      "0.0019105846388995033\n",
      "0.0019098548510313217\n",
      "0.0019091256204658267\n",
      "0.0019083969465648854\n",
      "0.0019076688286913392\n",
      "0.0019069412662090007\n",
      "0.0019062142584826535\n",
      "0.0019054878048780487\n",
      "0.0019047619047619048\n",
      "0.001904036557501904\n",
      "0.001903311762466692\n",
      "0.001902587519025875\n",
      "0.001901863826550019\n",
      "0.0019011406844106464\n",
      "0.0019004180919802356\n",
      "0.001899696048632219\n",
      "0.0018989745537409798\n",
      "0.0018982536066818527\n",
      "0.0018975332068311196\n",
      "0.0018968133535660092\n",
      "0.0018960940462646946\n",
      "0.0018953752843062926\n",
      "0.0018946570670708603\n",
      "0.001893939393939394\n",
      "0.001893222264293828\n",
      "0.0018925056775170325\n",
      "0.0018917896329928112\n",
      "0.0018910741301059002\n",
      "0.001890359168241966\n",
      "0.001889644746787604\n",
      "0.0018889308651303363\n",
      "0.0018882175226586104\n",
      "0.001887504718761797\n",
      "0.0018867924528301887\n",
      "0.001886080724254998\n",
      "0.001885369532428356\n",
      "0.0018846588767433095\n",
      "0.0018839487565938207\n",
      "0.0018832391713747645\n",
      "0.0018825301204819277\n",
      "0.001881821603312006\n",
      "0.0018811136192626034\n",
      "0.00188040616773223\n",
      "0.0018796992481203006\n",
      "0.0018789928598271326\n",
      "0.0018782870022539444\n",
      "0.001877581674802854\n",
      "0.0018768768768768769\n",
      "0.001876172607879925\n",
      "0.0018754688672168042\n",
      "0.0018747656542932134\n",
      "0.0018740629685157421\n",
      "0.0018733608092918695\n",
      "0.0018726591760299626\n",
      "0.0018719580681392737\n",
      "0.0018712574850299401\n",
      "0.0018705574261129816\n",
      "0.0018698578908002991\n",
      "0.001869158878504673\n",
      "0.0018684603886397607\n",
      "0.0018677624206200972\n",
      "0.0018670649738610904\n",
      "0.001866368047779022\n",
      "0.0018656716417910447\n",
      "0.001864975755315181\n",
      "0.0018642803877703207\n",
      "0.0018635855385762206\n",
      "0.0018628912071535022\n",
      "0.00186219739292365\n",
      "0.0018615040953090098\n",
      "0.0018608113137327876\n",
      "0.0018601190476190475\n",
      "0.001859427296392711\n",
      "0.0018587360594795538\n",
      "0.0018580453363062058\n",
      "0.0018573551263001485\n",
      "0.001856665428889714\n",
      "0.001855976243504083\n",
      "0.0018552875695732839\n",
      "0.00185459940652819\n",
      "0.0018539117538005192\n",
      "0.0018532246108228317\n",
      "0.001852537977028529\n",
      "0.001851851851851852\n",
      "0.0018511662347278786\n",
      "0.001850481125092524\n",
      "0.001849796522382538\n",
      "0.0018491124260355029\n",
      "0.0018484288354898336\n",
      "0.0018477457501847746\n",
      "0.001847063169560399\n",
      "0.001846381093057607\n",
      "0.0018456995201181247\n",
      "0.0018450184501845018\n",
      "0.0018443378827001106\n",
      "0.0018436578171091445\n",
      "0.0018429782528566164\n",
      "0.0018422991893883567\n",
      "0.001841620626151013\n",
      "0.001840942562592047\n",
      "0.001840264998159735\n",
      "0.001839587932303164\n",
      "0.0018389113644722325\n",
      "0.001838235294117647\n",
      "0.0018375597206909224\n",
      "0.0018368846436443791\n",
      "0.001836210062431142\n",
      "0.0018355359765051395\n",
      "0.001834862385321101\n",
      "0.001834189288334556\n",
      "0.0018335166850018336\n",
      "0.0018328445747800588\n",
      "0.001832172957127153\n",
      "0.0018315018315018315\n",
      "0.001830831197363603\n",
      "0.0018301610541727673\n",
      "0.0018294914013904135\n",
      "0.0018288222384784199\n",
      "0.0018281535648994515\n",
      "0.001827485380116959\n",
      "0.001826817683595177\n",
      "0.0018261504747991235\n",
      "0.0018254837531945967\n",
      "0.0018248175182481751\n",
      "0.0018241517694272164\n",
      "0.0018234865061998542\n",
      "0.0018228217280349982\n",
      "0.0018221574344023323\n",
      "0.0018214936247723133\n",
      "0.001820830298616169\n",
      "0.0018201674554058974\n",
      "0.001819505094614265\n",
      "0.0018188432157148053\n",
      "0.0018181818181818182\n",
      "0.0018175209014903672\n",
      "0.001816860465116279\n",
      "0.0018162005085361425\n",
      "0.0018155410312273058\n",
      "0.0018148820326678765\n",
      "0.00181422351233672\n",
      "0.0018135654697134566\n",
      "0.0018129079042784628\n",
      "0.001812250815512867\n",
      "0.0018115942028985507\n",
      "0.0018109380659181455\n",
      "0.0018102824040550326\n",
      "0.0018096272167933405\n",
      "0.001808972503617945\n",
      "0.0018083182640144665\n",
      "0.0018076644974692696\n",
      "0.0018070112034694614\n",
      "0.0018063583815028901\n",
      "0.0018057060310581437\n",
      "0.0018050541516245488\n",
      "0.001804402742692169\n",
      "0.0018037518037518038\n",
      "0.0018031013342949874\n",
      "0.001802451333813987\n",
      "0.0018018018018018018\n",
      "0.0018011527377521613\n",
      "0.0018005041411595247\n",
      "0.0017998560115190785\n",
      "0.0017992083483267362\n",
      "0.0017985611510791368\n",
      "0.0017979144192736426\n",
      "0.0017972681524083393\n",
      "0.0017966223499820337\n",
      "0.0017959770114942528\n",
      "0.0017953321364452424\n",
      "0.0017946877243359654\n",
      "0.001794043774668102\n",
      "0.001793400286944046\n",
      "0.0017927572606669057\n",
      "0.0017921146953405018\n",
      "0.0017914725904693658\n",
      "0.0017908309455587394\n",
      "0.0017901897601145722\n",
      "0.0017895490336435219\n",
      "0.0017889087656529517\n",
      "0.00178826895565093\n",
      "0.001787629603146228\n",
      "0.0017869907076483202\n",
      "0.0017863522686673813\n",
      "0.0017857142857142857\n",
      "0.001785076758300607\n",
      "0.0017844396859386152\n",
      "0.0017838030681412772\n",
      "0.001783166904422254\n",
      "0.0017825311942959\n",
      "0.001781895937277263\n",
      "0.0017812611328820805\n",
      "0.0017806267806267807\n",
      "0.00177999288002848\n",
      "0.0017793594306049821\n",
      "0.0017787264318747777\n",
      "0.0017780938833570413\n",
      "0.0017774617845716318\n",
      "0.0017768301350390902\n",
      "0.0017761989342806395\n",
      "0.0017755681818181818\n",
      "0.001774937877174299\n",
      "0.0017743080198722497\n",
      "0.0017736786094359701\n",
      "0.0017730496453900709\n",
      "0.001772421127259837\n",
      "0.001771793054571226\n",
      "0.001771165426850868\n",
      "0.0017705382436260624\n",
      "0.0017699115044247787\n",
      "0.0017692852087756545\n",
      "0.0017686593562079944\n",
      "0.001768033946251768\n",
      "0.0017674089784376105\n",
      "0.0017667844522968198\n",
      "0.0017661603673613563\n",
      "0.0017655367231638418\n",
      "0.0017649135192375574\n",
      "0.0017642907551164433\n",
      "0.001763668430335097\n",
      "0.001763046544428773\n",
      "0.0017624250969333803\n",
      "0.0017618040873854828\n",
      "0.0017611835153222965\n",
      "0.0017605633802816902\n",
      "0.0017599436818021823\n",
      "0.0017593244194229415\n",
      "0.0017587055926837848\n",
      "0.0017580872011251757\n",
      "0.0017574692442882249\n",
      "0.0017568517217146872\n",
      "0.0017562346329469617\n",
      "0.0017556179775280898\n",
      "0.001755001755001755\n",
      "0.0017543859649122807\n",
      "0.00175377060680463\n",
      "0.0017531556802244039\n",
      "0.0017525411847178409\n",
      "0.001751927119831815\n",
      "0.0017513134851138354\n",
      "0.0017507002801120449\n",
      "0.0017500875043752187\n",
      "0.0017494751574527643\n",
      "0.0017488632388947185\n",
      "0.0017482517482517483\n",
      "0.0017476406850751485\n",
      "0.0017470300489168414\n",
      "0.0017464198393293748\n",
      "0.0017458100558659217\n",
      "0.0017452006980802793\n",
      "0.0017445917655268667\n",
      "0.0017439832577607255\n",
      "0.0017433751743375174\n",
      "0.001742767514813524\n",
      "0.0017421602787456446\n",
      "0.0017415534656913968\n",
      "0.0017409470752089136\n",
      "0.001740341106856944\n",
      "0.0017397355601948504\n",
      "0.0017391304347826088\n",
      "0.0017385257301808068\n",
      "0.001737921445950643\n",
      "0.0017373175816539264\n",
      "0.0017367141368530739\n",
      "0.001736111111111111\n",
      "0.0017355085039916696\n",
      "0.0017349063150589867\n",
      "0.001734304543877905\n",
      "0.0017337031900138697\n",
      "0.0017331022530329288\n",
      "0.0017325017325017325\n",
      "0.0017319016279875303\n",
      "0.0017313019390581717\n",
      "0.0017307026652821046\n",
      "0.0017301038062283738\n",
      "0.0017295053614666206\n",
      "0.0017289073305670815\n",
      "0.0017283097131005876\n",
      "0.0017277125086385626\n",
      "0.0017271157167530224\n",
      "0.0017265193370165745\n",
      "0.0017259233690024164\n",
      "0.001725327812284334\n",
      "0.0017247326664367024\n",
      "0.0017241379310344827\n",
      "0.001723543605653223\n",
      "0.0017229496898690559\n",
      "0.001722356183258698\n",
      "0.001721763085399449\n",
      "0.0017211703958691911\n",
      "0.0017205781142463868\n",
      "0.0017199862401100791\n",
      "0.0017193947730398899\n",
      "0.0017188037126160192\n",
      "0.001718213058419244\n",
      "0.0017176228100309172\n",
      "0.001717032967032967\n",
      "0.0017164435290078957\n",
      "0.0017158544955387784\n",
      "0.0017152658662092624\n",
      "0.0017146776406035665\n",
      "0.0017140898183064792\n",
      "0.0017135023989033585\n",
      "0.0017129153819801302\n",
      "0.0017123287671232876\n",
      "0.0017117425539198905\n",
      "0.0017111567419575632\n",
      "0.0017105713308244953\n",
      "0.001709986320109439\n",
      "0.0017094017094017094\n",
      "0.0017088174982911825\n",
      "0.0017082336863682953\n",
      "0.0017076502732240437\n",
      "0.001707067258449983\n",
      "0.0017064846416382253\n",
      "0.0017059024223814397\n",
      "0.0017053206002728514\n",
      "0.0017047391749062393\n",
      "0.0017041581458759373\n",
      "0.0017035775127768314\n",
      "0.0017029972752043597\n",
      "0.0017024174327545114\n",
      "0.0017018379850238256\n",
      "0.001701258931609391\n",
      "0.0017006802721088435\n",
      "0.0017001020061203672\n",
      "0.001699524133242692\n",
      "0.0016989466530750934\n",
      "0.0016983695652173913\n",
      "0.001697792869269949\n",
      "0.0016972165648336728\n",
      "0.0016966406515100101\n",
      "0.0016960651289009499\n",
      "0.00169548999660902\n",
      "0.001694915254237288\n",
      "0.0016943409013893595\n",
      "0.0016937669376693768\n",
      "0.0016931933626820183\n",
      "0.0016926201760324984\n",
      "0.001692047377326565\n",
      "0.0016914749661705007\n",
      "0.0016909029421711193\n",
      "0.0016903313049357674\n",
      "0.0016897600540723217\n",
      "0.0016891891891891893\n",
      "0.0016886187098953055\n",
      "0.001688048615800135\n",
      "0.0016874789065136687\n",
      "0.0016869095816464238\n",
      "0.0016863406408094434\n",
      "0.0016857720836142953\n",
      "0.0016852039096730705\n",
      "0.0016846361185983828\n",
      "0.001684068710003368\n",
      "0.0016835016835016834\n",
      "0.001682935038707506\n",
      "0.0016823687752355316\n",
      "0.0016818028927009755\n",
      "0.0016812373907195697\n",
      "0.0016806722689075631\n",
      "0.0016801075268817205\n",
      "0.0016795431642593216\n",
      "0.0016789791806581598\n",
      "0.0016784155756965425\n",
      "0.0016778523489932886\n",
      "0.0016772895001677288\n",
      "0.001676727028839705\n",
      "0.0016761649346295675\n",
      "0.001675603217158177\n",
      "0.0016750418760469012\n",
      "0.0016744809109176155\n",
      "0.0016739203213927017\n",
      "0.0016733601070950468\n",
      "0.0016728002676480427\n",
      "0.0016722408026755853\n",
      "0.001671681711802073\n",
      "0.0016711229946524064\n",
      "0.001670564650851988\n",
      "0.0016700066800267202\n",
      "0.001669449081803005\n",
      "0.0016688918558077437\n",
      "0.001668335001668335\n",
      "0.001667778519012675\n",
      "0.0016672224074691564\n",
      "0.0016666666666666668\n",
      "0.0016661112962345886\n",
      "0.0016655562958027982\n",
      "0.001665001665001665\n",
      "0.0016644474034620505\n",
      "0.0016638935108153079\n",
      "0.00166333998669328\n",
      "0.0016627868307283007\n",
      "0.0016622340425531915\n",
      "0.001661681621801263\n",
      "0.0016611295681063123\n",
      "0.0016605778811026237\n",
      "0.0016600265604249668\n",
      "0.001659475605708596\n",
      "0.0016589250165892503\n",
      "0.001658374792703151\n",
      "0.0016578249336870027\n",
      "0.0016572754391779914\n",
      "0.0016567263088137839\n",
      "0.0016561775422325273\n",
      "0.0016556291390728477\n",
      "0.0016550810989738498\n",
      "0.0016545334215751159\n",
      "0.0016539861065167053\n",
      "0.0016534391534391533\n",
      "0.001652892561983471\n",
      "0.0016523463317911435\n",
      "0.0016518004625041295\n",
      "0.0016512549537648614\n",
      "0.001650709805216243\n",
      "0.0016501650165016502\n",
      "0.001649620587264929\n",
      "0.0016490765171503958\n",
      "0.0016485328058028356\n",
      "0.0016479894528675016\n",
      "0.0016474464579901153\n",
      "0.0016469038208168643\n",
      "0.0016463615409944023\n",
      "0.0016458196181698486\n",
      "0.0016452780519907865\n",
      "0.001644736842105263\n",
      "0.001644195988161789\n",
      "0.001643655489809336\n",
      "0.001643115346697338\n",
      "0.0016425755584756898\n",
      "0.0016420361247947454\n",
      "0.0016414970453053185\n",
      "0.0016409583196586807\n",
      "0.0016404199475065617\n",
      "0.0016398819285011479\n",
      "0.001639344262295082\n",
      "0.0016388069485414618\n",
      "0.00163826998689384\n",
      "0.0016377333770062235\n",
      "0.0016371971185330713\n",
      "0.0016366612111292963\n",
      "0.0016361256544502618\n",
      "0.0016355904481517827\n",
      "0.0016350555918901242\n",
      "0.0016345210853220007\n",
      "0.0016339869281045752\n",
      "0.001633453119895459\n",
      "0.0016329196603527107\n",
      "0.001632386549134835\n",
      "0.0016318537859007832\n",
      "0.0016313213703099511\n",
      "0.0016307893020221786\n",
      "0.0016302575806977503\n",
      "0.0016297262059973925\n",
      "0.0016291951775822744\n",
      "0.0016286644951140066\n",
      "0.0016281341582546401\n",
      "0.0016276041666666667\n",
      "0.0016270745200130166\n",
      "0.0016265452179570592\n",
      "0.0016260162601626016\n",
      "0.001625487646293888\n",
      "0.0016249593760155996\n",
      "0.0016244314489928524\n",
      "0.0016239038648911985\n",
      "0.0016233766233766235\n",
      "0.0016228497241155468\n",
      "0.0016223231667748216\n",
      "0.001621796951021732\n",
      "0.001621271076523995\n",
      "0.0016207455429497568\n",
      "0.0016202203499675956\n",
      "0.0016196954972465176\n",
      "0.0016191709844559584\n",
      "0.0016186468112657818\n",
      "0.0016181229773462784\n",
      "0.0016175994823681655\n",
      "0.0016170763260025874\n",
      "0.0016165535079211122\n",
      "0.0016160310277957336\n",
      "0.0016155088852988692\n",
      "0.001614987080103359\n",
      "0.0016144656118824668\n",
      "0.0016139444803098773\n",
      "0.0016134236850596966\n",
      "0.0016129032258064516\n",
      "0.0016123831022250886\n",
      "0.0016118633139909735\n",
      "0.0016113438607798904\n",
      "0.0016108247422680412\n",
      "0.001610305958132045\n",
      "0.0016097875080489374\n",
      "0.0016092693916961698\n",
      "0.0016087516087516086\n",
      "0.0016082341588935349\n",
      "0.001607717041800643\n",
      "0.0016072002571520412\n",
      "0.0016066838046272494\n",
      "0.0016061676839061998\n",
      "0.0016056518946692357\n",
      "0.0016051364365971107\n",
      "0.0016046213093709885\n",
      "0.0016041065126724415\n",
      "0.001603592046183451\n",
      "0.0016030779095864058\n",
      "0.0016025641025641025\n",
      "0.0016020506247997437\n",
      "0.0016015374759769379\n",
      "0.001601024655779699\n",
      "0.0016005121638924455\n",
      "0.0016\n",
      "0.001599488163787588\n",
      "0.0015989766549408379\n",
      "0.00159846547314578\n",
      "0.0015979546180888463\n",
      "0.001597444089456869\n",
      "0.0015969338869370809\n",
      "0.0015964240102171138\n",
      "0.0015959144589849984\n",
      "0.001595405232929164\n",
      "0.001594896331738437\n",
      "0.0015943877551020409\n",
      "0.0015938795027095952\n",
      "0.0015933715742511153\n",
      "0.0015928639694170119\n",
      "0.0015923566878980893\n",
      "0.001591849729385546\n",
      "0.001591343093570974\n",
      "0.001590836780146357\n",
      "0.0015903307888040711\n",
      "0.001589825119236884\n",
      "0.001589319771137953\n",
      "0.0015888147442008262\n",
      "0.0015883100381194409\n",
      "0.0015878056525881232\n",
      "0.0015873015873015873\n",
      "0.0015867978419549348\n",
      "0.0015862944162436548\n",
      "0.001585791309863622\n",
      "0.0015852885225110971\n",
      "0.001584786053882726\n",
      "0.0015842839036755386\n",
      "0.0015837820715869496\n",
      "0.0015832805573147563\n",
      "0.0015827793605571383\n",
      "0.0015822784810126582\n",
      "0.0015817779183802593\n",
      "0.0015812776723592662\n",
      "0.0015807777426493834\n",
      "0.0015802781289506952\n",
      "0.001579778830963665\n",
      "0.0015792798483891346\n",
      "0.0015787811809283233\n",
      "0.0015782828282828283\n",
      "0.001577784790154623\n",
      "0.0015772870662460567\n",
      "0.001576789656259855\n",
      "0.0015762925598991173\n",
      "0.001575795776867318\n",
      "0.001575299306868305\n",
      "0.0015748031496062992\n",
      "0.0015743073047858943\n",
      "0.0015738117721120553\n",
      "0.0015733165512901196\n",
      "0.0015728216420257944\n",
      "0.0015723270440251573\n",
      "0.0015718327569946558\n",
      "0.0015713387806411063\n",
      "0.0015708451146716933\n",
      "0.00157035175879397\n",
      "0.0015698587127158557\n",
      "0.001569365976145637\n",
      "0.0015688735487919673\n",
      "0.0015683814303638645\n",
      "0.0015678896205707118\n",
      "0.001567398119122257\n",
      "0.0015669069257286117\n",
      "0.0015664160401002505\n",
      "0.0015659254619480112\n",
      "0.0015654351909830933\n",
      "0.001564945226917058\n",
      "0.0015644555694618273\n",
      "0.0015639662183296842\n",
      "0.0015634771732332708\n",
      "0.0015629884338855893\n",
      "0.0015625\n",
      "0.001562011871290222\n",
      "0.001561524047470331\n",
      "0.0015610365282547611\n",
      "0.001560549313358302\n",
      "0.0015600624024961\n",
      "0.0015595757953836558\n",
      "0.0015590894917368258\n",
      "0.0015586034912718205\n",
      "0.0015581177937052041\n",
      "0.001557632398753894\n",
      "0.0015571473061351605\n",
      "0.001556662515566625\n",
      "0.001556178026766262\n",
      "0.0015556938394523958\n",
      "0.0015552099533437014\n",
      "0.001554726368159204\n",
      "0.001554243083618278\n",
      "0.0015537600994406464\n",
      "0.0015532774153463808\n",
      "0.0015527950310559005\n",
      "0.001552312946289972\n",
      "0.0015518311607697084\n",
      "0.0015513496742165685\n",
      "0.0015508684863523574\n",
      "0.0015503875968992248\n",
      "0.0015499070055796653\n",
      "0.0015494267121165168\n",
      "0.0015489467162329617\n",
      "0.001548467017652524\n",
      "0.0015479876160990713\n",
      "0.0015475085112968121\n",
      "0.001547029702970297\n",
      "0.001546551190844417\n",
      "0.0015460729746444033\n",
      "0.0015455950540958269\n",
      "0.0015451174289245982\n",
      "0.0015446400988569664\n",
      "0.0015441630636195182\n",
      "0.0015436863229391787\n",
      "0.0015432098765432098\n",
      "0.0015427337241592102\n",
      "0.0015422578655151142\n",
      "0.001541782300339192\n",
      "0.0015413070283600493\n",
      "0.0015408320493066256\n",
      "0.0015403573629081946\n",
      "0.001539882968894364\n",
      "0.001539408866995074\n",
      "0.0015389350569405972\n",
      "0.0015384615384615385\n",
      "0.0015379883112888342\n",
      "0.0015375153751537515\n",
      "0.001537042729787888\n",
      "0.0015365703749231714\n",
      "0.0015360983102918587\n",
      "0.0015356265356265355\n",
      "0.0015351550506601166\n",
      "0.001534683855125844\n",
      "0.0015342129487572874\n",
      "0.0015337423312883436\n",
      "0.0015332720024532351\n",
      "0.0015328019619865114\n",
      "0.0015323322096230463\n",
      "0.0015318627450980392\n",
      "0.0015313935681470138\n",
      "0.0015309246785058174\n",
      "0.0015304560759106215\n",
      "0.0015299877600979193\n",
      "0.0015295197308045274\n",
      "0.0015290519877675841\n",
      "0.001528584530724549\n",
      "0.001528117359413203\n",
      "0.0015276504735716467\n",
      "0.0015271838729383018\n",
      "0.0015267175572519084\n",
      "0.0015262515262515263\n",
      "0.0015257857796765334\n",
      "0.001525320317266626\n",
      "0.0015248551387618177\n",
      "0.001524390243902439\n",
      "0.0015239256324291375\n",
      "0.0015234613040828763\n",
      "0.0015229972586049345\n",
      "0.0015225334957369061\n",
      "0.0015220700152207\n",
      "0.0015216068167985392\n",
      "0.0015211439002129601\n",
      "0.0015206812652068127\n",
      "0.0015202189115232593\n",
      "0.001519756838905775\n",
      "0.0015192950470981465\n",
      "0.0015188335358444715\n",
      "0.0015183723048891589\n",
      "0.0015179113539769277\n",
      "0.0015174506828528073\n",
      "0.001516990291262136\n",
      "0.001516530178950561\n",
      "0.0015160703456640388\n",
      "0.001515610791148833\n",
      "0.0015151515151515152\n",
      "0.001514692517418964\n",
      "0.0015142337976983646\n",
      "0.0015137753557372085\n",
      "0.001513317191283293\n",
      "0.0015128593040847202\n",
      "0.0015124016938898972\n",
      "0.0015119443604475356\n",
      "0.0015114873035066505\n",
      "0.0015110305228165609\n",
      "0.0015105740181268882\n",
      "0.0015101177891875567\n",
      "0.0015096618357487923\n",
      "0.001509206157561123\n",
      "0.0015087507543753772\n",
      "0.0015082956259426848\n",
      "0.0015078407720144752\n",
      "0.0015073861923424782\n",
      "0.0015069318866787222\n",
      "0.0015064778547755348\n",
      "0.0015060240963855422\n",
      "0.0015055706112616681\n",
      "0.0015051173991571343\n",
      "0.001504664459825459\n",
      "0.0015042117930204573\n",
      "0.0015037593984962407\n",
      "0.001503307276007216\n",
      "0.0015028554253080854\n",
      "0.0015024038461538462\n",
      "0.0015019525382997897\n",
      "0.0015015015015015015\n",
      "0.0015010507355148605\n",
      "0.0015006002400960385\n",
      "0.0015001500150015\n",
      "0.0014997000599880025\n",
      "0.0014992503748125937\n",
      "0.001498800959232614\n",
      "0.0014983518130056938\n",
      "0.0014979029358897543\n",
      "0.001497454327643007\n",
      "0.0014970059880239522\n",
      "0.00149655791679138\n",
      "0.0014961101137043686\n",
      "0.0014956625785222854\n",
      "0.0014952153110047847\n",
      "0.0014947683109118087\n",
      "0.0014943215780035865\n",
      "0.0014938751120406335\n",
      "0.0014934289127837516\n",
      "0.001492982979994028\n",
      "0.0014925373134328358\n",
      "0.0014920919128618322\n",
      "0.0014916467780429594\n",
      "0.0014912019087384432\n",
      "0.0014907573047107932\n",
      "0.0014903129657228018\n",
      "0.0014898688915375446\n",
      "0.0014894250819183796\n",
      "0.0014889815366289458\n",
      "0.0014885382554331646\n",
      "0.001488095238095238\n",
      "0.001487652484379649\n",
      "0.00148720999405116\n",
      "0.0014867677668748143\n",
      "0.0014863258026159335\n",
      "0.0014858841010401188\n",
      "0.0014854426619132501\n",
      "0.001485001485001485\n",
      "0.0014845605700712589\n",
      "0.0014841199168892847\n",
      "0.001483679525222552\n",
      "0.0014832393948383269\n",
      "0.0014827995255041518\n",
      "0.0014823599169878447\n",
      "0.0014819205690574985\n",
      "0.0014814814814814814\n",
      "0.001481042654028436\n",
      "0.0014806040864672786\n",
      "0.0014801657785671995\n",
      "0.001479727730097662\n",
      "0.0014792899408284023\n",
      "0.0014788524105294291\n",
      "0.0014784151389710231\n",
      "0.0014779781259237363\n",
      "0.0014775413711583924\n",
      "0.0014771048744460858\n",
      "0.0014766686355581807\n",
      "0.0014762326542663124\n",
      "0.0014757969303423849\n",
      "0.0014753614635585719\n",
      "0.0014749262536873156\n",
      "0.001474491300501327\n",
      "0.001474056603773585\n",
      "0.0014736221632773356\n",
      "0.0014731879787860931\n",
      "0.0014727540500736377\n",
      "0.0014723203769140165\n",
      "0.0014718869590815426\n",
      "0.0014714537963507945\n",
      "0.0014710208884966167\n",
      "0.0014705882352941176\n",
      "0.001470155836518671\n",
      "0.0014697236919459142\n",
      "0.0014692918013517484\n",
      "0.0014688601645123384\n",
      "0.0014684287812041115\n",
      "0.001467997651203758\n",
      "0.0014675667742882301\n",
      "0.0014671361502347417\n",
      "0.0014667057788207685\n",
      "0.001466275659824047\n",
      "0.001465845793022574\n",
      "0.0014654161781946073\n",
      "0.001464986815118664\n",
      "0.0014645577035735209\n",
      "0.0014641288433382138\n",
      "0.0014637002341920376\n",
      "0.0014632718759145448\n",
      "0.001462843768285547\n",
      "0.0014624159110851126\n",
      "0.0014619883040935672\n",
      "0.0014615609470914938\n",
      "0.0014611338398597311\n",
      "0.001460706982179375\n",
      "0.0014602803738317756\n",
      "0.00145985401459854\n",
      "0.0014594279042615295\n",
      "0.0014590020426028597\n",
      "0.0014585764294049008\n",
      "0.0014581510644502771\n",
      "0.0014577259475218659\n",
      "0.001457301078402798\n",
      "0.001456876456876457\n",
      "0.0014564520827264782\n",
      "0.00145602795573675\n",
      "0.001455604075691412\n",
      "0.0014551804423748546\n",
      "0.0014547570555717194\n",
      "0.0014543339150668994\n",
      "0.0014539110206455365\n",
      "0.0014534883720930232\n",
      "0.0014530659691950015\n",
      "0.001452643811737362\n",
      "0.0014522218995062445\n",
      "0.0014518002322880372\n",
      "0.001451378809869376\n",
      "0.0014509576320371445\n",
      "0.001450536698578474\n",
      "0.0014501160092807424\n",
      "0.0014496955639315744\n",
      "0.0014492753623188406\n",
      "0.0014488554042306578\n",
      "0.0014484356894553883\n",
      "0.0014480162177816392\n",
      "0.0014475969889982628\n",
      "0.001447178002894356\n",
      "0.0014467592592592592\n",
      "0.0014463407578825572\n",
      "0.0014459224985540775\n",
      "0.0014455044810638912\n",
      "0.001445086705202312\n",
      "0.001444669170759896\n",
      "0.0014442518775274408\n",
      "0.0014438348252959862\n",
      "0.001443418013856813\n",
      "0.001443001443001443\n",
      "0.0014425851125216388\n",
      "0.001442169022209403\n",
      "0.0014417531718569781\n",
      "0.0014413375612568463\n",
      "0.001440922190201729\n",
      "0.0014405070584845865\n",
      "0.0014400921658986176\n",
      "0.0014396775122372588\n",
      "0.0014392630972941854\n",
      "0.0014388489208633094\n",
      "0.0014384349827387803\n",
      "0.0014380212827149843\n",
      "0.001437607820586544\n",
      "0.0014371945961483186\n",
      "0.0014367816091954023\n",
      "0.0014363688595231256\n",
      "0.0014359563469270534\n",
      "0.001435544071202986\n",
      "0.0014351320321469576\n",
      "0.0014347202295552368\n",
      "0.001434308663224326\n",
      "0.0014338973329509608\n",
      "0.0014334862385321102\n",
      "0.0014330753797649756\n",
      "0.0014326647564469914\n",
      "0.0014322543683758235\n",
      "0.0014318442153493699\n",
      "0.0014314342971657602\n",
      "0.0014310246136233543\n",
      "0.001430615164520744\n",
      "0.0014302059496567505\n",
      "0.0014297969688304261\n",
      "0.001429388221841052\n",
      "0.0014289797084881394\n",
      "0.0014285714285714286\n",
      "0.0014281633818908884\n",
      "0.0014277555682467161\n",
      "0.0014273479874393378\n",
      "0.0014269406392694063\n",
      "0.0014265335235378032\n",
      "0.001426126640045636\n",
      "0.00142571998859424\n",
      "0.0014253135689851768\n",
      "0.0014249073810202336\n",
      "0.0014245014245014246\n",
      "0.0014240956992309882\n",
      "0.0014236902050113896\n",
      "0.0014232849416453174\n",
      "0.0014228799089356858\n",
      "0.001422475106685633\n",
      "0.001422070534698521\n",
      "0.0014216661927779358\n",
      "0.0014212620807276862\n",
      "0.0014208581983518045\n",
      "0.0014204545454545455\n",
      "0.0014200511218403862\n",
      "0.0014196479273140261\n",
      "0.001419244961680386\n",
      "0.0014188422247446084\n",
      "0.0014184397163120568\n",
      "0.0014180374361883153\n",
      "0.001417635384179189\n",
      "0.001417233560090703\n",
      "0.0014168319637291016\n",
      "0.00141643059490085\n",
      "0.001416029453412631\n",
      "0.0014156285390713476\n",
      "0.001415227851684121\n",
      "0.0014148273910582908\n",
      "0.0014144271570014145\n",
      "0.001414027149321267\n",
      "0.0014136273678258412\n",
      "0.0014132278123233466\n",
      "0.0014128284826222096\n",
      "0.0014124293785310734\n",
      "0.001412030499858797\n",
      "0.001411631846414455\n",
      "0.0014112334180073384\n",
      "0.0014108352144469526\n",
      "0.0014104372355430183\n",
      "0.0014100394811054709\n",
      "0.00140964195094446\n",
      "0.0014092446448703494\n",
      "0.0014088475626937165\n",
      "0.0014084507042253522\n",
      "0.0014080540692762602\n",
      "0.0014076576576576576\n",
      "0.0014072614691809737\n",
      "0.0014068655036578502\n",
      "0.0014064697609001407\n",
      "0.00140607424071991\n",
      "0.0014056789429294349\n",
      "0.001405283867341203\n",
      "0.0014048890137679123\n",
      "0.0014044943820224719\n",
      "0.0014040999719180005\n",
      "0.001403705783267827\n",
      "0.0014033118158854898\n",
      "0.0014029180695847362\n",
      "0.001402524544179523\n",
      "0.0014021312394840158\n",
      "0.0014017381553125877\n",
      "0.0014013452914798206\n",
      "0.0014009526478005044\n",
      "0.0014005602240896359\n",
      "0.0014001680201624195\n",
      "0.0013997760358342665\n",
      "0.001399384270920795\n",
      "0.0013989927252378287\n",
      "0.0013986013986013986\n",
      "0.0013982102908277406\n",
      "0.0013978194017332962\n",
      "0.001397428731134712\n",
      "0.0013970382788488405\n",
      "0.0013966480446927375\n",
      "0.0013962580284836638\n",
      "0.0013958682300390843\n",
      "0.0013954786491766676\n",
      "0.0013950892857142857\n",
      "0.001394700139470014\n",
      "0.0013943112102621305\n",
      "0.0013939224979091162\n",
      "0.0013935340022296545\n",
      "0.0013931457230426303\n",
      "0.001392757660167131\n",
      "0.001392369813422445\n",
      "0.0013919821826280624\n",
      "0.0013915947676036739\n",
      "0.0013912075681691708\n",
      "0.0013908205841446453\n",
      "0.0013904338153503894\n",
      "0.0013900472616068947\n",
      "0.0013896609227348527\n",
      "0.0013892747985551543\n",
      "0.001388888888888889\n",
      "0.0013885031935573452\n",
      "0.00138811771238201\n",
      "0.0013877324451845685\n",
      "0.0013873473917869034\n",
      "0.0013869625520110957\n",
      "0.0013865779256794233\n",
      "0.0013861935126143609\n",
      "0.001385809312638581\n",
      "0.0013854253255749516\n",
      "0.0013850415512465374\n",
      "0.0013846579894765993\n",
      "0.0013842746400885937\n",
      "0.0013838915029061722\n",
      "0.001383508577753182\n",
      "0.0013831258644536654\n",
      "0.0013827433628318584\n",
      "0.0013823610727121925\n",
      "0.0013819789939192924\n",
      "0.0013815971262779773\n",
      "0.0013812154696132596\n",
      "0.0013808340237503453\n",
      "0.0013804527885146328\n",
      "0.001380071763731714\n",
      "0.0013796909492273732\n",
      "0.001379310344827586\n",
      "0.0013789299503585218\n",
      "0.0013785497656465398\n",
      "0.0013781697905181918\n",
      "0.0013777900248002205\n",
      "0.0013774104683195593\n",
      "0.0013770311209033324\n",
      "0.0013766519823788547\n",
      "0.0013762730525736307\n",
      "0.001375894331315355\n",
      "0.001375515818431912\n",
      "0.0013751375137513752\n",
      "0.0013747594171020072\n",
      "0.0013743815283122594\n",
      "0.0013740038472107722\n",
      "0.0013736263736263737\n",
      "0.0013732491073880802\n",
      "0.0013728720483250961\n",
      "0.001372495196266813\n",
      "0.0013721185510428102\n",
      "0.0013717421124828531\n",
      "0.0013713658804168952\n",
      "0.0013709898546750755\n",
      "0.0013706140350877192\n",
      "0.0013702384214853384\n",
      "0.0013698630136986301\n",
      "0.001369487811558477\n",
      "0.0013691128148959474\n",
      "0.001368738023542294\n",
      "0.0013683634373289546\n",
      "0.0013679890560875513\n",
      "0.0013676148796498905\n",
      "0.0013672409078479629\n",
      "0.001366867140513942\n",
      "0.001366493577480186\n",
      "0.001366120218579235\n",
      "0.0013657470636438131\n",
      "0.001365374112506827\n",
      "0.001365001365001365\n",
      "0.0013646288209606986\n",
      "0.001364256480218281\n",
      "0.001363884342607747\n",
      "0.0013635124079629125\n",
      "0.0013631406761177754\n",
      "0.001362769146906514\n",
      "0.0013623978201634877\n",
      "0.001362026695723236\n",
      "0.0013616557734204794\n",
      "0.001361285053090117\n",
      "0.0013609145345672292\n",
      "0.0013605442176870747\n",
      "0.0013601741022850925\n",
      "0.0013598041881968997\n",
      "0.0013594344752582926\n",
      "0.001359064963305246\n",
      "0.001358695652173913\n",
      "0.0013583265417006249\n",
      "0.0013579576317218902\n",
      "0.0013575889220743959\n",
      "0.0013572204125950054\n",
      "0.0013568521031207597\n",
      "0.0013564839934888768\n",
      "0.0013561160835367507\n",
      "0.0013557483731019523\n",
      "0.0013553808620222283\n",
      "0.0013550135501355014\n",
      "0.00135464643727987\n",
      "0.0013542795232936078\n",
      "0.0013539128080151638\n",
      "0.0013535462912831618\n",
      "0.0013531799729364006\n",
      "0.0013528138528138528\n",
      "0.001352447930754666\n",
      "0.0013520822065981612\n",
      "0.0013517166801838335\n",
      "0.0013513513513513514\n",
      "0.0013509862199405566\n",
      "0.001350621285791464\n",
      "0.0013502565487442614\n",
      "0.0013498920086393088\n",
      "0.001349527665317139\n",
      "0.0013491635186184566\n",
      "0.001348799568384138\n",
      "0.001348435814455232\n",
      "0.0013480722566729577\n",
      "0.0013477088948787063\n",
      "0.0013473457289140394\n",
      "0.0013469827586206897\n",
      "0.00134661998384056\n",
      "0.0013462574044157242\n",
      "0.0013458950201884253\n",
      "0.0013455328310010765\n",
      "0.0013451708366962604\n",
      "0.0013448090371167294\n",
      "0.0013444474321054048\n",
      "0.0013440860215053765\n",
      "0.0013437248051599033\n",
      "0.0013433637829124126\n",
      "0.0013430029546065002\n",
      "0.0013426423200859291\n",
      "0.0013422818791946308\n",
      "0.0013419216317767043\n",
      "0.0013415615776764154\n",
      "0.0013412017167381974\n",
      "0.0013408420488066506\n",
      "0.0013404825737265416\n",
      "0.0013401232913428035\n",
      "0.0013397642015005359\n",
      "0.001339405304045004\n",
      "0.001339046598821639\n",
      "0.0013386880856760374\n",
      "0.0013383297644539614\n",
      "0.001337971635001338\n",
      "0.001337613697164259\n",
      "0.001337255950788981\n",
      "0.001336898395721925\n",
      "0.0013365410318096765\n",
      "0.0013361838588989846\n",
      "0.0013358268768367619\n",
      "0.0013354700854700855\n",
      "0.0013351134846461949\n",
      "0.0013347570742124934\n",
      "0.0013344008540165466\n",
      "0.0013340448239060833\n",
      "0.0013336889837289945\n",
      "0.0013333333333333333\n",
      "0.0013329778725673154\n",
      "0.0013326226012793177\n",
      "0.001332267519317879\n",
      "0.0013319126265316996\n",
      "0.0013315579227696406\n",
      "0.0013312034078807242\n",
      "0.0013308490817141336\n",
      "0.0013304949441192123\n",
      "0.0013301409949454642\n",
      "0.0013297872340425532\n",
      "0.0013294336612603031\n",
      "0.0013290802764486975\n",
      "0.0013287270794578793\n",
      "0.001328374070138151\n",
      "0.0013280212483399733\n",
      "0.0013276686139139671\n",
      "0.0013273161667109105\n",
      "0.001326963906581741\n",
      "0.0013266118333775537\n",
      "0.001326259946949602\n",
      "0.0013259082471492973\n",
      "0.001325556733828208\n",
      "0.0013252054068380599\n",
      "0.0013248542660307366\n",
      "0.0013245033112582781\n",
      "0.0013241525423728813\n",
      "0.0013238019592268996\n",
      "0.0013234515616728428\n",
      "0.0013231013495633766\n",
      "0.0013227513227513227\n",
      "0.0013224014810896587\n",
      "0.0013220518244315177\n",
      "0.0013217023526301878\n",
      "0.001321353065539112\n",
      "0.001321003963011889\n",
      "0.0013206550449022716\n",
      "0.0013203063110641669\n",
      "0.0013199577613516368\n",
      "0.0013196093956188968\n",
      "0.0013192612137203166\n",
      "0.0013189132155104195\n",
      "0.0013185654008438818\n",
      "0.001318217769575534\n",
      "0.0013178703215603585\n",
      "0.0013175230566534915\n",
      "0.0013171759747102212\n",
      "0.001316829075585989\n",
      "0.0013164823591363876\n",
      "0.0013161358252171624\n",
      "0.0013157894736842105\n",
      "0.0013154433043935806\n",
      "0.0013150973172014729\n",
      "0.0013147515119642387\n",
      "0.0013144058885383807\n",
      "0.001314060446780552\n",
      "0.0013137151865475565\n",
      "0.001313370107696349\n",
      "0.0013130252100840337\n",
      "0.0013126804935678655\n",
      "0.0013123359580052493\n",
      "0.0013119916032537393\n",
      "0.0013116474291710388\n",
      "0.0013113034356150013\n",
      "0.0013109596224436288\n",
      "0.001310615989515072\n",
      "0.001310272536687631\n",
      "0.0013099292638197536\n",
      "0.0013095861707700367\n",
      "0.0013092432573972245\n",
      "0.0013089005235602095\n",
      "0.0013085579691180318\n",
      "0.0013082155939298796\n",
      "0.0013078733978550876\n",
      "0.001307531380753138\n",
      "0.00130718954248366\n",
      "0.0013068478829064297\n",
      "0.0013065064018813691\n",
      "0.0013061650992685476\n",
      "0.0013058239749281796\n",
      "0.0013054830287206266\n",
      "0.0013051422605063951\n",
      "0.0013048016701461378\n",
      "0.0013044612575006521\n",
      "0.0013041210224308817\n",
      "0.001303780964797914\n",
      "0.0013034410844629822\n",
      "0.0013031013812874641\n",
      "0.0013027618551328818\n",
      "0.0013024225058609013\n",
      "0.0013020833333333333\n",
      "0.0013017443374121322\n",
      "0.0013014055179593961\n",
      "0.0013010668748373666\n",
      "0.0013007284079084287\n",
      "0.0013003901170351106\n",
      "0.0013000520020800832\n",
      "0.0012997140629061607\n",
      "0.0012993762993762994\n",
      "0.0012990387113535984\n",
      "0.0012987012987012987\n",
      "0.0012983640612827837\n",
      "0.0012980269989615785\n",
      "0.0012976901116013497\n",
      "0.0012973533990659055\n",
      "0.0012970168612191958\n",
      "0.0012966804979253112\n",
      "0.0012963443090484833\n",
      "0.0012960082944530845\n",
      "0.001295672454003628\n",
      "0.0012953367875647669\n",
      "0.001295001295001295\n",
      "0.001294665976178146\n",
      "0.0012943308309603934\n",
      "0.0012939958592132505\n",
      "0.00129366106080207\n",
      "0.0012933264355923435\n",
      "0.0012929919834497026\n",
      "0.0012926577042399173\n",
      "0.0012923235978288964\n",
      "0.0012919896640826874\n",
      "0.0012916559028674762\n",
      "0.0012913223140495868\n",
      "0.0012909888974954814\n",
      "0.0012906556530717604\n",
      "0.0012903225806451613\n",
      "0.0012899896800825593\n",
      "0.0012896569512509672\n",
      "0.0012893243940175349\n",
      "0.001288992008249549\n",
      "0.001288659793814433\n",
      "0.0012883277505797476\n",
      "0.001287995878413189\n",
      "0.0012876641771825909\n",
      "0.0012873326467559218\n",
      "0.001287001287001287\n",
      "0.0012866700977869274\n",
      "0.0012863390789812194\n",
      "0.001286008230452675\n",
      "0.0012856775520699408\n",
      "0.0012853470437017994\n",
      "0.0012850167052171678\n",
      "0.0012846865364850976\n",
      "0.0012843565373747753\n",
      "0.0012840267077555213\n",
      "0.0012836970474967907\n",
      "0.0012833675564681724\n",
      "0.0012830382345393892\n",
      "0.0012827090815802976\n",
      "0.0012823800974608873\n",
      "0.001282051282051282\n",
      "0.001281722635221738\n",
      "0.0012813941568426447\n",
      "0.0012810658467845247\n",
      "0.0012807377049180327\n",
      "0.0012804097311139564\n",
      "0.0012800819252432156\n",
      "0.001279754287176862\n",
      "0.00127942681678608\n",
      "0.0012790995139421847\n",
      "0.0012787723785166241\n",
      "0.0012784454103809768\n",
      "0.001278118609406953\n",
      "0.001277791975466394\n",
      "0.0012774655084312723\n",
      "0.001277139208173691\n",
      "0.0012768130745658835\n",
      "0.0012764871074802144\n",
      "0.001276161306789178\n",
      "0.0012758356723653994\n",
      "0.0012755102040816326\n",
      "0.0012751849018107625\n",
      "0.0012748597654258032\n",
      "0.0012745347947998981\n",
      "0.0012742099898063201\n",
      "0.0012738853503184713\n",
      "0.0012735608762098828\n",
      "0.0012732365673542145\n",
      "0.0012729124236252546\n",
      "0.0012725884448969204\n",
      "0.001272264631043257\n",
      "0.0012719409819384382\n",
      "0.001271617497456765\n",
      "0.0012712941774726673\n",
      "0.0012709710218607015\n",
      "0.0012706480304955528\n",
      "0.0012703252032520325\n",
      "0.00127000254000508\n",
      "0.0012696800406297613\n",
      "0.0012693577050012694\n",
      "0.0012690355329949238\n",
      "0.001268713524486171\n",
      "0.0012683916793505834\n",
      "0.00126806999746386\n",
      "0.0012677484787018255\n",
      "0.0012674271229404308\n",
      "0.0012671059300557526\n",
      "0.001266784899923993\n",
      "0.0012664640324214793\n",
      "0.0012661433274246644\n",
      "0.0012658227848101266\n",
      "0.0012655024044545685\n",
      "0.0012651821862348178\n",
      "0.0012648621300278269\n",
      "0.0012645422357106728\n",
      "0.0012642225031605564\n",
      "0.0012639029322548028\n",
      "0.0012635835228708618\n",
      "0.0012632642748863063\n",
      "0.001262945188178833\n",
      "0.0012626262626262627\n",
      "0.0012623074981065387\n",
      "0.0012619888944977284\n",
      "0.0012616704516780217\n",
      "0.0012613521695257316\n",
      "0.0012610340479192938\n",
      "0.0012607160867372667\n",
      "0.0012603982858583312\n",
      "0.0012600806451612903\n",
      "0.0012597631645250692\n",
      "0.0012594458438287153\n",
      "0.0012591286829513977\n",
      "0.0012588116817724068\n",
      "0.0012584948401711553\n",
      "0.0012581781580271766\n",
      "0.0012578616352201257\n",
      "0.0012575452716297787\n",
      "0.001257229067136032\n",
      "0.001256913021618904\n",
      "0.0012565971349585323\n",
      "0.001256281407035176\n",
      "0.0012559658377292139\n",
      "0.0012556504269211452\n",
      "0.0012553351744915891\n",
      "0.0012550200803212851\n",
      "0.0012547051442910915\n",
      "0.001254390366281987\n",
      "0.001254075746175069\n",
      "0.0012537612838515546\n",
      "0.00125344697919278\n",
      "0.0012531328320802004\n",
      "0.0012528188423953897\n",
      "0.00125250501002004\n",
      "0.001252191334835963\n",
      "0.0012518778167250877\n",
      "0.0012515644555694619\n",
      "0.0012512512512512512\n",
      "0.0012509382036527395\n",
      "0.0012506253126563281\n",
      "0.001250312578144536\n",
      "0.00125\n",
      "0.0012496875781054736\n",
      "0.0012493753123438282\n",
      "0.0012490632025980515\n",
      "0.0012487512487512488\n",
      "0.0012484394506866417\n",
      "0.0012481278082875687\n",
      "0.0012478163214374844\n",
      "0.00124750499001996\n",
      "0.001247193813918683\n",
      "0.0012468827930174563\n",
      "0.0012465719272001994\n",
      "0.0012462612163509472\n",
      "0.00124595066035385\n",
      "0.001245640259093174\n",
      "0.0012453300124533001\n",
      "0.001245019920318725\n",
      "0.0012447099825740602\n",
      "0.0012444001991040318\n",
      "0.001244090569793481\n",
      "0.0012437810945273632\n",
      "0.0012434717731907485\n",
      "0.0012431626056688214\n",
      "0.0012428535918468805\n",
      "0.001242544731610338\n",
      "0.0012422360248447205\n",
      "0.0012419274714356682\n",
      "0.0012416190712689348\n",
      "0.0012413108242303873\n",
      "0.0012410027302060065\n",
      "0.0012406947890818859\n",
      "0.0012403870007442323\n",
      "0.001240079365079365\n",
      "0.001239771881973717\n",
      "0.0012394645513138325\n",
      "0.0012391573729863693\n",
      "0.001238850346878097\n",
      "0.0012385434728758979\n",
      "0.0012382367508667657\n",
      "0.0012379301807378064\n",
      "0.0012376237623762376\n",
      "0.0012373174956693887\n",
      "0.0012370113805047005\n",
      "0.0012367054167697256\n",
      "0.0012363996043521265\n",
      "0.0012360939431396785\n",
      "0.001235788433020267\n",
      "0.001235483073881888\n",
      "0.0012351778656126482\n",
      "0.0012348728081007657\n",
      "0.0012345679012345679\n",
      "0.0012342631449024932\n",
      "0.0012339585389930898\n",
      "0.001233654083395016\n",
      "0.00123334977799704\n",
      "0.0012330456226880395\n",
      "0.001232741617357002\n",
      "0.0012324377618930244\n",
      "0.0012321340561853129\n",
      "0.001231830500123183\n",
      "0.0012315270935960591\n",
      "0.0012312238364934746\n",
      "0.0012309207287050715\n",
      "0.0012306177701206006\n",
      "0.0012303149606299212\n",
      "0.0012300123001230013\n",
      "0.0012297097884899164\n",
      "0.0012294074256208507\n",
      "0.0012291052114060963\n",
      "0.001228803145736053\n",
      "0.0012285012285012285\n",
      "0.0012281994595922379\n",
      "0.0012278978388998035\n",
      "0.0012275963663147557\n",
      "0.0012272950417280314\n",
      "0.001226993865030675\n",
      "0.0012266928361138372\n",
      "0.0012263919548687761\n",
      "0.0012260912211868563\n",
      "0.001225790634959549\n",
      "0.0012254901960784314\n",
      "0.0012251899044351876\n",
      "0.001224889759921607\n",
      "0.0012245897624295861\n",
      "0.0012242899118511264\n",
      "0.0012239902080783353\n",
      "0.0012236906510034262\n",
      "0.001223391240518718\n",
      "0.001223091976516634\n",
      "0.001222792858889704\n",
      "0.0012224938875305623\n",
      "0.0012221950623319481\n",
      "0.0012218963831867058\n",
      "0.001221597849987784\n",
      "0.0012212994626282364\n",
      "0.001221001221001221\n",
      "0.001220703125\n",
      "0.00122040517451794\n",
      "0.0012201073694485115\n",
      "0.0012198097096852891\n",
      "0.0012195121951219512\n",
      "0.00121921482565228\n",
      "0.0012189176011701609\n",
      "0.0012186205215695832\n",
      "0.0012183235867446393\n",
      "0.001218026796589525\n",
      "0.0012177301509985387\n",
      "0.0012174336498660824\n",
      "0.0012171372930866603\n",
      "0.0012168410805548796\n",
      "0.0012165450121654502\n",
      "0.0012162490878131842\n",
      "0.0012159533073929961\n",
      "0.0012156576707999028\n",
      "0.0012153621779290229\n",
      "0.001215066828675577\n",
      "0.0012147716229348883\n",
      "0.0012144765606023804\n",
      "0.0012141816415735794\n",
      "0.0012138868657441126\n",
      "0.0012135922330097086\n",
      "0.0012132977432661976\n",
      "0.0012130033964095099\n",
      "0.001212709192335678\n",
      "0.0012124151309408342\n",
      "0.0012121212121212121\n",
      "0.0012118274357731458\n",
      "0.00121153380179307\n",
      "0.0012112403100775194\n",
      "0.001210946960523129\n",
      "0.0012106537530266344\n",
      "0.0012103606874848704\n",
      "0.0012100677637947724\n",
      "0.0012097749818533753\n",
      "0.0012094823415578133\n",
      "0.0012091898428053204\n",
      "0.0012088974854932303\n",
      "0.001208605269518975\n",
      "0.001208313194780087\n",
      "0.0012080212611741967\n",
      "0.0012077294685990338\n",
      "0.001207437816952427\n",
      "0.0012071463061323032\n",
      "0.0012068549360366883\n",
      "0.0012065637065637065\n",
      "0.0012062726176115801\n",
      "0.00120598166907863\n",
      "0.0012056908608632747\n",
      "0.0012054001928640309\n",
      "0.001205109664979513\n",
      "0.0012048192771084338\n",
      "0.0012045290291496024\n",
      "0.0012042389210019267\n",
      "0.0012039489525644113\n",
      "0.001203659123736158\n",
      "0.0012033694344163659\n",
      "0.001203079884504331\n",
      "0.0012027904738994466\n",
      "0.0012025012025012026\n",
      "0.0012022120702091848\n",
      "0.001201923076923077\n",
      "0.001201634222542658\n",
      "0.001201345506967804\n",
      "0.0012010569300984868\n",
      "0.0012007684918347744\n",
      "0.0012004801920768306\n",
      "0.001200192030724916\n",
      "0.0011999040076793857\n",
      "0.0011996161228406909\n",
      "0.0011993283761093788\n",
      "0.001199040767386091\n",
      "0.0011987532965715656\n",
      "0.0011984659635666348\n",
      "0.0011981787682722263\n",
      "0.0011978917105893627\n",
      "0.0011976047904191617\n",
      "0.0011973180076628352\n",
      "0.0011970313622216902\n",
      "0.0011967448539971278\n",
      "0.0011964584828906438\n",
      "0.0011961722488038277\n",
      "0.001195886151638364\n",
      "0.0011956001912960307\n",
      "0.0011953143676786994\n",
      "0.0011950286806883365\n",
      "0.0011947431302270011\n",
      "0.0011944577161968467\n",
      "0.0011941724385001193\n",
      "0.0011938872970391596\n",
      "0.0011936022917164002\n",
      "0.0011933174224343676\n",
      "0.0011930326890956812\n",
      "0.0011927480916030535\n",
      "0.0011924636298592892\n",
      "0.0011921793037672865\n",
      "0.0011918951132300357\n",
      "0.0011916110581506197\n",
      "0.0011913271384322134\n",
      "0.0011910433539780848\n",
      "0.0011907597046915933\n",
      "0.0011904761904761906\n",
      "0.00119019281123542\n",
      "0.0011899095668729176\n",
      "0.0011896264572924102\n",
      "0.0011893434823977164\n",
      "0.0011890606420927466\n",
      "0.0011887779362815027\n",
      "0.001188495364868077\n",
      "0.001188212927756654\n",
      "0.0011879306248515087\n",
      "0.0011876484560570072\n",
      "0.0011873664212776064\n",
      "0.0011870845204178537\n",
      "0.0011868027533823878\n",
      "0.0011865211200759373\n",
      "0.0011862396204033216\n",
      "0.0011859582542694497\n",
      "0.0011856770215793219\n",
      "0.0011853959222380276\n",
      "0.0011851149561507466\n",
      "0.001184834123222749\n",
      "0.0011845534233593934\n",
      "0.0011842728564661299\n",
      "0.0011839924224484964\n",
      "0.0011837121212121212\n",
      "0.001183431952662722\n",
      "0.001183151916706105\n",
      "0.0011828720132481666\n",
      "0.0011825922421948912\n",
      "0.0011823126034523528\n",
      "0.001182033096926714\n",
      "0.001181753722524226\n",
      "0.0011814744801512287\n",
      "0.0011811953697141507\n",
      "0.0011809163911195087\n",
      "0.0011806375442739079\n",
      "0.0011803588290840415\n",
      "0.001180080245456691\n",
      "0.0011798017932987258\n",
      "0.0011795234725171032\n",
      "0.0011792452830188679\n",
      "0.001178967224711153\n",
      "0.0011786892975011788\n",
      "0.0011784115012962526\n",
      "0.00117813383600377\n",
      "0.001177856301531213\n",
      "0.0011775788977861517\n",
      "0.0011773016246762421\n",
      "0.0011770244821092278\n",
      "0.0011767474699929394\n",
      "0.001176470588235294\n",
      "0.0011761938367442955\n",
      "0.0011759172154280338\n",
      "0.0011756407241946861\n",
      "0.0011753643629525152\n",
      "0.0011750881316098707\n",
      "0.001174812030075188\n",
      "0.0011745360582569885\n",
      "0.0011742602160638798\n",
      "0.0011739845034045551\n",
      "0.0011737089201877935\n",
      "0.0011734334663224596\n",
      "0.0011731581417175035\n",
      "0.001172882946281961\n",
      "0.0011726078799249532\n",
      "0.0011723329425556857\n",
      "0.0011720581340834506\n",
      "0.0011717834544176236\n",
      "0.0011715089034676663\n",
      "0.0011712344811431249\n",
      "0.00117096018735363\n",
      "0.0011706860220088973\n",
      "0.0011704119850187266\n",
      "0.0011701380762930026\n",
      "0.001169864295741694\n",
      "0.0011695906432748538\n",
      "0.0011693171188026192\n",
      "0.0011690437222352116\n",
      "0.0011687704534829358\n",
      "0.0011684973124561813\n",
      "0.0011682242990654205\n",
      "0.00116795141322121\n",
      "0.0011676786548341896\n",
      "0.0011674060238150829\n",
      "0.0011671335200746965\n",
      "0.0011668611435239206\n",
      "0.0011665888940737283\n",
      "0.001166316771635176\n",
      "0.0011660447761194029\n",
      "0.0011657729074376311\n",
      "0.0011655011655011655\n",
      "0.0011652295502213937\n",
      "0.0011649580615097856\n",
      "0.0011646866992778943\n",
      "0.0011644154634373545\n",
      "0.0011641443538998836\n",
      "0.0011638733705772813\n",
      "0.0011636025133814289\n",
      "0.0011633317822242904\n",
      "0.0011630611770179111\n",
      "0.0011627906976744186\n",
      "0.0011625203441060219\n",
      "0.0011622501162250117\n",
      "0.0011619800139437602\n",
      "0.0011617100371747212\n",
      "0.0011614401858304297\n",
      "0.0011611704598235022\n",
      "0.0011609008590666356\n",
      "0.001160631383472609\n",
      "0.0011603620329542817\n",
      "0.001160092807424594\n",
      "0.001159823706796567\n",
      "0.0011595547309833025\n",
      "0.001159285879897983\n",
      "0.0011590171534538712\n",
      "0.0011587485515643105\n",
      "0.0011584800741427247\n",
      "0.0011582117211026176\n",
      "0.001157943492357573\n",
      "0.0011576753878212549\n",
      "0.0011574074074074073\n",
      "0.0011571395510298543\n",
      "0.0011568718186024988\n",
      "0.0011566042100393246\n",
      "0.001156336725254394\n",
      "0.0011560693641618498\n",
      "0.001155802126675913\n",
      "0.0011555350127108851\n",
      "0.0011552680221811461\n",
      "0.001155001155001155\n",
      "0.0011547344110854503\n",
      "0.0011544677903486493\n",
      "0.0011542012927054479\n",
      "0.0011539349180706207\n",
      "0.0011536686663590216\n",
      "0.0011534025374855825\n",
      "0.0011531365313653136\n",
      "0.001152870647913304\n",
      "0.001152604887044721\n",
      "0.00115233924867481\n",
      "0.001152073732718894\n",
      "0.001151808339092375\n",
      "0.0011515430677107323\n",
      "0.0011512779184895234\n",
      "0.0011510128913443832\n",
      "0.0011507479861910242\n",
      "0.001150483202945237\n",
      "0.0011502185415228894\n",
      "0.0011499540018399263\n",
      "0.0011496895838123706\n",
      "0.0011494252873563218\n",
      "0.0011491611123879567\n",
      "0.0011488970588235295\n",
      "0.0011486331265793705\n",
      "0.0011483693155718878\n",
      "0.001148105625717566\n",
      "0.001147842056932966\n",
      "0.0011475786091347257\n",
      "0.0011473152822395595\n",
      "0.0011470520761642578\n",
      "0.0011467889908256881\n",
      "0.0011465260261407934\n",
      "0.0011462631820265932\n",
      "0.0011460004584001834\n",
      "0.001145737855178735\n",
      "0.001145475372279496\n",
      "0.0011452130096197893\n",
      "0.001144950767117014\n",
      "0.0011446886446886447\n",
      "0.0011444266422522317\n",
      "0.0011441647597254005\n",
      "0.0011439029970258523\n",
      "0.0011436413540713633\n",
      "0.001143379830779785\n",
      "0.0011431184270690445\n",
      "0.001142857142857143\n",
      "0.0011425959780621572\n",
      "0.001142334932602239\n",
      "0.0011420740063956144\n",
      "0.0011418131993605847\n",
      "0.001141552511415525\n",
      "0.0011412919424788862\n",
      "0.0011410314924691922\n",
      "0.0011407711613050423\n",
      "0.0011405109489051094\n",
      "0.0011402508551881414\n",
      "0.0011399908800729594\n",
      "0.0011397310234784591\n",
      "0.0011394712853236098\n",
      "0.001139211665527455\n",
      "0.0011389521640091116\n",
      "0.0011386927806877705\n",
      "0.001138433515482696\n",
      "0.0011381743683132257\n",
      "0.001137915339098771\n",
      "0.0011376564277588168\n",
      "0.0011373976342129207\n",
      "0.0011371389583807142\n",
      "0.001136880400181901\n",
      "0.0011366219595362582\n",
      "0.0011363636363636363\n",
      "0.0011361054305839581\n",
      "0.0011358473421172195\n",
      "0.0011355893708834886\n",
      "0.0011353315168029065\n",
      "0.0011350737797956867\n",
      "0.0011348161597821154\n",
      "0.0011345586566825505\n",
      "0.001134301270417423\n",
      "0.0011340440009072353\n",
      "0.0011337868480725624\n",
      "0.0011335298118340512\n",
      "0.0011332728921124207\n",
      "0.0011330160888284614\n",
      "0.0011327594019030357\n",
      "0.0011325028312570782\n",
      "0.0011322463768115942\n",
      "0.0011319900384876612\n",
      "0.0011317338162064282\n",
      "0.0011314777098891152\n",
      "0.0011312217194570137\n",
      "0.001130965844831486\n",
      "0.0011307100859339666\n",
      "0.0011304544426859599\n",
      "0.0011301989150090416\n",
      "0.0011299435028248588\n",
      "0.0011296882060551287\n",
      "0.00112943302462164\n",
      "0.001129177958446251\n",
      "0.001128923007450892\n",
      "0.001128668171557562\n",
      "0.0011284134506883321\n",
      "0.001128158844765343\n",
      "0.0011279043537108053\n",
      "0.0011276499774470004\n",
      "0.0011273957158962795\n",
      "0.001127141568981064\n",
      "0.001126887536623845\n",
      "0.0011266336187471834\n",
      "0.0011263798152737104\n",
      "0.0011261261261261261\n",
      "0.001125872551227201\n",
      "0.0011256190904997748\n",
      "0.0011253657438667567\n",
      "0.0011251125112511251\n",
      "0.0011248593925759281\n",
      "0.0011246063877642825\n",
      "0.001124353496739375\n",
      "0.0011241007194244604\n",
      "0.0011238480557428637\n",
      "0.0011235955056179776\n",
      "0.0011233430689732643\n",
      "0.0011230907457322552\n",
      "0.0011228385358185494\n",
      "0.001122586439155815\n",
      "0.001122334455667789\n",
      "0.0011220825852782765\n",
      "0.001121830827911151\n",
      "0.0011215791834903544\n",
      "0.001121327651939897\n",
      "0.0011210762331838565\n",
      "0.0011208249271463797\n",
      "0.0011205737337516809\n",
      "0.001120322652924042\n",
      "0.0011200716845878136\n",
      "0.0011198208286674132\n",
      "0.0011195700850873264\n",
      "0.0011193194537721066\n",
      "0.0011190689346463742\n",
      "0.0011188185276348177\n",
      "0.0011185682326621924\n",
      "0.0011183180496533215\n",
      "0.0011180679785330948\n",
      "0.0011178180192264698\n",
      "0.001117568171658471\n",
      "0.0011173184357541898\n",
      "0.0011170688114387846\n",
      "0.0011168192986374804\n",
      "0.0011165698972755694\n",
      "0.0011163206072784104\n",
      "0.0011160714285714285\n",
      "0.0011158223610801161\n",
      "0.0011155734047300313\n",
      "0.001115324559446799\n",
      "0.0011150758251561106\n",
      "0.0011148272017837235\n",
      "0.0011145786892554615\n",
      "0.0011143302874972142\n",
      "0.0011140819964349377\n",
      "0.0011138338159946536\n",
      "0.0011135857461024498\n",
      "0.00111333778668448\n",
      "0.0011130899376669634\n",
      "0.001112842198976185\n",
      "0.0011125945705384957\n",
      "0.0011123470522803114\n",
      "0.001112099644128114\n",
      "0.0011118523460084502\n",
      "0.0011116051578479323\n",
      "0.0011113580795732384\n",
      "0.0011111111111111111\n",
      "0.001110864252388358\n",
      "0.0011106175033318525\n",
      "0.0011103708638685321\n",
      "0.0011101243339253996\n",
      "0.0011098779134295228\n",
      "0.0011096316023080338\n",
      "0.0011093854004881295\n",
      "0.0011091393078970719\n",
      "0.0011088933244621868\n",
      "0.0011086474501108647\n",
      "0.0011084016847705607\n",
      "0.0011081560283687944\n",
      "0.0011079104808331486\n",
      "0.0011076650420912715\n",
      "0.0011074197120708748\n",
      "0.0011071744906997344\n",
      "0.0011069293779056896\n",
      "0.0011066843736166445\n",
      "0.0011064394777605664\n",
      "0.0011061946902654867\n",
      "0.0011059500110595002\n",
      "0.0011057054400707652\n",
      "0.001105460977227504\n",
      "0.0011052166224580018\n",
      "0.0011049723756906078\n",
      "0.001104728236853734\n",
      "0.001104484205875856\n",
      "0.0011042402826855124\n",
      "0.001103996467211305\n",
      "0.0011037527593818985\n",
      "0.0011035091591260207\n",
      "0.0011032656663724624\n",
      "0.0011030222810500773\n",
      "0.0011027790030877812\n",
      "0.0011025358324145535\n",
      "0.0011022927689594356\n",
      "0.001102049812651532\n",
      "0.0011018069634200088\n",
      "0.0011015642211940956\n",
      "0.0011013215859030838\n",
      "0.001101079057476327\n",
      "0.001100836635843241\n",
      "0.001100594320933304\n",
      "0.0011003521126760564\n",
      "0.0011001100110011\n",
      "0.0010998680158380994\n",
      "0.0010996261271167802\n",
      "0.0010993843447669306\n",
      "0.0010991426687183997\n",
      "0.001098901098901099\n",
      "0.001098659635245001\n",
      "0.0010984182776801407\n",
      "0.0010981770261366132\n",
      "0.0010979358805445762\n",
      "0.0010976948408342481\n",
      "0.0010974539069359087\n",
      "0.0010972130787798991\n",
      "0.0010969723562966214\n",
      "0.0010967317394165387\n",
      "0.0010964912280701754\n",
      "0.0010962508221881166\n",
      "0.0010960105217010083\n",
      "0.0010957703265395574\n",
      "0.0010955302366345311\n",
      "0.001095290251916758\n",
      "0.0010950503723171265\n",
      "0.0010948105977665863\n",
      "0.0010945709281961471\n",
      "0.001094331363536879\n",
      "0.0010940919037199124\n",
      "0.0010938525486764385\n",
      "0.0010936132983377078\n",
      "0.0010933741526350316\n",
      "0.0010931351114997813\n",
      "0.001092896174863388\n",
      "0.0010926573426573427\n",
      "0.0010924186148131964\n",
      "0.00109217999126256\n",
      "0.0010919414719371041\n",
      "0.001091703056768559\n",
      "0.0010914647456887142\n",
      "0.0010912265386294195\n",
      "0.0010909884355225835\n",
      "0.0010907504363001745\n",
      "0.0010905125408942203\n",
      "0.0010902747492368076\n",
      "0.0010900370612600828\n",
      "0.001089799476896251\n",
      "0.0010895619960775767\n",
      "0.0010893246187363835\n",
      "0.0010890873448050533\n",
      "0.0010888501742160278\n",
      "0.001088613106901807\n",
      "0.00108837614279495\n",
      "0.001088139281828074\n",
      "0.0010879025239338555\n",
      "0.0010876658690450293\n",
      "0.001087429317094389\n",
      "0.0010871928680147858\n",
      "0.0010869565217391304\n",
      "0.0010867202782003911\n",
      "0.0010864841373315949\n",
      "0.0010862480990658267\n",
      "0.0010860121633362294\n",
      "0.0010857763300760044\n",
      "0.0010855405992184109\n",
      "0.0010853049706967658\n",
      "0.0010850694444444445\n",
      "0.0010848340203948796\n",
      "0.0010845986984815619\n",
      "0.0010843634786380394\n",
      "0.0010841283607979184\n",
      "0.0010838933448948623\n",
      "0.001083658430862592\n",
      "0.0010834236186348862\n",
      "0.0010831889081455806\n",
      "0.0010829542993285683\n",
      "0.0010827197921178\n",
      "0.001082485386447283\n",
      "0.0010822510822510823\n",
      "0.0010820168794633195\n",
      "0.0010817827780181739\n",
      "0.001081548777849881\n",
      "0.0010813148788927337\n",
      "0.001081081081081081\n",
      "0.00108084738434933\n",
      "0.001080613788631943\n",
      "0.00108038029386344\n",
      "0.001080146899978397\n",
      "0.0010799136069114472\n",
      "0.0010796804145972792\n",
      "0.001079447322970639\n",
      "0.0010792143319663286\n",
      "0.0010789814415192059\n",
      "0.0010787486515641855\n",
      "0.0010785159620362382\n",
      "0.0010782833728703904\n",
      "0.0010780508840017248\n",
      "0.0010778184953653806\n",
      "0.0010775862068965517\n",
      "0.0010773540185304892\n",
      "0.001077121930202499\n",
      "0.001076889941847943\n",
      "0.0010766580534022395\n",
      "0.001076426264800861\n",
      "0.001076194575979337\n",
      "0.0010759629868732515\n",
      "0.0010757314974182443\n",
      "0.0010755001075500108\n",
      "0.001075268817204301\n",
      "0.0010750376263169211\n",
      "0.0010748065348237317\n",
      "0.001074575542660649\n",
      "0.0010743446497636442\n",
      "0.0010741138560687433\n",
      "0.0010738831615120276\n",
      "0.001073652566029633\n",
      "0.00107342206955775\n",
      "0.0010731916720326251\n",
      "0.001072961373390558\n",
      "0.001072731173567904\n",
      "0.0010725010725010724\n",
      "0.001072271070126528\n",
      "0.001072041166380789\n",
      "0.0010718113612004287\n",
      "0.0010715816545220746\n",
      "0.0010713520462824085\n",
      "0.0010711225364181663\n",
      "0.0010708931248661383\n",
      "0.0010706638115631692\n",
      "0.001070434596446157\n",
      "0.0010702054794520547\n",
      "0.0010699764605178687\n",
      "0.001069747539580659\n",
      "0.0010695187165775401\n",
      "0.00106928999144568\n",
      "0.0010690613641223007\n",
      "0.0010688328345446773\n",
      "0.0010686044026501388\n",
      "0.0010683760683760685\n",
      "0.0010681478316599017\n",
      "0.0010679196924391287\n",
      "0.001067691650651292\n",
      "0.001067463706233988\n",
      "0.0010672358591248667\n",
      "0.0010670081092616305\n",
      "0.0010667804565820354\n",
      "0.0010665529010238908\n",
      "0.0010663254425250586\n",
      "0.0010660980810234541\n",
      "0.0010658708164570454\n",
      "0.0010656436487638534\n",
      "0.001065416577881952\n",
      "0.0010651896037494673\n",
      "0.0010649627263045794\n",
      "0.0010647359454855196\n",
      "0.0010645092612305727\n",
      "0.0010642826734780758\n",
      "0.0010640561821664183\n",
      "0.0010638297872340426\n",
      "0.0010636034886194426\n",
      "0.0010633772862611655\n",
      "0.00106315118009781\n",
      "0.0010629251700680273\n",
      "0.0010626992561105207\n",
      "0.0010624734381640458\n",
      "0.0010622477161674102\n",
      "0.0010620220900594733\n",
      "0.0010617965597791463\n",
      "0.0010615711252653928\n",
      "0.0010613457864572277\n",
      "0.0010611205432937182\n",
      "0.0010608953957139827\n",
      "0.0010606703436571913\n",
      "0.0010604453870625664\n",
      "0.0010602205258693808\n",
      "0.00105999576001696\n",
      "0.00105977108944468\n",
      "0.0010595465140919686\n",
      "0.001059322033898305\n",
      "0.0010590976488032196\n",
      "0.0010588733587462938\n",
      "0.0010586491636671606\n",
      "0.0010584250635055038\n",
      "0.0010582010582010583\n",
      "0.0010579771476936098\n",
      "0.0010577533319229956\n",
      "0.0010575296108291032\n",
      "0.0010573059843518714\n",
      "0.0010570824524312897\n",
      "0.001056859015007398\n",
      "0.0010566356720202875\n",
      "0.0010564124234100994\n",
      "0.0010561892691170257\n",
      "0.0010559662090813093\n",
      "0.0010557432432432433\n",
      "0.0010555203715431707\n",
      "0.001055297593921486\n",
      "0.0010550749103186326\n",
      "0.0010548523206751054\n",
      "0.001054629824931449\n",
      "0.001054407423028258\n",
      "0.0010541851149061775\n",
      "0.0010539629005059021\n",
      "0.001053740779768177\n",
      "0.001053518752633797\n",
      "0.0010532968190436064\n",
      "0.0010530749789385003\n",
      "0.0010528532322594231\n",
      "0.0010526315789473684\n",
      "0.0010524100189433804\n",
      "0.0010521885521885522\n",
      "0.001051967178624027\n",
      "0.001051745898190997\n",
      "0.0010515247108307045\n",
      "0.0010513036164844407\n",
      "0.0010510826150935463\n",
      "0.0010508617065994115\n",
      "0.0010506408909434755\n",
      "0.0010504201680672268\n",
      "0.0010501995379122034\n",
      "0.0010499790004199917\n",
      "0.0010497585555322277\n",
      "0.0010495382031905961\n",
      "0.001049317943336831\n",
      "0.001049097775912715\n",
      "0.0010488777008600798\n",
      "0.0010486577181208054\n",
      "0.0010484378276368212\n",
      "0.0010482180293501049\n",
      "0.0010479983232026828\n",
      "0.0010477787091366304\n",
      "0.001047559187094071\n",
      "0.0010473397570171764\n",
      "0.0010471204188481676\n",
      "0.0010469011725293131\n",
      "0.0010466820180029307\n",
      "0.0010464629552113854\n",
      "0.0010462439840970914\n",
      "0.0010460251046025104\n",
      "0.0010458063166701526\n",
      "0.0010455876202425764\n",
      "0.0010453690152623877\n",
      "0.0010451505016722408\n",
      "0.0010449320794148381\n",
      "0.0010447137484329294\n",
      "0.0010444955086693127\n",
      "0.0010442773600668337\n",
      "0.0010440593025683859\n",
      "0.0010438413361169101\n",
      "0.0010436234606553956\n",
      "0.001043405676126878\n",
      "0.001043187982474442\n",
      "0.0010429703796412183\n",
      "0.0010427528675703858\n",
      "0.001042535446205171\n",
      "0.0010423181154888472\n",
      "0.0010421008753647354\n",
      "0.0010418837257762034\n",
      "0.0010416666666666667\n",
      "0.0010414496979795876\n",
      "0.0010412328196584756\n",
      "0.0010410160316468874\n",
      "0.0010407993338884263\n",
      "0.001040582726326743\n",
      "0.0010403662089055348\n",
      "0.001040149781568546\n",
      "0.0010399334442595673\n",
      "0.001039717196922437\n",
      "0.0010395010395010396\n",
      "0.0010392849719393059\n",
      "0.0010390689941812137\n",
      "0.0010388531061707874\n",
      "0.001038637307852098\n",
      "0.0010384215991692627\n",
      "0.0010382059800664453\n",
      "0.0010379904504878555\n",
      "0.0010377750103777502\n",
      "0.0010375596596804316\n",
      "0.001037344398340249\n",
      "0.0010371292263015972\n",
      "0.0010369141435089175\n",
      "0.0010366991499066972\n",
      "0.0010364842454394694\n",
      "0.0010362694300518134\n",
      "0.0010360547036883548\n",
      "0.0010358400662937642\n",
      "0.001035625517812759\n",
      "0.0010354110581901014\n",
      "0.0010351966873706005\n",
      "0.0010349824052991099\n",
      "0.0010347682119205299\n",
      "0.0010345541071798054\n",
      "0.001034340091021928\n",
      "0.001034126163391934\n",
      "0.0010339123242349049\n",
      "0.0010336985734959686\n",
      "0.0010334849111202976\n",
      "0.0010332713370531101\n",
      "0.0010330578512396695\n",
      "0.001032844453625284\n",
      "0.0010326311441553077\n",
      "0.0010324179227751394\n",
      "0.001032204789430223\n",
      "0.0010319917440660474\n",
      "0.0010317787866281469\n",
      "0.0010315659170621002\n",
      "0.0010313531353135313\n",
      "0.0010311404413281089\n",
      "0.0010309278350515464\n",
      "0.0010307153164296021\n",
      "0.001030502885408079\n",
      "0.0010302905419328251\n",
      "0.0010300782859497322\n",
      "0.0010298661174047373\n",
      "0.001029654036243822\n",
      "0.0010294420424130121\n",
      "0.0010292301358583778\n",
      "0.0010290183165260341\n",
      "0.00102880658436214\n",
      "0.0010285949393128986\n",
      "0.0010283833813245578\n",
      "0.0010281719103434094\n",
      "0.0010279605263157894\n",
      "0.0010277492291880781\n",
      "0.0010275380189066995\n",
      "0.001027326895418122\n",
      "0.001027115858668858\n",
      "0.0010269049086054631\n",
      "0.001026694045174538\n",
      "0.0010264832683227264\n",
      "0.001026272577996716\n",
      "0.0010260619741432383\n",
      "0.0010258514567090685\n",
      "0.0010256410256410256\n",
      "0.001025430680885972\n",
      "0.001025220422390814\n",
      "0.001025010250102501\n",
      "0.0010248001639680262\n",
      "0.0010245901639344263\n",
      "0.001024380249948781\n",
      "0.0010241704219582138\n",
      "0.0010239606799098914\n",
      "0.0010237510237510238\n",
      "0.0010235414534288639\n",
      "0.001023331968890708\n",
      "0.0010231225700838961\n",
      "0.0010229132569558102\n",
      "0.0010227040294538761\n",
      "0.0010224948875255625\n",
      "0.0010222858311183807\n",
      "0.0010220768601798855\n",
      "0.0010218679746576743\n",
      "0.001021659174499387\n",
      "0.0010214504596527069\n",
      "0.0010212418300653595\n",
      "0.0010210332856851133\n",
      "0.0010208248264597796\n",
      "0.0010206164523372118\n",
      "0.0010204081632653062\n",
      "0.0010201999591920017\n",
      "0.0010199918400652795\n",
      "0.0010197838058331635\n",
      "0.0010195758564437193\n",
      "0.0010193679918450561\n",
      "0.0010191602119853241\n",
      "0.0010189525168127166\n",
      "0.0010187449062754685\n",
      "0.001018537380321858\n",
      "0.0010183299389002036\n",
      "0.0010181225819588678\n",
      "0.001017915309446254\n",
      "0.0010177081213108082\n",
      "0.0010175010175010174\n",
      "0.001017293997965412\n",
      "0.0010170870626525631\n",
      "0.001016880211511084\n",
      "0.0010166734444896298\n",
      "0.0010164667615368977\n",
      "0.0010162601626016261\n",
      "0.001016053647632595\n",
      "0.0010158472165786266\n",
      "0.0010156408693885843\n",
      "0.0010154346060113728\n",
      "0.0010152284263959391\n",
      "0.0010150223304912708\n",
      "0.0010148163182463973\n",
      "0.0010146103896103895\n",
      "0.0010144045445323595\n",
      "0.0010141987829614604\n",
      "0.001013993104846887\n",
      "0.001013787510137875\n",
      "0.0010135819987837015\n",
      "0.0010133765707336846\n",
      "0.0010131712259371835\n",
      "0.001012965964343598\n",
      "0.0010127607859023698\n",
      "0.001012555690562981\n",
      "0.0010123506782749544\n",
      "0.0010121457489878543\n",
      "0.0010119409026512851\n",
      "0.0010117361392148927\n",
      "0.0010115314586283633\n",
      "0.0010113268608414239\n",
      "0.0010111223458038423\n",
      "0.0010109179134654266\n",
      "0.001010713563776026\n",
      "0.0010105092966855296\n",
      "0.0010103051121438675\n",
      "0.00101010101010101\n",
      "0.0010098969905069683\n",
      "0.0010096930533117932\n",
      "0.0010094891984655764\n",
      "0.0010092854259184498\n",
      "0.0010090817356205853\n",
      "0.0010088781275221952\n",
      "0.0010086746015735323\n",
      "0.001008471157724889\n",
      "0.001008267795926598\n",
      "0.0010080645161290322\n",
      "0.0010078613182826044\n",
      "0.001007658202337767\n",
      "0.0010074551682450132\n",
      "0.001007252215954875\n",
      "0.0010070493454179255\n",
      "0.0010068465565847766\n",
      "0.0010066438494060802\n",
      "0.001006441223832528\n",
      "0.001006238679814852\n",
      "0.001006036217303823\n",
      "0.0010058338362502514\n",
      "0.001005631536604988\n",
      "0.0010054293183189222\n",
      "0.0010052271813429834\n",
      "0.0010050251256281408\n",
      "0.0010048231511254019\n",
      "0.0010046212577858146\n",
      "0.001004419445560466\n",
      "0.001004217714400482\n",
      "0.001004016064257028\n",
      "0.001003814495081309\n",
      "0.0010036130068245685\n",
      "0.0010034115994380895\n",
      "0.0010032102728731941\n",
      "0.0010030090270812437\n",
      "0.0010028078620136383\n",
      "0.0010026067776218166\n",
      "0.0010024057738572574\n",
      "0.0010022048506714773\n",
      "0.001002004008016032\n",
      "0.0010018032458425166\n",
      "0.001001602564102564\n",
      "0.001001401962747847\n",
      "0.001001201441730076\n",
      "0.001001001001001001\n",
      "0.0010008006405124099\n",
      "0.0010006003602161296\n",
      "0.0010004001600640256\n",
      "0.0010002000400080016\n",
      "0.001\n",
      "0.0009998000399920016\n",
      "0.0009996001599360256\n",
      "0.0009994003597841295\n",
      "0.0009992006394884093\n",
      "0.000999000999000999\n",
      "0.000998801438274071\n",
      "0.0009986019572598363\n",
      "0.000998402555910543\n",
      "0.0009982032341784787\n",
      "0.000998003992015968\n",
      "0.000997804829375374\n",
      "0.0009976057462090981\n",
      "0.000997406742469579\n",
      "0.000997207818109294\n",
      "0.0009970089730807576\n",
      "0.000996810207336523\n",
      "0.000996611520829181\n",
      "0.0009964129135113591\n",
      "0.0009962143853357243\n",
      "0.00099601593625498\n",
      "0.0009958175662218682\n",
      "0.0009956192751891676\n",
      "0.0009954210631096954\n",
      "0.0009952229299363057\n",
      "0.0009950248756218905\n",
      "0.0009948269001193793\n",
      "0.0009946290033817386\n",
      "0.000994431185361973\n",
      "0.000994233446013124\n",
      "0.0009940357852882703\n",
      "0.0009938382031405286\n",
      "0.0009936406995230524\n",
      "0.0009934432743890324\n",
      "0.0009932459276916965\n",
      "0.0009930486593843098\n",
      "0.0009928514694201747\n",
      "0.0009926543577526306\n",
      "0.0009924573243350536\n",
      "0.0009922603691208574\n",
      "0.000992063492063492\n",
      "0.0009918666931164452\n",
      "0.0009916699722332407\n",
      "0.00099147332936744\n",
      "0.0009912767644726407\n",
      "0.0009910802775024777\n",
      "0.0009908838684106222\n",
      "0.0009906875371507827\n",
      "0.0009904912836767037\n",
      "0.0009902951079421667\n"
     ]
    }
   ],
   "source": [
    "thetha = np.random.rand(2,1) # random initialisation\n",
    "# m is number of data points\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(thetha) - yi)\n",
    "        eta = learning_schedule(epoch * m + i )\n",
    "        print(eta)\n",
    "        thetha = thetha - eta * gradients\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdd9855f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.36045555],\n",
       "       [2.92617513]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4945180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor(eta0=0.1, penalty=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SGDRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.SGDRegressor.html\">?<span>Documentation for SGDRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">loss&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">0.15</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shuffle',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shuffle&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('epsilon',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">epsilon&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;invscaling&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eta0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eta0&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('power_t',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">power_t&nbsp;</td>\n",
       "            <td class=\"value\">0.25</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_fraction&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter_no_change&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('average',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">average&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "SGDRegressor(eta0=0.1, penalty=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attempting SGD using  Scikit learn\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg= SGDRegressor(penalty=None, eta0=0.1)\n",
    "\n",
    "sgd_reg.fit(X, y.ravel()) # automatically sets for bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d6c6de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.38407317])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7b142e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.96994555])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424881c",
   "metadata": {},
   "source": [
    "\n",
    "## Polynomial Regression\n",
    "\n",
    " Surprisingly,\n",
    " you can actually use a linear model to fit nonlinear data. A simple way to do this is to\n",
    " add powers of each feature as new features, then train a linear model on this extended\n",
    " set of features. This technique is called Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91009768",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m X\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m X \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(m,\u001b[38;5;241m1\u001b[39m ) \u001b[38;5;66;03m# plotting a quadratic equation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxlabel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, let’s generate some nonlinear data, based on a simple quadratic equation\n",
    "\n",
    "m = 100\n",
    "X = 6 * np.random.rand(m, 1) - 3\n",
    "y = 0.5 * X**2 + X + 2 + np.random.randn(m,1 ) # plotting a quadratic equation\n",
    "\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2ffe197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c6a9093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # 100 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "238786c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7646556]\n",
      "[0.7646556  0.58469819]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(X_poly[0]) #  X_poly now contains the original feature of X plus the square of this feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5ba1b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9245328] [[0.9905883  0.52640816]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, y)\n",
    "print(lin_reg.intercept_, lin_reg.coef_)\n",
    "\n",
    "\n",
    "y_predicted = lin_reg.predict(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c000ea5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X, y_predicted, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxlabel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(X, y_predicted, \"r.\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aac5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we do three degree??\n",
    "\n",
    "three_deg_poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly_three_deg = three_deg_poly_features.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d45c4f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_deg_lin_reg = LinearRegression()\n",
    "three_deg_lin_reg.fit(X_poly_three_deg, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caa4e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_three_deg = three_deg_lin_reg.predict(X_poly_three_deg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2b981b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x263a17a41f0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(X, y_pred_three_deg, \"r.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15b6defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_two_deg = mean_squared_error(y, y_predicted)\n",
    "mse_three_deg = mean_squared_error(y, y_pred_three_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72f1dd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two deg error  0.789678056158672\n",
      "three deg error  0.7896659070564992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._base.LinearRegression"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"two deg error \", mse_two_deg)\n",
    "print(\"three deg error \", mse_three_deg)\n",
    "LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5f82d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deciding on complexity of the model\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def plot_learning_curves(model, X: np.array, y: np.array, title: str): # training set = validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    \n",
    "    for m in range(1, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        \n",
    "        train_errors.append(rmse(y_train[:m], y_train_predict))\n",
    "        val_errors.append(rmse(y_val, y_val_predict))\n",
    "        \n",
    "        \n",
    "    plt.plot(train_errors, \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(val_errors, \"b-\", linewidth=3, label=\"val\")\n",
    "    plt.ylabel = \"RMSE\"\n",
    "    plt.xlabel = \"Training Set size\"\n",
    "    plt.title(title)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf39d816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "plot_learning_curves(lin_reg, X, y, \"Linear Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01348cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let’s look at the learning curves of a 10th-degree polynomial model on the same data\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "poly_regression = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=10, include_bias=False)),\n",
    "    (\"lin_reg\", LinearRegression())\n",
    "])\n",
    "\n",
    "plot_learning_curves(poly_regression, X, y, \"10 degree Polynomial Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f7f7a3",
   "metadata": {},
   "source": [
    "## One way to improve an overfitting model is to feed it more training\n",
    "## data until the validation error reaches the training error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e41b47",
   "metadata": {},
   "source": [
    "# Regularisation\n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    " adding a penalty term... means minimising the loss function and the values of weights also"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bcae3",
   "metadata": {},
   "source": [
    "#### in linear regression, you can perform Ridge regularisaation using\n",
    "1. closed form soln (like normal equation of linear regression)\n",
    "2. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e9ef3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.985911])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Closed form Solution Ridge Regression\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg= Ridge(alpha=1, solver=\"cholesky\")\n",
    "ridge_reg.fit(X,y)\n",
    "ridge_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cce3654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.8389915])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Stochastic Gradient descent\n",
    "\n",
    "sgd_reg_with_ridge = SGDRegressor(penalty=\"l2\", max_iter=5000, eta0=0.01) # l2 means square of weights is added (ridge).. l1 means absolutbe weights are added (lasso)\n",
    "sgd_reg_with_ridge.fit(X, y.ravel())\n",
    "\n",
    "sgd_reg.predict([[1.5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66a37bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.30236887]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "sgd_reg = make_pipeline(\n",
    "    StandardScaler(),  # Feature scaling is crucial\n",
    "    SGDRegressor(\n",
    "        penalty=\"l2\",     # Ridge\n",
    "        alpha=1.0,        # Match alpha with Ridge\n",
    "        max_iter=5000,    # More iterations\n",
    "        tol=1e-5,         # Allow tighter convergence\n",
    "        # learning_rate='constant',\n",
    "        eta0=0.01,        # Learning rate\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "print(sgd_reg.predict([[1.5]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae21bdf",
   "metadata": {},
   "source": [
    "####  Lasso Regression automatically performs feature selection and outputs a sparse model (i.e., with few nonzero feature weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7c10296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.94526955])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg  = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(X, y)\n",
    "\n",
    "lasso_reg.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d5352",
   "metadata": {},
   "source": [
    " So when should you use plain Linear Regression (i.e., without any regularization),\n",
    " Ridge, Lasso, or Elastic Net? It is almost always preferable to have at least a little bit of\n",
    " regularization, so generally you should avoid plain Linear Regression. Ridge is a good\n",
    " default, but if you suspect that only a few features are actually useful, you should pre\n",
    "fer Lasso or Elastic Net since they tend to reduce the useless features’ weights down to\n",
    " zero as we have discussed. In general, Elastic Net is preferred over Lasso since Lasso\n",
    " may behave erratically when the number of features is greater than the number of\n",
    " training instances or when several features are strongly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19b41b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.94747062])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementing elastic net\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5) # alpha = a + b and l1_ratio = a / (a + b)\n",
    "elastic_net.fit(X, y)\n",
    "elastic_net.predict([[1.5]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0f674",
   "metadata": {},
   "source": [
    "## “beautiful free lunch.” or Early stopping\n",
    "\n",
    "jaise hi minimum RMSE aa jaye on validation dataset then rok doo!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6636b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1579: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# implementation of early stopping\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "poly_scaler = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=90, include_bias=False)),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "    \n",
    "])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "X_train_poly_scaled = poly_scaler.fit_transform(X_train)\n",
    "X_val_poly_scaled = poly_scaler.transform(X_val)\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=1, warm_start=True, penalty=None, learning_rate=\"constant\", eta0=0.0005)\n",
    "\n",
    "# When set to True, reuse the solution of the previous call to fit as\n",
    "#         initialization, otherwise, just erase the previous solution.\n",
    "\n",
    "minimum_val_error = float(\"inf\")\n",
    "best_epoch = None\n",
    "best_model = None\n",
    "for epoch in range(1000): ## 1000 baar train krke dekhein ?? \n",
    "    sgd_reg.fit(X_train_poly_scaled, y_train) # continues where it left off, maybe due to warm_start is true\n",
    "    y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
    "    val_error = mean_squared_error(y_val, y_val_predict)\n",
    "    \n",
    "    if val_error < minimum_val_error:\n",
    "        minimum_val_error = val_error\n",
    "        best_epoch = epoch\n",
    "        best_model = clone(sgd_reg)\n",
    "    \n",
    "\n",
    "#  Note that with warm_start=True, when the fit() method is called, it just continues\n",
    "#  training where it left off instead of restarting from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a1bd55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(sgd_reg, \"best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "607ec3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = joblib.load(\"best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c45c7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted = best_model.predict(X_val_poly_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7f12c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.83901957],\n",
       "       [3.82011849],\n",
       "       [0.74354647],\n",
       "       [3.71182493],\n",
       "       [0.03773502],\n",
       "       [2.81852767],\n",
       "       [6.4520331 ],\n",
       "       [5.13898156],\n",
       "       [0.60647284],\n",
       "       [4.07662839],\n",
       "       [8.17431609],\n",
       "       [5.11583952],\n",
       "       [2.70785884],\n",
       "       [1.32714673],\n",
       "       [4.42477344],\n",
       "       [9.61952571],\n",
       "       [4.719299  ],\n",
       "       [6.99596622],\n",
       "       [3.27622149],\n",
       "       [2.36952224]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28e9366e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0232741831705798"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_val, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e84a64",
   "metadata": {},
   "source": [
    "#### LOGiSTIC REGRESSION\n",
    "\n",
    "1. a regression which does classification\n",
    "2. calculates probabilty of belonging to a particular class\n",
    "3. just give predicted value (thetha transpose x) to sigmoid function and it will spit out a probabiltiy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f645a",
   "metadata": {},
   "source": [
    "#### cost function for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f50417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "print(list(iris.keys()))\n",
    "\n",
    "# 4 features - sepal length, sepal width, petal length, petal width\n",
    "# classes - 0,1,2 --> iris setosa, iris versicolor, iris verginica\n",
    "\n",
    "## prob: train a logistic regression classifer to predict wether a flower is iris verginica or not\n",
    "\n",
    "X = iris[\"data\"][:, 3: ] # petal width only\n",
    "y= (iris[\"target\"] == 2).astype(np.int8)\n",
    "\n",
    "print(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0828b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61c4ff57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e6810bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Probability')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using matplotlib for visuallisation\n",
    "from importlib import reload\n",
    "plt =reload(plt)\n",
    "\n",
    "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y_prob = clf.predict_proba(X_new)\n",
    "plt.plot(X_new, y_prob[:, 1], \"g-\", label=\"virginica\")\n",
    "plt.plot(X_new, y_prob[:, 0], \"b--\", label=\"Non virginica\") \n",
    "\n",
    "plt.xlabel(\"Petal width(cm)\")\n",
    "plt.ylabel(\"Probability\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c0dc55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1.7], [1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce0f06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Just like the other linear models, Logistic Regression models can be regularized using \n",
    "# ℓ1\n",
    "#  or ℓ2\n",
    "#  penalties. Scitkit-Learn actually adds an ℓ2\n",
    "#  penalty by default\n",
    "\n",
    "# The hyperparameter controlling the regularization strength of a\n",
    "#  Scikit-Learn LogisticRegression model is not alpha (as in other\n",
    "#  linear models), but its inverse: C. The higher the value of C, the less\n",
    "#  the model is regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd99c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[\"data\"][:,(2,3)] # petal length and petal width only we are considering as features\n",
    "y = iris[\"target\"] ## we have three classes here (or three labels)\n",
    "\n",
    "softmax_reg = LogisticRegression(C=10, solver=\"lbfgs\", multi_class=\"multinomial\")    # higher C hyperparameter means less regularisation (inverse of alpha used in regularisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5d4ffbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learning_ml\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;multinomial&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, multi_class='multinomial')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01056a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg.predict([[5, 2]]) # preding iris with 5 cm long and 2 cm wide petals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d0452b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.21626370e-07, 5.73689802e-02, 9.42630398e-01]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg.predict_proba([[5, 2]]) # predicts class 2 with highest score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5403c08",
   "metadata": {},
   "source": [
    " 1. What Linear Regression training algorithm can you use if you have a training set\n",
    " with millions of features?\n",
    "\n",
    " ans1: Normal equation, as it scale very good with large no of features but due to inversing of instance matrix, if we have many number of instances, then using Gradient Descent is better.\n",
    "\n",
    "\n",
    "\n",
    " 2. Suppose the features in your training set have very different scales. What algo\n",
    "rithms might suffer from this, and how? What can you do about it?\n",
    "\n",
    " ans2: Regularisation models will suffer from this, Use standard scaler, its  a good practice to use it \n",
    "\n",
    " 3. Can Gradient Descent get stuck in a local minimum when training a Logistic\n",
    " Regression model?\n",
    "\n",
    " ans3. yes it can get very well stuck, that's why we use Stochiastic GD sometimes when the graph is not convex.\n",
    "\n",
    " 4. Do all Gradient Descent algorithms lead to the same model provided you let\n",
    " them run long enough?\n",
    " ans4. Maybe\n",
    "\n",
    " 5. Suppose you use Batch Gradient Descent and you plot the validation error at\n",
    " every epoch. If you notice that the validation error consistently goes up, what is\n",
    " likely going on? How can you fix this?\n",
    "\n",
    " ans 5. this means the model is performing poorly on the validation dataset, leading to the conclusion that the model is underfitting.. feed it more data points or use a more complex model\n",
    "\n",
    " 6. Is it a good idea to stop Mini-batch Gradient Descent immediately when the vali\n",
    "dation error goes up?\n",
    "\n",
    "ans6. No, wait a little.. \n",
    "\n",
    " 7. Which Gradient Descent algorithm (among those we discussed) will reach the\n",
    " vicinity of the optimal solution the fastest? Which will actually converge? How\n",
    " can you make the others converge as well?\n",
    "\n",
    " ans 7. we discussed Gradient Descent, that runs on all instances, smooth graph, very high computation power required if millions of instances and can get stuck at local minima.. and may never reach global minima\n",
    " second we discussed, stochisatic GD, randomly picks instances, and weights for that.. i dont get ur weird question , lets move forward\n",
    "\n",
    " 8. Suppose you are using Polynomial Regression. You plot the learning curves and\n",
    " you notice that there is a large gap between the training error and the validation\n",
    " error. What is happening? What are three ways to solve this?\n",
    "\n",
    " ans8. large gap between training error and val error generally means that the model is overfitting. you can reduce the complexity of the model or try penalising the model, using regularisation, 3 major techniuqes --> Ridge Regression (l2), Lasso Regression (l1), elastic net (mix)\n",
    "\n",
    " 9. Suppose you are using Ridge Regression and you notice that the training error\n",
    " and the validation error are almost equal and fairly high. Would you say that the\n",
    " model suffers from high bias or high variance? Should you increase the regulari\n",
    "zation hyperparameter α or reduce it?\n",
    "\n",
    "ans 9, in that case, i belive model is underfitting and variance is high and bias is low, hyperparameter alpha should be reduced and penalty should be decreased for an optimal model\n",
    "\n",
    "\n",
    " 10. Why would you want to use:\n",
    " • Ridge Regression instead of plain Linear Regression (i.e., without any regulari\n",
    "zation)?  ---> to prevent overfitting\n",
    " • Lasso instead of Ridge Regression? ----> to prevent overfitting and feature selection (eliminate least important features)\n",
    " • Elastic Net instead of Lasso? ---> when we need custom mix of lasso and ridge both ig\n",
    "\n",
    " 11. Suppose you want to classify pictures as outdoor/indoor and daytime/nighttime.\n",
    " Should you implement two Logistic Regression classifiers or one Softmax Regres\n",
    "sion classifier? --> two logistic regression classifiers\n",
    "\n",
    " 12. Implement Batch Gradient Descent with early stopping for Softmax Regression \n",
    "(without using Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f7454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95797629, 4.07166218, 1.48940496, 5.75567177]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63400bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831264a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fc4aed2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 | error:  -1.110223024625156e-15\n",
      "epoch:  1 | error:  -1.110223024625156e-15\n",
      "epoch:  2 | error:  -1.110223024625156e-15\n",
      "epoch:  3 | error:  -1.110223024625156e-15\n",
      "epoch:  4 | error:  -1.110223024625156e-15\n",
      "epoch:  5 | error:  -1.110223024625156e-15\n",
      "epoch:  6 | error:  -1.110223024625156e-15\n",
      "epoch:  7 | error:  -1.110223024625156e-15\n",
      "epoch:  8 | error:  -1.110223024625156e-15\n",
      "epoch:  9 | error:  -1.110223024625156e-15\n",
      "epoch:  10 | error:  -1.110223024625156e-15\n",
      "epoch:  11 | error:  -1.110223024625156e-15\n",
      "epoch:  12 | error:  -1.110223024625156e-15\n",
      "epoch:  13 | error:  -1.110223024625156e-15\n",
      "epoch:  14 | error:  -1.110223024625156e-15\n",
      "epoch:  15 | error:  -1.110223024625156e-15\n",
      "epoch:  16 | error:  -1.110223024625156e-15\n",
      "epoch:  17 | error:  -1.110223024625156e-15\n",
      "epoch:  18 | error:  -1.110223024625156e-15\n",
      "epoch:  19 | error:  -1.110223024625156e-15\n",
      "epoch:  20 | error:  -1.110223024625156e-15\n",
      "epoch:  21 | error:  -1.110223024625156e-15\n",
      "epoch:  22 | error:  -1.110223024625156e-15\n",
      "epoch:  23 | error:  -1.110223024625156e-15\n",
      "epoch:  24 | error:  -1.110223024625156e-15\n",
      "epoch:  25 | error:  -1.110223024625156e-15\n",
      "epoch:  26 | error:  -1.110223024625156e-15\n",
      "epoch:  27 | error:  -1.110223024625156e-15\n",
      "epoch:  28 | error:  -1.110223024625156e-15\n",
      "epoch:  29 | error:  -1.110223024625156e-15\n",
      "epoch:  30 | error:  -1.110223024625156e-15\n",
      "epoch:  31 | error:  -1.110223024625156e-15\n",
      "epoch:  32 | error:  -1.110223024625156e-15\n",
      "epoch:  33 | error:  -1.110223024625156e-15\n",
      "epoch:  34 | error:  -1.110223024625156e-15\n",
      "epoch:  35 | error:  -1.110223024625156e-15\n",
      "epoch:  36 | error:  -1.110223024625156e-15\n",
      "epoch:  37 | error:  -1.110223024625156e-15\n",
      "epoch:  38 | error:  -1.110223024625156e-15\n",
      "epoch:  39 | error:  -1.110223024625156e-15\n",
      "epoch:  40 | error:  -1.110223024625156e-15\n",
      "epoch:  41 | error:  -1.110223024625156e-15\n",
      "epoch:  42 | error:  -1.110223024625156e-15\n",
      "epoch:  43 | error:  -1.110223024625156e-15\n",
      "epoch:  44 | error:  -1.110223024625156e-15\n",
      "epoch:  45 | error:  -1.110223024625156e-15\n",
      "epoch:  46 | error:  -1.110223024625156e-15\n",
      "epoch:  47 | error:  -1.110223024625156e-15\n",
      "epoch:  48 | error:  -1.110223024625156e-15\n",
      "epoch:  49 | error:  -1.110223024625156e-15\n",
      "epoch:  50 | error:  -1.110223024625156e-15\n",
      "epoch:  51 | error:  -1.110223024625156e-15\n",
      "epoch:  52 | error:  -1.110223024625156e-15\n",
      "epoch:  53 | error:  -1.110223024625156e-15\n",
      "epoch:  54 | error:  -1.110223024625156e-15\n",
      "epoch:  55 | error:  -1.110223024625156e-15\n",
      "epoch:  56 | error:  -1.110223024625156e-15\n",
      "epoch:  57 | error:  -1.110223024625156e-15\n",
      "epoch:  58 | error:  -1.110223024625156e-15\n",
      "epoch:  59 | error:  -1.110223024625156e-15\n",
      "epoch:  60 | error:  -1.110223024625156e-15\n",
      "epoch:  61 | error:  -1.110223024625156e-15\n",
      "epoch:  62 | error:  -1.110223024625156e-15\n",
      "epoch:  63 | error:  -1.110223024625156e-15\n",
      "epoch:  64 | error:  -1.110223024625156e-15\n",
      "epoch:  65 | error:  -1.110223024625156e-15\n",
      "epoch:  66 | error:  -1.110223024625156e-15\n",
      "epoch:  67 | error:  -1.110223024625156e-15\n",
      "epoch:  68 | error:  -1.110223024625156e-15\n",
      "epoch:  69 | error:  -1.110223024625156e-15\n",
      "epoch:  70 | error:  -1.110223024625156e-15\n",
      "epoch:  71 | error:  -1.110223024625156e-15\n",
      "epoch:  72 | error:  -1.110223024625156e-15\n",
      "epoch:  73 | error:  -1.110223024625156e-15\n",
      "epoch:  74 | error:  -1.110223024625156e-15\n",
      "epoch:  75 | error:  -1.110223024625156e-15\n",
      "epoch:  76 | error:  -1.110223024625156e-15\n",
      "epoch:  77 | error:  -1.110223024625156e-15\n",
      "epoch:  78 | error:  -1.110223024625156e-15\n",
      "epoch:  79 | error:  -1.110223024625156e-15\n",
      "epoch:  80 | error:  -1.110223024625156e-15\n",
      "epoch:  81 | error:  -1.110223024625156e-15\n",
      "epoch:  82 | error:  -1.110223024625156e-15\n",
      "epoch:  83 | error:  -1.110223024625156e-15\n",
      "epoch:  84 | error:  -1.110223024625156e-15\n",
      "epoch:  85 | error:  -1.110223024625156e-15\n",
      "epoch:  86 | error:  -1.110223024625156e-15\n",
      "epoch:  87 | error:  -1.110223024625156e-15\n",
      "epoch:  88 | error:  -1.110223024625156e-15\n",
      "epoch:  89 | error:  -1.110223024625156e-15\n",
      "epoch:  90 | error:  -1.110223024625156e-15\n",
      "epoch:  91 | error:  -1.110223024625156e-15\n",
      "epoch:  92 | error:  -1.110223024625156e-15\n",
      "epoch:  93 | error:  -1.110223024625156e-15\n",
      "epoch:  94 | error:  -1.110223024625156e-15\n",
      "epoch:  95 | error:  -1.110223024625156e-15\n",
      "epoch:  96 | error:  -1.110223024625156e-15\n",
      "epoch:  97 | error:  -1.110223024625156e-15\n",
      "epoch:  98 | error:  -1.110223024625156e-15\n",
      "epoch:  99 | error:  -1.110223024625156e-15\n",
      "epoch:  100 | error:  -1.110223024625156e-15\n",
      "epoch:  101 | error:  -1.110223024625156e-15\n",
      "epoch:  102 | error:  -1.110223024625156e-15\n",
      "epoch:  103 | error:  -1.110223024625156e-15\n",
      "epoch:  104 | error:  -1.110223024625156e-15\n",
      "epoch:  105 | error:  -1.110223024625156e-15\n",
      "epoch:  106 | error:  -1.110223024625156e-15\n",
      "epoch:  107 | error:  -1.110223024625156e-15\n",
      "epoch:  108 | error:  -1.110223024625156e-15\n",
      "epoch:  109 | error:  -1.110223024625156e-15\n",
      "epoch:  110 | error:  -1.110223024625156e-15\n",
      "epoch:  111 | error:  -1.110223024625156e-15\n",
      "epoch:  112 | error:  -1.110223024625156e-15\n",
      "epoch:  113 | error:  -1.110223024625156e-15\n",
      "epoch:  114 | error:  -1.110223024625156e-15\n",
      "epoch:  115 | error:  -1.110223024625156e-15\n",
      "epoch:  116 | error:  -1.110223024625156e-15\n",
      "epoch:  117 | error:  -1.110223024625156e-15\n",
      "epoch:  118 | error:  -1.110223024625156e-15\n",
      "epoch:  119 | error:  -1.110223024625156e-15\n",
      "epoch:  120 | error:  -1.110223024625156e-15\n",
      "epoch:  121 | error:  -1.110223024625156e-15\n",
      "epoch:  122 | error:  -1.110223024625156e-15\n",
      "epoch:  123 | error:  -1.110223024625156e-15\n",
      "epoch:  124 | error:  -1.110223024625156e-15\n",
      "epoch:  125 | error:  -1.110223024625156e-15\n",
      "epoch:  126 | error:  -1.110223024625156e-15\n",
      "epoch:  127 | error:  -1.110223024625156e-15\n",
      "epoch:  128 | error:  -1.110223024625156e-15\n",
      "epoch:  129 | error:  -1.110223024625156e-15\n",
      "epoch:  130 | error:  -1.110223024625156e-15\n",
      "epoch:  131 | error:  -1.110223024625156e-15\n",
      "epoch:  132 | error:  -1.110223024625156e-15\n",
      "epoch:  133 | error:  -1.110223024625156e-15\n",
      "epoch:  134 | error:  -1.110223024625156e-15\n",
      "epoch:  135 | error:  -1.110223024625156e-15\n",
      "epoch:  136 | error:  -1.110223024625156e-15\n",
      "epoch:  137 | error:  -1.110223024625156e-15\n",
      "epoch:  138 | error:  -1.110223024625156e-15\n",
      "epoch:  139 | error:  -1.110223024625156e-15\n",
      "epoch:  140 | error:  -1.110223024625156e-15\n",
      "epoch:  141 | error:  -1.110223024625156e-15\n",
      "epoch:  142 | error:  -1.110223024625156e-15\n",
      "epoch:  143 | error:  -1.110223024625156e-15\n",
      "epoch:  144 | error:  -1.110223024625156e-15\n",
      "epoch:  145 | error:  -1.110223024625156e-15\n",
      "epoch:  146 | error:  -1.110223024625156e-15\n",
      "epoch:  147 | error:  -1.110223024625156e-15\n",
      "epoch:  148 | error:  -1.110223024625156e-15\n",
      "epoch:  149 | error:  -1.110223024625156e-15\n",
      "epoch:  150 | error:  -1.110223024625156e-15\n",
      "epoch:  151 | error:  -1.110223024625156e-15\n",
      "epoch:  152 | error:  -1.110223024625156e-15\n",
      "epoch:  153 | error:  -1.110223024625156e-15\n",
      "epoch:  154 | error:  -1.110223024625156e-15\n",
      "epoch:  155 | error:  -1.110223024625156e-15\n",
      "epoch:  156 | error:  -1.110223024625156e-15\n",
      "epoch:  157 | error:  -1.110223024625156e-15\n",
      "epoch:  158 | error:  -1.110223024625156e-15\n",
      "epoch:  159 | error:  -1.110223024625156e-15\n",
      "epoch:  160 | error:  -1.110223024625156e-15\n",
      "epoch:  161 | error:  -1.110223024625156e-15\n",
      "epoch:  162 | error:  -1.110223024625156e-15\n",
      "epoch:  163 | error:  -1.110223024625156e-15\n",
      "epoch:  164 | error:  -1.110223024625156e-15\n",
      "epoch:  165 | error:  -1.110223024625156e-15\n",
      "epoch:  166 | error:  -1.110223024625156e-15\n",
      "epoch:  167 | error:  -1.110223024625156e-15\n",
      "epoch:  168 | error:  -1.110223024625156e-15\n",
      "epoch:  169 | error:  -1.110223024625156e-15\n",
      "epoch:  170 | error:  -1.110223024625156e-15\n",
      "epoch:  171 | error:  -1.110223024625156e-15\n",
      "epoch:  172 | error:  -1.110223024625156e-15\n",
      "epoch:  173 | error:  -1.110223024625156e-15\n",
      "epoch:  174 | error:  -1.110223024625156e-15\n",
      "epoch:  175 | error:  -1.110223024625156e-15\n",
      "epoch:  176 | error:  -1.110223024625156e-15\n",
      "epoch:  177 | error:  -1.110223024625156e-15\n",
      "epoch:  178 | error:  -1.110223024625156e-15\n",
      "epoch:  179 | error:  -1.110223024625156e-15\n",
      "epoch:  180 | error:  -1.110223024625156e-15\n",
      "epoch:  181 | error:  -1.110223024625156e-15\n",
      "epoch:  182 | error:  -1.110223024625156e-15\n",
      "epoch:  183 | error:  -1.110223024625156e-15\n",
      "epoch:  184 | error:  -1.110223024625156e-15\n",
      "epoch:  185 | error:  -1.110223024625156e-15\n",
      "epoch:  186 | error:  -1.110223024625156e-15\n",
      "epoch:  187 | error:  -1.110223024625156e-15\n",
      "epoch:  188 | error:  -1.110223024625156e-15\n",
      "epoch:  189 | error:  -1.110223024625156e-15\n",
      "epoch:  190 | error:  -1.110223024625156e-15\n",
      "epoch:  191 | error:  -1.110223024625156e-15\n",
      "epoch:  192 | error:  -1.110223024625156e-15\n",
      "epoch:  193 | error:  -1.110223024625156e-15\n",
      "epoch:  194 | error:  -1.110223024625156e-15\n",
      "epoch:  195 | error:  -1.110223024625156e-15\n",
      "epoch:  196 | error:  -1.110223024625156e-15\n",
      "epoch:  197 | error:  -1.110223024625156e-15\n",
      "epoch:  198 | error:  -1.110223024625156e-15\n",
      "epoch:  199 | error:  -1.110223024625156e-15\n",
      "epoch:  200 | error:  -1.110223024625156e-15\n",
      "epoch:  201 | error:  -1.110223024625156e-15\n",
      "epoch:  202 | error:  -1.110223024625156e-15\n",
      "epoch:  203 | error:  -1.110223024625156e-15\n",
      "epoch:  204 | error:  -1.110223024625156e-15\n",
      "epoch:  205 | error:  -1.110223024625156e-15\n",
      "epoch:  206 | error:  -1.110223024625156e-15\n",
      "epoch:  207 | error:  -1.110223024625156e-15\n",
      "epoch:  208 | error:  -1.110223024625156e-15\n",
      "epoch:  209 | error:  -1.110223024625156e-15\n",
      "epoch:  210 | error:  -1.110223024625156e-15\n",
      "epoch:  211 | error:  -1.110223024625156e-15\n",
      "epoch:  212 | error:  -1.110223024625156e-15\n",
      "epoch:  213 | error:  -1.110223024625156e-15\n",
      "epoch:  214 | error:  -1.110223024625156e-15\n",
      "epoch:  215 | error:  -1.110223024625156e-15\n",
      "epoch:  216 | error:  -1.110223024625156e-15\n",
      "epoch:  217 | error:  -1.110223024625156e-15\n",
      "epoch:  218 | error:  -1.110223024625156e-15\n",
      "epoch:  219 | error:  -1.110223024625156e-15\n",
      "epoch:  220 | error:  -1.110223024625156e-15\n",
      "epoch:  221 | error:  -1.110223024625156e-15\n",
      "epoch:  222 | error:  -1.110223024625156e-15\n",
      "epoch:  223 | error:  -1.110223024625156e-15\n",
      "epoch:  224 | error:  -1.110223024625156e-15\n",
      "epoch:  225 | error:  -1.110223024625156e-15\n",
      "epoch:  226 | error:  -1.110223024625156e-15\n",
      "epoch:  227 | error:  -1.110223024625156e-15\n",
      "epoch:  228 | error:  -1.110223024625156e-15\n",
      "epoch:  229 | error:  -1.110223024625156e-15\n",
      "epoch:  230 | error:  -1.110223024625156e-15\n",
      "epoch:  231 | error:  -1.110223024625156e-15\n",
      "epoch:  232 | error:  -1.110223024625156e-15\n",
      "epoch:  233 | error:  -1.110223024625156e-15\n",
      "epoch:  234 | error:  -1.110223024625156e-15\n",
      "epoch:  235 | error:  -1.110223024625156e-15\n",
      "epoch:  236 | error:  -1.110223024625156e-15\n",
      "epoch:  237 | error:  -1.110223024625156e-15\n",
      "epoch:  238 | error:  -1.110223024625156e-15\n",
      "epoch:  239 | error:  -1.110223024625156e-15\n",
      "epoch:  240 | error:  -1.110223024625156e-15\n",
      "epoch:  241 | error:  -1.110223024625156e-15\n",
      "epoch:  242 | error:  -1.110223024625156e-15\n",
      "epoch:  243 | error:  -1.110223024625156e-15\n",
      "epoch:  244 | error:  -1.110223024625156e-15\n",
      "epoch:  245 | error:  -1.110223024625156e-15\n",
      "epoch:  246 | error:  -1.110223024625156e-15\n",
      "epoch:  247 | error:  -1.110223024625156e-15\n",
      "epoch:  248 | error:  -1.110223024625156e-15\n",
      "epoch:  249 | error:  -1.110223024625156e-15\n",
      "epoch:  250 | error:  -1.110223024625156e-15\n",
      "epoch:  251 | error:  -1.110223024625156e-15\n",
      "epoch:  252 | error:  -1.110223024625156e-15\n",
      "epoch:  253 | error:  -1.110223024625156e-15\n",
      "epoch:  254 | error:  -1.110223024625156e-15\n",
      "epoch:  255 | error:  -1.110223024625156e-15\n",
      "epoch:  256 | error:  -1.110223024625156e-15\n",
      "epoch:  257 | error:  -1.110223024625156e-15\n",
      "epoch:  258 | error:  -1.110223024625156e-15\n",
      "epoch:  259 | error:  -1.110223024625156e-15\n",
      "epoch:  260 | error:  -1.110223024625156e-15\n",
      "epoch:  261 | error:  -1.110223024625156e-15\n",
      "epoch:  262 | error:  -1.110223024625156e-15\n",
      "epoch:  263 | error:  -1.110223024625156e-15\n",
      "epoch:  264 | error:  -1.110223024625156e-15\n",
      "epoch:  265 | error:  -1.110223024625156e-15\n",
      "epoch:  266 | error:  -1.110223024625156e-15\n",
      "epoch:  267 | error:  -1.110223024625156e-15\n",
      "epoch:  268 | error:  -1.110223024625156e-15\n",
      "epoch:  269 | error:  -1.110223024625156e-15\n",
      "epoch:  270 | error:  -1.110223024625156e-15\n",
      "epoch:  271 | error:  -1.110223024625156e-15\n",
      "epoch:  272 | error:  -1.110223024625156e-15\n",
      "epoch:  273 | error:  -1.110223024625156e-15\n",
      "epoch:  274 | error:  -1.110223024625156e-15\n",
      "epoch:  275 | error:  -1.110223024625156e-15\n",
      "epoch:  276 | error:  -1.110223024625156e-15\n",
      "epoch:  277 | error:  -1.110223024625156e-15\n",
      "epoch:  278 | error:  -1.110223024625156e-15\n",
      "epoch:  279 | error:  -1.110223024625156e-15\n",
      "epoch:  280 | error:  -1.110223024625156e-15\n",
      "epoch:  281 | error:  -1.110223024625156e-15\n",
      "epoch:  282 | error:  -1.110223024625156e-15\n",
      "epoch:  283 | error:  -1.110223024625156e-15\n",
      "epoch:  284 | error:  -1.110223024625156e-15\n",
      "epoch:  285 | error:  -1.110223024625156e-15\n",
      "epoch:  286 | error:  -1.110223024625156e-15\n",
      "epoch:  287 | error:  -1.110223024625156e-15\n",
      "epoch:  288 | error:  -1.110223024625156e-15\n",
      "epoch:  289 | error:  -1.110223024625156e-15\n",
      "epoch:  290 | error:  -1.110223024625156e-15\n",
      "epoch:  291 | error:  -1.110223024625156e-15\n",
      "epoch:  292 | error:  -1.110223024625156e-15\n",
      "epoch:  293 | error:  -1.110223024625156e-15\n",
      "epoch:  294 | error:  -1.110223024625156e-15\n",
      "epoch:  295 | error:  -1.110223024625156e-15\n",
      "epoch:  296 | error:  -1.110223024625156e-15\n",
      "epoch:  297 | error:  -1.110223024625156e-15\n",
      "epoch:  298 | error:  -1.110223024625156e-15\n",
      "epoch:  299 | error:  -1.110223024625156e-15\n",
      "epoch:  300 | error:  -1.110223024625156e-15\n",
      "epoch:  301 | error:  -1.110223024625156e-15\n",
      "epoch:  302 | error:  -1.110223024625156e-15\n",
      "epoch:  303 | error:  -1.110223024625156e-15\n",
      "epoch:  304 | error:  -1.110223024625156e-15\n",
      "epoch:  305 | error:  -1.110223024625156e-15\n",
      "epoch:  306 | error:  -1.110223024625156e-15\n",
      "epoch:  307 | error:  -1.110223024625156e-15\n",
      "epoch:  308 | error:  -1.110223024625156e-15\n",
      "epoch:  309 | error:  -1.110223024625156e-15\n",
      "epoch:  310 | error:  -1.110223024625156e-15\n",
      "epoch:  311 | error:  -1.110223024625156e-15\n",
      "epoch:  312 | error:  -1.110223024625156e-15\n",
      "epoch:  313 | error:  -1.110223024625156e-15\n",
      "epoch:  314 | error:  -1.110223024625156e-15\n",
      "epoch:  315 | error:  -1.110223024625156e-15\n",
      "epoch:  316 | error:  -1.110223024625156e-15\n",
      "epoch:  317 | error:  -1.110223024625156e-15\n",
      "epoch:  318 | error:  -1.110223024625156e-15\n",
      "epoch:  319 | error:  -1.110223024625156e-15\n",
      "epoch:  320 | error:  -1.110223024625156e-15\n",
      "epoch:  321 | error:  -1.110223024625156e-15\n",
      "epoch:  322 | error:  -1.110223024625156e-15\n",
      "epoch:  323 | error:  -1.110223024625156e-15\n",
      "epoch:  324 | error:  -1.110223024625156e-15\n",
      "epoch:  325 | error:  -1.110223024625156e-15\n",
      "epoch:  326 | error:  -1.110223024625156e-15\n",
      "epoch:  327 | error:  -1.110223024625156e-15\n",
      "epoch:  328 | error:  -1.110223024625156e-15\n",
      "epoch:  329 | error:  -1.110223024625156e-15\n",
      "epoch:  330 | error:  -1.110223024625156e-15\n",
      "epoch:  331 | error:  -1.110223024625156e-15\n",
      "epoch:  332 | error:  -1.110223024625156e-15\n",
      "epoch:  333 | error:  -1.110223024625156e-15\n",
      "epoch:  334 | error:  -1.110223024625156e-15\n",
      "epoch:  335 | error:  -1.110223024625156e-15\n",
      "epoch:  336 | error:  -1.110223024625156e-15\n",
      "epoch:  337 | error:  -1.110223024625156e-15\n",
      "epoch:  338 | error:  -1.110223024625156e-15\n",
      "epoch:  339 | error:  -1.110223024625156e-15\n",
      "epoch:  340 | error:  -1.110223024625156e-15\n",
      "epoch:  341 | error:  -1.110223024625156e-15\n",
      "epoch:  342 | error:  -1.110223024625156e-15\n",
      "epoch:  343 | error:  -1.110223024625156e-15\n",
      "epoch:  344 | error:  -1.110223024625156e-15\n",
      "epoch:  345 | error:  -1.110223024625156e-15\n",
      "epoch:  346 | error:  -1.110223024625156e-15\n",
      "epoch:  347 | error:  -1.110223024625156e-15\n",
      "epoch:  348 | error:  -1.110223024625156e-15\n",
      "epoch:  349 | error:  -1.110223024625156e-15\n",
      "epoch:  350 | error:  -1.110223024625156e-15\n",
      "epoch:  351 | error:  -1.110223024625156e-15\n",
      "epoch:  352 | error:  -1.110223024625156e-15\n",
      "epoch:  353 | error:  -1.110223024625156e-15\n",
      "epoch:  354 | error:  -1.110223024625156e-15\n",
      "epoch:  355 | error:  -1.110223024625156e-15\n",
      "epoch:  356 | error:  -1.110223024625156e-15\n",
      "epoch:  357 | error:  -1.110223024625156e-15\n",
      "epoch:  358 | error:  -1.110223024625156e-15\n",
      "epoch:  359 | error:  -1.110223024625156e-15\n",
      "epoch:  360 | error:  -1.110223024625156e-15\n",
      "epoch:  361 | error:  -1.110223024625156e-15\n",
      "epoch:  362 | error:  -1.110223024625156e-15\n",
      "epoch:  363 | error:  -1.110223024625156e-15\n",
      "epoch:  364 | error:  -1.110223024625156e-15\n",
      "epoch:  365 | error:  -1.110223024625156e-15\n",
      "epoch:  366 | error:  -1.110223024625156e-15\n",
      "epoch:  367 | error:  -1.110223024625156e-15\n",
      "epoch:  368 | error:  -1.110223024625156e-15\n",
      "epoch:  369 | error:  -1.110223024625156e-15\n",
      "epoch:  370 | error:  -1.110223024625156e-15\n",
      "epoch:  371 | error:  -1.110223024625156e-15\n",
      "epoch:  372 | error:  -1.110223024625156e-15\n",
      "epoch:  373 | error:  -1.110223024625156e-15\n",
      "epoch:  374 | error:  -1.110223024625156e-15\n",
      "epoch:  375 | error:  -1.110223024625156e-15\n",
      "epoch:  376 | error:  -1.110223024625156e-15\n",
      "epoch:  377 | error:  -1.110223024625156e-15\n",
      "epoch:  378 | error:  -1.110223024625156e-15\n",
      "epoch:  379 | error:  -1.110223024625156e-15\n",
      "epoch:  380 | error:  -1.110223024625156e-15\n",
      "epoch:  381 | error:  -1.110223024625156e-15\n",
      "epoch:  382 | error:  -1.110223024625156e-15\n",
      "epoch:  383 | error:  -1.110223024625156e-15\n",
      "epoch:  384 | error:  -1.110223024625156e-15\n",
      "epoch:  385 | error:  -1.110223024625156e-15\n",
      "epoch:  386 | error:  -1.110223024625156e-15\n",
      "epoch:  387 | error:  -1.110223024625156e-15\n",
      "epoch:  388 | error:  -1.110223024625156e-15\n",
      "epoch:  389 | error:  -1.110223024625156e-15\n",
      "epoch:  390 | error:  -1.110223024625156e-15\n",
      "epoch:  391 | error:  -1.110223024625156e-15\n",
      "epoch:  392 | error:  -1.110223024625156e-15\n",
      "epoch:  393 | error:  -1.110223024625156e-15\n",
      "epoch:  394 | error:  -1.110223024625156e-15\n",
      "epoch:  395 | error:  -1.110223024625156e-15\n",
      "epoch:  396 | error:  -1.110223024625156e-15\n",
      "epoch:  397 | error:  -1.110223024625156e-15\n",
      "epoch:  398 | error:  -1.110223024625156e-15\n",
      "epoch:  399 | error:  -1.110223024625156e-15\n",
      "epoch:  400 | error:  -1.110223024625156e-15\n",
      "epoch:  401 | error:  -1.110223024625156e-15\n",
      "epoch:  402 | error:  -1.110223024625156e-15\n",
      "epoch:  403 | error:  -1.110223024625156e-15\n",
      "epoch:  404 | error:  -1.110223024625156e-15\n",
      "epoch:  405 | error:  -1.110223024625156e-15\n",
      "epoch:  406 | error:  -1.110223024625156e-15\n",
      "epoch:  407 | error:  -1.110223024625156e-15\n",
      "epoch:  408 | error:  -1.110223024625156e-15\n",
      "epoch:  409 | error:  -1.110223024625156e-15\n",
      "epoch:  410 | error:  -1.110223024625156e-15\n",
      "epoch:  411 | error:  -1.110223024625156e-15\n",
      "epoch:  412 | error:  -1.110223024625156e-15\n",
      "epoch:  413 | error:  -1.110223024625156e-15\n",
      "epoch:  414 | error:  -1.110223024625156e-15\n",
      "epoch:  415 | error:  -1.110223024625156e-15\n",
      "epoch:  416 | error:  -1.110223024625156e-15\n",
      "epoch:  417 | error:  -1.110223024625156e-15\n",
      "epoch:  418 | error:  -1.110223024625156e-15\n",
      "epoch:  419 | error:  -1.110223024625156e-15\n",
      "epoch:  420 | error:  -1.110223024625156e-15\n",
      "epoch:  421 | error:  -1.110223024625156e-15\n",
      "epoch:  422 | error:  -1.110223024625156e-15\n",
      "epoch:  423 | error:  -1.110223024625156e-15\n",
      "epoch:  424 | error:  -1.110223024625156e-15\n",
      "epoch:  425 | error:  -1.110223024625156e-15\n",
      "epoch:  426 | error:  -1.110223024625156e-15\n",
      "epoch:  427 | error:  -1.110223024625156e-15\n",
      "epoch:  428 | error:  -1.110223024625156e-15\n",
      "epoch:  429 | error:  -1.110223024625156e-15\n",
      "epoch:  430 | error:  -1.110223024625156e-15\n",
      "epoch:  431 | error:  -1.110223024625156e-15\n",
      "epoch:  432 | error:  -1.110223024625156e-15\n",
      "epoch:  433 | error:  -1.110223024625156e-15\n",
      "epoch:  434 | error:  -1.110223024625156e-15\n",
      "epoch:  435 | error:  -1.110223024625156e-15\n",
      "epoch:  436 | error:  -1.110223024625156e-15\n",
      "epoch:  437 | error:  -1.110223024625156e-15\n",
      "epoch:  438 | error:  -1.110223024625156e-15\n",
      "epoch:  439 | error:  -1.110223024625156e-15\n",
      "epoch:  440 | error:  -1.110223024625156e-15\n",
      "epoch:  441 | error:  -1.110223024625156e-15\n",
      "epoch:  442 | error:  -1.110223024625156e-15\n",
      "epoch:  443 | error:  -1.110223024625156e-15\n",
      "epoch:  444 | error:  -1.110223024625156e-15\n",
      "epoch:  445 | error:  -1.110223024625156e-15\n",
      "epoch:  446 | error:  -1.110223024625156e-15\n",
      "epoch:  447 | error:  -1.110223024625156e-15\n",
      "epoch:  448 | error:  -1.110223024625156e-15\n",
      "epoch:  449 | error:  -1.110223024625156e-15\n",
      "epoch:  450 | error:  -1.110223024625156e-15\n",
      "epoch:  451 | error:  -1.110223024625156e-15\n",
      "epoch:  452 | error:  -1.110223024625156e-15\n",
      "epoch:  453 | error:  -1.110223024625156e-15\n",
      "epoch:  454 | error:  -1.110223024625156e-15\n",
      "epoch:  455 | error:  -1.110223024625156e-15\n",
      "epoch:  456 | error:  -1.110223024625156e-15\n",
      "epoch:  457 | error:  -1.110223024625156e-15\n",
      "epoch:  458 | error:  -1.110223024625156e-15\n",
      "epoch:  459 | error:  -1.110223024625156e-15\n",
      "epoch:  460 | error:  -1.110223024625156e-15\n",
      "epoch:  461 | error:  -1.110223024625156e-15\n",
      "epoch:  462 | error:  -1.110223024625156e-15\n",
      "epoch:  463 | error:  -1.110223024625156e-15\n",
      "epoch:  464 | error:  -1.110223024625156e-15\n",
      "epoch:  465 | error:  -1.110223024625156e-15\n",
      "epoch:  466 | error:  -1.110223024625156e-15\n",
      "epoch:  467 | error:  -1.110223024625156e-15\n",
      "epoch:  468 | error:  -1.110223024625156e-15\n",
      "epoch:  469 | error:  -1.110223024625156e-15\n",
      "epoch:  470 | error:  -1.110223024625156e-15\n",
      "epoch:  471 | error:  -1.110223024625156e-15\n",
      "epoch:  472 | error:  -1.110223024625156e-15\n",
      "epoch:  473 | error:  -1.110223024625156e-15\n",
      "epoch:  474 | error:  -1.110223024625156e-15\n",
      "epoch:  475 | error:  -1.110223024625156e-15\n",
      "epoch:  476 | error:  -1.110223024625156e-15\n",
      "epoch:  477 | error:  -1.110223024625156e-15\n",
      "epoch:  478 | error:  -1.110223024625156e-15\n",
      "epoch:  479 | error:  -1.110223024625156e-15\n",
      "epoch:  480 | error:  -1.110223024625156e-15\n",
      "epoch:  481 | error:  -1.110223024625156e-15\n",
      "epoch:  482 | error:  -1.110223024625156e-15\n",
      "epoch:  483 | error:  -1.110223024625156e-15\n",
      "epoch:  484 | error:  -1.110223024625156e-15\n",
      "epoch:  485 | error:  -1.110223024625156e-15\n",
      "epoch:  486 | error:  -1.110223024625156e-15\n",
      "epoch:  487 | error:  -1.110223024625156e-15\n",
      "epoch:  488 | error:  -1.110223024625156e-15\n",
      "epoch:  489 | error:  -1.110223024625156e-15\n",
      "epoch:  490 | error:  -1.110223024625156e-15\n",
      "epoch:  491 | error:  -1.110223024625156e-15\n",
      "epoch:  492 | error:  -1.110223024625156e-15\n",
      "epoch:  493 | error:  -1.110223024625156e-15\n",
      "epoch:  494 | error:  -1.110223024625156e-15\n",
      "epoch:  495 | error:  -1.110223024625156e-15\n",
      "epoch:  496 | error:  -1.110223024625156e-15\n",
      "epoch:  497 | error:  -1.110223024625156e-15\n",
      "epoch:  498 | error:  -1.110223024625156e-15\n",
      "epoch:  499 | error:  -1.110223024625156e-15\n",
      "epoch:  500 | error:  -1.110223024625156e-15\n",
      "epoch:  501 | error:  -1.110223024625156e-15\n",
      "epoch:  502 | error:  -1.110223024625156e-15\n",
      "epoch:  503 | error:  -1.110223024625156e-15\n",
      "epoch:  504 | error:  -1.110223024625156e-15\n",
      "epoch:  505 | error:  -1.110223024625156e-15\n",
      "epoch:  506 | error:  -1.110223024625156e-15\n",
      "epoch:  507 | error:  -1.110223024625156e-15\n",
      "epoch:  508 | error:  -1.110223024625156e-15\n",
      "epoch:  509 | error:  -1.110223024625156e-15\n",
      "epoch:  510 | error:  -1.110223024625156e-15\n",
      "epoch:  511 | error:  -1.110223024625156e-15\n",
      "epoch:  512 | error:  -1.110223024625156e-15\n",
      "epoch:  513 | error:  -1.110223024625156e-15\n",
      "epoch:  514 | error:  -1.110223024625156e-15\n",
      "epoch:  515 | error:  -1.110223024625156e-15\n",
      "epoch:  516 | error:  -1.110223024625156e-15\n",
      "epoch:  517 | error:  -1.110223024625156e-15\n",
      "epoch:  518 | error:  -1.110223024625156e-15\n",
      "epoch:  519 | error:  -1.110223024625156e-15\n",
      "epoch:  520 | error:  -1.110223024625156e-15\n",
      "epoch:  521 | error:  -1.110223024625156e-15\n",
      "epoch:  522 | error:  -1.110223024625156e-15\n",
      "epoch:  523 | error:  -1.110223024625156e-15\n",
      "epoch:  524 | error:  -1.110223024625156e-15\n",
      "epoch:  525 | error:  -1.110223024625156e-15\n",
      "epoch:  526 | error:  -1.110223024625156e-15\n",
      "epoch:  527 | error:  -1.110223024625156e-15\n",
      "epoch:  528 | error:  -1.110223024625156e-15\n",
      "epoch:  529 | error:  -1.110223024625156e-15\n",
      "epoch:  530 | error:  -1.110223024625156e-15\n",
      "epoch:  531 | error:  -1.110223024625156e-15\n",
      "epoch:  532 | error:  -1.110223024625156e-15\n",
      "epoch:  533 | error:  -1.110223024625156e-15\n",
      "epoch:  534 | error:  -1.110223024625156e-15\n",
      "epoch:  535 | error:  -1.110223024625156e-15\n",
      "epoch:  536 | error:  -1.110223024625156e-15\n",
      "epoch:  537 | error:  -1.110223024625156e-15\n",
      "epoch:  538 | error:  -1.110223024625156e-15\n",
      "epoch:  539 | error:  -1.110223024625156e-15\n",
      "epoch:  540 | error:  -1.110223024625156e-15\n",
      "epoch:  541 | error:  -1.110223024625156e-15\n",
      "epoch:  542 | error:  -1.110223024625156e-15\n",
      "epoch:  543 | error:  -1.110223024625156e-15\n",
      "epoch:  544 | error:  -1.110223024625156e-15\n",
      "epoch:  545 | error:  -1.110223024625156e-15\n",
      "epoch:  546 | error:  -1.110223024625156e-15\n",
      "epoch:  547 | error:  -1.110223024625156e-15\n",
      "epoch:  548 | error:  -1.110223024625156e-15\n",
      "epoch:  549 | error:  -1.110223024625156e-15\n",
      "epoch:  550 | error:  -1.110223024625156e-15\n",
      "epoch:  551 | error:  -1.110223024625156e-15\n",
      "epoch:  552 | error:  -1.110223024625156e-15\n",
      "epoch:  553 | error:  -1.110223024625156e-15\n",
      "epoch:  554 | error:  -1.110223024625156e-15\n",
      "epoch:  555 | error:  -1.110223024625156e-15\n",
      "epoch:  556 | error:  -1.110223024625156e-15\n",
      "epoch:  557 | error:  -1.110223024625156e-15\n",
      "epoch:  558 | error:  -1.110223024625156e-15\n",
      "epoch:  559 | error:  -1.110223024625156e-15\n",
      "epoch:  560 | error:  -1.110223024625156e-15\n",
      "epoch:  561 | error:  -1.110223024625156e-15\n",
      "epoch:  562 | error:  -1.110223024625156e-15\n",
      "epoch:  563 | error:  -1.110223024625156e-15\n",
      "epoch:  564 | error:  -1.110223024625156e-15\n",
      "epoch:  565 | error:  -1.110223024625156e-15\n",
      "epoch:  566 | error:  -1.110223024625156e-15\n",
      "epoch:  567 | error:  -1.110223024625156e-15\n",
      "epoch:  568 | error:  -1.110223024625156e-15\n",
      "epoch:  569 | error:  -1.110223024625156e-15\n",
      "epoch:  570 | error:  -1.110223024625156e-15\n",
      "epoch:  571 | error:  -1.110223024625156e-15\n",
      "epoch:  572 | error:  -1.110223024625156e-15\n",
      "epoch:  573 | error:  -1.110223024625156e-15\n",
      "epoch:  574 | error:  -1.110223024625156e-15\n",
      "epoch:  575 | error:  -1.110223024625156e-15\n",
      "epoch:  576 | error:  -1.110223024625156e-15\n",
      "epoch:  577 | error:  -1.110223024625156e-15\n",
      "epoch:  578 | error:  -1.110223024625156e-15\n",
      "epoch:  579 | error:  -1.110223024625156e-15\n",
      "epoch:  580 | error:  -1.110223024625156e-15\n",
      "epoch:  581 | error:  -1.110223024625156e-15\n",
      "epoch:  582 | error:  -1.110223024625156e-15\n",
      "epoch:  583 | error:  -1.110223024625156e-15\n",
      "epoch:  584 | error:  -1.110223024625156e-15\n",
      "epoch:  585 | error:  -1.110223024625156e-15\n",
      "epoch:  586 | error:  -1.110223024625156e-15\n",
      "epoch:  587 | error:  -1.110223024625156e-15\n",
      "epoch:  588 | error:  -1.110223024625156e-15\n",
      "epoch:  589 | error:  -1.110223024625156e-15\n",
      "epoch:  590 | error:  -1.110223024625156e-15\n",
      "epoch:  591 | error:  -1.110223024625156e-15\n",
      "epoch:  592 | error:  -1.110223024625156e-15\n",
      "epoch:  593 | error:  -1.110223024625156e-15\n",
      "epoch:  594 | error:  -1.110223024625156e-15\n",
      "epoch:  595 | error:  -1.110223024625156e-15\n",
      "epoch:  596 | error:  -1.110223024625156e-15\n",
      "epoch:  597 | error:  -1.110223024625156e-15\n",
      "epoch:  598 | error:  -1.110223024625156e-15\n",
      "epoch:  599 | error:  -1.110223024625156e-15\n",
      "epoch:  600 | error:  -1.110223024625156e-15\n",
      "epoch:  601 | error:  -1.110223024625156e-15\n",
      "epoch:  602 | error:  -1.110223024625156e-15\n",
      "epoch:  603 | error:  -1.110223024625156e-15\n",
      "epoch:  604 | error:  -1.110223024625156e-15\n",
      "epoch:  605 | error:  -1.110223024625156e-15\n",
      "epoch:  606 | error:  -1.110223024625156e-15\n",
      "epoch:  607 | error:  -1.110223024625156e-15\n",
      "epoch:  608 | error:  -1.110223024625156e-15\n",
      "epoch:  609 | error:  -1.110223024625156e-15\n",
      "epoch:  610 | error:  -1.110223024625156e-15\n",
      "epoch:  611 | error:  -1.110223024625156e-15\n",
      "epoch:  612 | error:  -1.110223024625156e-15\n",
      "epoch:  613 | error:  -1.110223024625156e-15\n",
      "epoch:  614 | error:  -1.110223024625156e-15\n",
      "epoch:  615 | error:  -1.110223024625156e-15\n",
      "epoch:  616 | error:  -1.110223024625156e-15\n",
      "epoch:  617 | error:  -1.110223024625156e-15\n",
      "epoch:  618 | error:  -1.110223024625156e-15\n",
      "epoch:  619 | error:  -1.110223024625156e-15\n",
      "epoch:  620 | error:  -1.110223024625156e-15\n",
      "epoch:  621 | error:  -1.110223024625156e-15\n",
      "epoch:  622 | error:  -1.110223024625156e-15\n",
      "epoch:  623 | error:  -1.110223024625156e-15\n",
      "epoch:  624 | error:  -1.110223024625156e-15\n",
      "epoch:  625 | error:  -1.110223024625156e-15\n",
      "epoch:  626 | error:  -1.110223024625156e-15\n",
      "epoch:  627 | error:  -1.110223024625156e-15\n",
      "epoch:  628 | error:  -1.110223024625156e-15\n",
      "epoch:  629 | error:  -1.110223024625156e-15\n",
      "epoch:  630 | error:  -1.110223024625156e-15\n",
      "epoch:  631 | error:  -1.110223024625156e-15\n",
      "epoch:  632 | error:  -1.110223024625156e-15\n",
      "epoch:  633 | error:  -1.110223024625156e-15\n",
      "epoch:  634 | error:  -1.110223024625156e-15\n",
      "epoch:  635 | error:  -1.110223024625156e-15\n",
      "epoch:  636 | error:  -1.110223024625156e-15\n",
      "epoch:  637 | error:  -1.110223024625156e-15\n",
      "epoch:  638 | error:  -1.110223024625156e-15\n",
      "epoch:  639 | error:  -1.110223024625156e-15\n",
      "epoch:  640 | error:  -1.110223024625156e-15\n",
      "epoch:  641 | error:  -1.110223024625156e-15\n",
      "epoch:  642 | error:  -1.110223024625156e-15\n",
      "epoch:  643 | error:  -1.110223024625156e-15\n",
      "epoch:  644 | error:  -1.110223024625156e-15\n",
      "epoch:  645 | error:  -1.110223024625156e-15\n",
      "epoch:  646 | error:  -1.110223024625156e-15\n",
      "epoch:  647 | error:  -1.110223024625156e-15\n",
      "epoch:  648 | error:  -1.110223024625156e-15\n",
      "epoch:  649 | error:  -1.110223024625156e-15\n",
      "epoch:  650 | error:  -1.110223024625156e-15\n",
      "epoch:  651 | error:  -1.110223024625156e-15\n",
      "epoch:  652 | error:  -1.110223024625156e-15\n",
      "epoch:  653 | error:  -1.110223024625156e-15\n",
      "epoch:  654 | error:  -1.110223024625156e-15\n",
      "epoch:  655 | error:  -1.110223024625156e-15\n",
      "epoch:  656 | error:  -1.110223024625156e-15\n",
      "epoch:  657 | error:  -1.110223024625156e-15\n",
      "epoch:  658 | error:  -1.110223024625156e-15\n",
      "epoch:  659 | error:  -1.110223024625156e-15\n",
      "epoch:  660 | error:  -1.110223024625156e-15\n",
      "epoch:  661 | error:  -1.110223024625156e-15\n",
      "epoch:  662 | error:  -1.110223024625156e-15\n",
      "epoch:  663 | error:  -1.110223024625156e-15\n",
      "epoch:  664 | error:  -1.110223024625156e-15\n",
      "epoch:  665 | error:  -1.110223024625156e-15\n",
      "epoch:  666 | error:  -1.110223024625156e-15\n",
      "epoch:  667 | error:  -1.110223024625156e-15\n",
      "epoch:  668 | error:  -1.110223024625156e-15\n",
      "epoch:  669 | error:  -1.110223024625156e-15\n",
      "epoch:  670 | error:  -1.110223024625156e-15\n",
      "epoch:  671 | error:  -1.110223024625156e-15\n",
      "epoch:  672 | error:  -1.110223024625156e-15\n",
      "epoch:  673 | error:  -1.110223024625156e-15\n",
      "epoch:  674 | error:  -1.110223024625156e-15\n",
      "epoch:  675 | error:  -1.110223024625156e-15\n",
      "epoch:  676 | error:  -1.110223024625156e-15\n",
      "epoch:  677 | error:  -1.110223024625156e-15\n",
      "epoch:  678 | error:  -1.110223024625156e-15\n",
      "epoch:  679 | error:  -1.110223024625156e-15\n",
      "epoch:  680 | error:  -1.110223024625156e-15\n",
      "epoch:  681 | error:  -1.110223024625156e-15\n",
      "epoch:  682 | error:  -1.110223024625156e-15\n",
      "epoch:  683 | error:  -1.110223024625156e-15\n",
      "epoch:  684 | error:  -1.110223024625156e-15\n",
      "epoch:  685 | error:  -1.110223024625156e-15\n",
      "epoch:  686 | error:  -1.110223024625156e-15\n",
      "epoch:  687 | error:  -1.110223024625156e-15\n",
      "epoch:  688 | error:  -1.110223024625156e-15\n",
      "epoch:  689 | error:  -1.110223024625156e-15\n",
      "epoch:  690 | error:  -1.110223024625156e-15\n",
      "epoch:  691 | error:  -1.110223024625156e-15\n",
      "epoch:  692 | error:  -1.110223024625156e-15\n",
      "epoch:  693 | error:  -1.110223024625156e-15\n",
      "epoch:  694 | error:  -1.110223024625156e-15\n",
      "epoch:  695 | error:  -1.110223024625156e-15\n",
      "epoch:  696 | error:  -1.110223024625156e-15\n",
      "epoch:  697 | error:  -1.110223024625156e-15\n",
      "epoch:  698 | error:  -1.110223024625156e-15\n",
      "epoch:  699 | error:  -1.110223024625156e-15\n",
      "epoch:  700 | error:  -1.110223024625156e-15\n",
      "epoch:  701 | error:  -1.110223024625156e-15\n",
      "epoch:  702 | error:  -1.110223024625156e-15\n",
      "epoch:  703 | error:  -1.110223024625156e-15\n",
      "epoch:  704 | error:  -1.110223024625156e-15\n",
      "epoch:  705 | error:  -1.110223024625156e-15\n",
      "epoch:  706 | error:  -1.110223024625156e-15\n",
      "epoch:  707 | error:  -1.110223024625156e-15\n",
      "epoch:  708 | error:  -1.110223024625156e-15\n",
      "epoch:  709 | error:  -1.110223024625156e-15\n",
      "epoch:  710 | error:  -1.110223024625156e-15\n",
      "epoch:  711 | error:  -1.110223024625156e-15\n",
      "epoch:  712 | error:  -1.110223024625156e-15\n",
      "epoch:  713 | error:  -1.110223024625156e-15\n",
      "epoch:  714 | error:  -1.110223024625156e-15\n",
      "epoch:  715 | error:  -1.110223024625156e-15\n",
      "epoch:  716 | error:  -1.110223024625156e-15\n",
      "epoch:  717 | error:  -1.110223024625156e-15\n",
      "epoch:  718 | error:  -1.110223024625156e-15\n",
      "epoch:  719 | error:  -1.110223024625156e-15\n",
      "epoch:  720 | error:  -1.110223024625156e-15\n",
      "epoch:  721 | error:  -1.110223024625156e-15\n",
      "epoch:  722 | error:  -1.110223024625156e-15\n",
      "epoch:  723 | error:  -1.110223024625156e-15\n",
      "epoch:  724 | error:  -1.110223024625156e-15\n",
      "epoch:  725 | error:  -1.110223024625156e-15\n",
      "epoch:  726 | error:  -1.110223024625156e-15\n",
      "epoch:  727 | error:  -1.110223024625156e-15\n",
      "epoch:  728 | error:  -1.110223024625156e-15\n",
      "epoch:  729 | error:  -1.110223024625156e-15\n",
      "epoch:  730 | error:  -1.110223024625156e-15\n",
      "epoch:  731 | error:  -1.110223024625156e-15\n",
      "epoch:  732 | error:  -1.110223024625156e-15\n",
      "epoch:  733 | error:  -1.110223024625156e-15\n",
      "epoch:  734 | error:  -1.110223024625156e-15\n",
      "epoch:  735 | error:  -1.110223024625156e-15\n",
      "epoch:  736 | error:  -1.110223024625156e-15\n",
      "epoch:  737 | error:  -1.110223024625156e-15\n",
      "epoch:  738 | error:  -1.110223024625156e-15\n",
      "epoch:  739 | error:  -1.110223024625156e-15\n",
      "epoch:  740 | error:  -1.110223024625156e-15\n",
      "epoch:  741 | error:  -1.110223024625156e-15\n",
      "epoch:  742 | error:  -1.110223024625156e-15\n",
      "epoch:  743 | error:  -1.110223024625156e-15\n",
      "epoch:  744 | error:  -1.110223024625156e-15\n",
      "epoch:  745 | error:  -1.110223024625156e-15\n",
      "epoch:  746 | error:  -1.110223024625156e-15\n",
      "epoch:  747 | error:  -1.110223024625156e-15\n",
      "epoch:  748 | error:  -1.110223024625156e-15\n",
      "epoch:  749 | error:  -1.110223024625156e-15\n",
      "epoch:  750 | error:  -1.110223024625156e-15\n",
      "epoch:  751 | error:  -1.110223024625156e-15\n",
      "epoch:  752 | error:  -1.110223024625156e-15\n",
      "epoch:  753 | error:  -1.110223024625156e-15\n",
      "epoch:  754 | error:  -1.110223024625156e-15\n",
      "epoch:  755 | error:  -1.110223024625156e-15\n",
      "epoch:  756 | error:  -1.110223024625156e-15\n",
      "epoch:  757 | error:  -1.110223024625156e-15\n",
      "epoch:  758 | error:  -1.110223024625156e-15\n",
      "epoch:  759 | error:  -1.110223024625156e-15\n",
      "epoch:  760 | error:  -1.110223024625156e-15\n",
      "epoch:  761 | error:  -1.110223024625156e-15\n",
      "epoch:  762 | error:  -1.110223024625156e-15\n",
      "epoch:  763 | error:  -1.110223024625156e-15\n",
      "epoch:  764 | error:  -1.110223024625156e-15\n",
      "epoch:  765 | error:  -1.110223024625156e-15\n",
      "epoch:  766 | error:  -1.110223024625156e-15\n",
      "epoch:  767 | error:  -1.110223024625156e-15\n",
      "epoch:  768 | error:  -1.110223024625156e-15\n",
      "epoch:  769 | error:  -1.110223024625156e-15\n",
      "epoch:  770 | error:  -1.110223024625156e-15\n",
      "epoch:  771 | error:  -1.110223024625156e-15\n",
      "epoch:  772 | error:  -1.110223024625156e-15\n",
      "epoch:  773 | error:  -1.110223024625156e-15\n",
      "epoch:  774 | error:  -1.110223024625156e-15\n",
      "epoch:  775 | error:  -1.110223024625156e-15\n",
      "epoch:  776 | error:  -1.110223024625156e-15\n",
      "epoch:  777 | error:  -1.110223024625156e-15\n",
      "epoch:  778 | error:  -1.110223024625156e-15\n",
      "epoch:  779 | error:  -1.110223024625156e-15\n",
      "epoch:  780 | error:  -1.110223024625156e-15\n",
      "epoch:  781 | error:  -1.110223024625156e-15\n",
      "epoch:  782 | error:  -1.110223024625156e-15\n",
      "epoch:  783 | error:  -1.110223024625156e-15\n",
      "epoch:  784 | error:  -1.110223024625156e-15\n",
      "epoch:  785 | error:  -1.110223024625156e-15\n",
      "epoch:  786 | error:  -1.110223024625156e-15\n",
      "epoch:  787 | error:  -1.110223024625156e-15\n",
      "epoch:  788 | error:  -1.110223024625156e-15\n",
      "epoch:  789 | error:  -1.110223024625156e-15\n",
      "epoch:  790 | error:  -1.110223024625156e-15\n",
      "epoch:  791 | error:  -1.110223024625156e-15\n",
      "epoch:  792 | error:  -1.110223024625156e-15\n",
      "epoch:  793 | error:  -1.110223024625156e-15\n",
      "epoch:  794 | error:  -1.110223024625156e-15\n",
      "epoch:  795 | error:  -1.110223024625156e-15\n",
      "epoch:  796 | error:  -1.110223024625156e-15\n",
      "epoch:  797 | error:  -1.110223024625156e-15\n",
      "epoch:  798 | error:  -1.110223024625156e-15\n",
      "epoch:  799 | error:  -1.110223024625156e-15\n",
      "epoch:  800 | error:  -1.110223024625156e-15\n",
      "epoch:  801 | error:  -1.110223024625156e-15\n",
      "epoch:  802 | error:  -1.110223024625156e-15\n",
      "epoch:  803 | error:  -1.110223024625156e-15\n",
      "epoch:  804 | error:  -1.110223024625156e-15\n",
      "epoch:  805 | error:  -1.110223024625156e-15\n",
      "epoch:  806 | error:  -1.110223024625156e-15\n",
      "epoch:  807 | error:  -1.110223024625156e-15\n",
      "epoch:  808 | error:  -1.110223024625156e-15\n",
      "epoch:  809 | error:  -1.110223024625156e-15\n",
      "epoch:  810 | error:  -1.110223024625156e-15\n",
      "epoch:  811 | error:  -1.110223024625156e-15\n",
      "epoch:  812 | error:  -1.110223024625156e-15\n",
      "epoch:  813 | error:  -1.110223024625156e-15\n",
      "epoch:  814 | error:  -1.110223024625156e-15\n",
      "epoch:  815 | error:  -1.110223024625156e-15\n",
      "epoch:  816 | error:  -1.110223024625156e-15\n",
      "epoch:  817 | error:  -1.110223024625156e-15\n",
      "epoch:  818 | error:  -1.110223024625156e-15\n",
      "epoch:  819 | error:  -1.110223024625156e-15\n",
      "epoch:  820 | error:  -1.110223024625156e-15\n",
      "epoch:  821 | error:  -1.110223024625156e-15\n",
      "epoch:  822 | error:  -1.110223024625156e-15\n",
      "epoch:  823 | error:  -1.110223024625156e-15\n",
      "epoch:  824 | error:  -1.110223024625156e-15\n",
      "epoch:  825 | error:  -1.110223024625156e-15\n",
      "epoch:  826 | error:  -1.110223024625156e-15\n",
      "epoch:  827 | error:  -1.110223024625156e-15\n",
      "epoch:  828 | error:  -1.110223024625156e-15\n",
      "epoch:  829 | error:  -1.110223024625156e-15\n",
      "epoch:  830 | error:  -1.110223024625156e-15\n",
      "epoch:  831 | error:  -1.110223024625156e-15\n",
      "epoch:  832 | error:  -1.110223024625156e-15\n",
      "epoch:  833 | error:  -1.110223024625156e-15\n",
      "epoch:  834 | error:  -1.110223024625156e-15\n",
      "epoch:  835 | error:  -1.110223024625156e-15\n",
      "epoch:  836 | error:  -1.110223024625156e-15\n",
      "epoch:  837 | error:  -1.110223024625156e-15\n",
      "epoch:  838 | error:  -1.110223024625156e-15\n",
      "epoch:  839 | error:  -1.110223024625156e-15\n",
      "epoch:  840 | error:  -1.110223024625156e-15\n",
      "epoch:  841 | error:  -1.110223024625156e-15\n",
      "epoch:  842 | error:  -1.110223024625156e-15\n",
      "epoch:  843 | error:  -1.110223024625156e-15\n",
      "epoch:  844 | error:  -1.110223024625156e-15\n",
      "epoch:  845 | error:  -1.110223024625156e-15\n",
      "epoch:  846 | error:  -1.110223024625156e-15\n",
      "epoch:  847 | error:  -1.110223024625156e-15\n",
      "epoch:  848 | error:  -1.110223024625156e-15\n",
      "epoch:  849 | error:  -1.110223024625156e-15\n",
      "epoch:  850 | error:  -1.110223024625156e-15\n",
      "epoch:  851 | error:  -1.110223024625156e-15\n",
      "epoch:  852 | error:  -1.110223024625156e-15\n",
      "epoch:  853 | error:  -1.110223024625156e-15\n",
      "epoch:  854 | error:  -1.110223024625156e-15\n",
      "epoch:  855 | error:  -1.110223024625156e-15\n",
      "epoch:  856 | error:  -1.110223024625156e-15\n",
      "epoch:  857 | error:  -1.110223024625156e-15\n",
      "epoch:  858 | error:  -1.110223024625156e-15\n",
      "epoch:  859 | error:  -1.110223024625156e-15\n",
      "epoch:  860 | error:  -1.110223024625156e-15\n",
      "epoch:  861 | error:  -1.110223024625156e-15\n",
      "epoch:  862 | error:  -1.110223024625156e-15\n",
      "epoch:  863 | error:  -1.110223024625156e-15\n",
      "epoch:  864 | error:  -1.110223024625156e-15\n",
      "epoch:  865 | error:  -1.110223024625156e-15\n",
      "epoch:  866 | error:  -1.110223024625156e-15\n",
      "epoch:  867 | error:  -1.110223024625156e-15\n",
      "epoch:  868 | error:  -1.110223024625156e-15\n",
      "epoch:  869 | error:  -1.110223024625156e-15\n",
      "epoch:  870 | error:  -1.110223024625156e-15\n",
      "epoch:  871 | error:  -1.110223024625156e-15\n",
      "epoch:  872 | error:  -1.110223024625156e-15\n",
      "epoch:  873 | error:  -1.110223024625156e-15\n",
      "epoch:  874 | error:  -1.110223024625156e-15\n",
      "epoch:  875 | error:  -1.110223024625156e-15\n",
      "epoch:  876 | error:  -1.110223024625156e-15\n",
      "epoch:  877 | error:  -1.110223024625156e-15\n",
      "epoch:  878 | error:  -1.110223024625156e-15\n",
      "epoch:  879 | error:  -1.110223024625156e-15\n",
      "epoch:  880 | error:  -1.110223024625156e-15\n",
      "epoch:  881 | error:  -1.110223024625156e-15\n",
      "epoch:  882 | error:  -1.110223024625156e-15\n",
      "epoch:  883 | error:  -1.110223024625156e-15\n",
      "epoch:  884 | error:  -1.110223024625156e-15\n",
      "epoch:  885 | error:  -1.110223024625156e-15\n",
      "epoch:  886 | error:  -1.110223024625156e-15\n",
      "epoch:  887 | error:  -1.110223024625156e-15\n",
      "epoch:  888 | error:  -1.110223024625156e-15\n",
      "epoch:  889 | error:  -1.110223024625156e-15\n",
      "epoch:  890 | error:  -1.110223024625156e-15\n",
      "epoch:  891 | error:  -1.110223024625156e-15\n",
      "epoch:  892 | error:  -1.110223024625156e-15\n",
      "epoch:  893 | error:  -1.110223024625156e-15\n",
      "epoch:  894 | error:  -1.110223024625156e-15\n",
      "epoch:  895 | error:  -1.110223024625156e-15\n",
      "epoch:  896 | error:  -1.110223024625156e-15\n",
      "epoch:  897 | error:  -1.110223024625156e-15\n",
      "epoch:  898 | error:  -1.110223024625156e-15\n",
      "epoch:  899 | error:  -1.110223024625156e-15\n",
      "epoch:  900 | error:  -1.110223024625156e-15\n",
      "epoch:  901 | error:  -1.110223024625156e-15\n",
      "epoch:  902 | error:  -1.110223024625156e-15\n",
      "epoch:  903 | error:  -1.110223024625156e-15\n",
      "epoch:  904 | error:  -1.110223024625156e-15\n",
      "epoch:  905 | error:  -1.110223024625156e-15\n",
      "epoch:  906 | error:  -1.110223024625156e-15\n",
      "epoch:  907 | error:  -1.110223024625156e-15\n",
      "epoch:  908 | error:  -1.110223024625156e-15\n",
      "epoch:  909 | error:  -1.110223024625156e-15\n",
      "epoch:  910 | error:  -1.110223024625156e-15\n",
      "epoch:  911 | error:  -1.110223024625156e-15\n",
      "epoch:  912 | error:  -1.110223024625156e-15\n",
      "epoch:  913 | error:  -1.110223024625156e-15\n",
      "epoch:  914 | error:  -1.110223024625156e-15\n",
      "epoch:  915 | error:  -1.110223024625156e-15\n",
      "epoch:  916 | error:  -1.110223024625156e-15\n",
      "epoch:  917 | error:  -1.110223024625156e-15\n",
      "epoch:  918 | error:  -1.110223024625156e-15\n",
      "epoch:  919 | error:  -1.110223024625156e-15\n",
      "epoch:  920 | error:  -1.110223024625156e-15\n",
      "epoch:  921 | error:  -1.110223024625156e-15\n",
      "epoch:  922 | error:  -1.110223024625156e-15\n",
      "epoch:  923 | error:  -1.110223024625156e-15\n",
      "epoch:  924 | error:  -1.110223024625156e-15\n",
      "epoch:  925 | error:  -1.110223024625156e-15\n",
      "epoch:  926 | error:  -1.110223024625156e-15\n",
      "epoch:  927 | error:  -1.110223024625156e-15\n",
      "epoch:  928 | error:  -1.110223024625156e-15\n",
      "epoch:  929 | error:  -1.110223024625156e-15\n",
      "epoch:  930 | error:  -1.110223024625156e-15\n",
      "epoch:  931 | error:  -1.110223024625156e-15\n",
      "epoch:  932 | error:  -1.110223024625156e-15\n",
      "epoch:  933 | error:  -1.110223024625156e-15\n",
      "epoch:  934 | error:  -1.110223024625156e-15\n",
      "epoch:  935 | error:  -1.110223024625156e-15\n",
      "epoch:  936 | error:  -1.110223024625156e-15\n",
      "epoch:  937 | error:  -1.110223024625156e-15\n",
      "epoch:  938 | error:  -1.110223024625156e-15\n",
      "epoch:  939 | error:  -1.110223024625156e-15\n",
      "epoch:  940 | error:  -1.110223024625156e-15\n",
      "epoch:  941 | error:  -1.110223024625156e-15\n",
      "epoch:  942 | error:  -1.110223024625156e-15\n",
      "epoch:  943 | error:  -1.110223024625156e-15\n",
      "epoch:  944 | error:  -1.110223024625156e-15\n",
      "epoch:  945 | error:  -1.110223024625156e-15\n",
      "epoch:  946 | error:  -1.110223024625156e-15\n",
      "epoch:  947 | error:  -1.110223024625156e-15\n",
      "epoch:  948 | error:  -1.110223024625156e-15\n",
      "epoch:  949 | error:  -1.110223024625156e-15\n",
      "epoch:  950 | error:  -1.110223024625156e-15\n",
      "epoch:  951 | error:  -1.110223024625156e-15\n",
      "epoch:  952 | error:  -1.110223024625156e-15\n",
      "epoch:  953 | error:  -1.110223024625156e-15\n",
      "epoch:  954 | error:  -1.110223024625156e-15\n",
      "epoch:  955 | error:  -1.110223024625156e-15\n",
      "epoch:  956 | error:  -1.110223024625156e-15\n",
      "epoch:  957 | error:  -1.110223024625156e-15\n",
      "epoch:  958 | error:  -1.110223024625156e-15\n",
      "epoch:  959 | error:  -1.110223024625156e-15\n",
      "epoch:  960 | error:  -1.110223024625156e-15\n",
      "epoch:  961 | error:  -1.110223024625156e-15\n",
      "epoch:  962 | error:  -1.110223024625156e-15\n",
      "epoch:  963 | error:  -1.110223024625156e-15\n",
      "epoch:  964 | error:  -1.110223024625156e-15\n",
      "epoch:  965 | error:  -1.110223024625156e-15\n",
      "epoch:  966 | error:  -1.110223024625156e-15\n",
      "epoch:  967 | error:  -1.110223024625156e-15\n",
      "epoch:  968 | error:  -1.110223024625156e-15\n",
      "epoch:  969 | error:  -1.110223024625156e-15\n",
      "epoch:  970 | error:  -1.110223024625156e-15\n",
      "epoch:  971 | error:  -1.110223024625156e-15\n",
      "epoch:  972 | error:  -1.110223024625156e-15\n",
      "epoch:  973 | error:  -1.110223024625156e-15\n",
      "epoch:  974 | error:  -1.110223024625156e-15\n",
      "epoch:  975 | error:  -1.110223024625156e-15\n",
      "epoch:  976 | error:  -1.110223024625156e-15\n",
      "epoch:  977 | error:  -1.110223024625156e-15\n",
      "epoch:  978 | error:  -1.110223024625156e-15\n",
      "epoch:  979 | error:  -1.110223024625156e-15\n",
      "epoch:  980 | error:  -1.110223024625156e-15\n",
      "epoch:  981 | error:  -1.110223024625156e-15\n",
      "epoch:  982 | error:  -1.110223024625156e-15\n",
      "epoch:  983 | error:  -1.110223024625156e-15\n",
      "epoch:  984 | error:  -1.110223024625156e-15\n",
      "epoch:  985 | error:  -1.110223024625156e-15\n",
      "epoch:  986 | error:  -1.110223024625156e-15\n",
      "epoch:  987 | error:  -1.110223024625156e-15\n",
      "epoch:  988 | error:  -1.110223024625156e-15\n",
      "epoch:  989 | error:  -1.110223024625156e-15\n",
      "epoch:  990 | error:  -1.110223024625156e-15\n",
      "epoch:  991 | error:  -1.110223024625156e-15\n",
      "epoch:  992 | error:  -1.110223024625156e-15\n",
      "epoch:  993 | error:  -1.110223024625156e-15\n",
      "epoch:  994 | error:  -1.110223024625156e-15\n",
      "epoch:  995 | error:  -1.110223024625156e-15\n",
      "epoch:  996 | error:  -1.110223024625156e-15\n",
      "epoch:  997 | error:  -1.110223024625156e-15\n",
      "epoch:  998 | error:  -1.110223024625156e-15\n",
      "epoch:  999 | error:  -1.110223024625156e-15\n"
     ]
    }
   ],
   "source": [
    "# implementing Batch GD with early stopping for Softmax regression\n",
    "\n",
    "# 4 features - sepal length, sepal width, petal length, petal width\n",
    "# classes - 0,1,2 --> iris setosa, iris versicolor, iris verginica\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = iris[\"data\"] \n",
    "y = iris[\"target\"]\n",
    "for epoch in range(len(X)):\n",
    "    pass\n",
    "\n",
    "np.unique(y)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = encoder.fit_transform(y.reshape(-1, 1))\n",
    "classes = np.unique(y_onehot) # all available classes\n",
    "# not acutall probability\n",
    "# for k in classes:\n",
    "k = classes[0]\n",
    "\n",
    "class_instances = X[(y == k)]\n",
    "best_weight = 0\n",
    "weight = np.random.random((1, 4))  # random intial weights\n",
    "# dot karne ke lie shape should be same\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "errors = []\n",
    "weights = []\n",
    "for epoch in range(1000):\n",
    "    softmax_scores = X.dot(weight.T)\n",
    "    softmax_scores_exp = np.exp(softmax_scores)\n",
    "    total = np.sum(softmax_scores_exp, axis=1, keepdims=True)  # sum across classes for each sample\n",
    "    probabilty_ = softmax_scores_exp / total\n",
    "    \n",
    "    # now lets find best weight for each class\n",
    "    yi = np.array([1 if label == k else 0 for label in y]).reshape(-1, 1)\n",
    "\n",
    "    gradient = -1 / len(X) * (yi - probabilty_).T.dot(X)  # shape (1, 4)\n",
    "\n",
    "    \n",
    "    eps = 1e-15\n",
    "    error = -np.mean(np.sum(y_onehot * np.log(probabilty_ + eps), axis=1))\n",
    "\n",
    "    errors.append(error)\n",
    "    weights.append(weight)\n",
    "    weight = weight - (alpha * gradient)\n",
    "    \n",
    "    # print(weight)\n",
    "    \n",
    "    print(\"epoch: \", epoch, \"|\", \"error: \", error)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ec1c839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457),\n",
       " np.float64(23.025850929940457)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "58ff0ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150, 5)\n",
      "Number of classes: 3\n",
      "Starting training...\n",
      "--------------------------------------------------\n",
      "Epoch    1 | Loss: 1.131609 | Accuracy: 0.3333\n",
      "Epoch  100 | Loss: 0.713707 | Accuracy: 0.6800\n",
      "Epoch  200 | Loss: 0.584332 | Accuracy: 0.7867\n",
      "Epoch  300 | Loss: 0.519719 | Accuracy: 0.8667\n",
      "Epoch  400 | Loss: 0.478383 | Accuracy: 0.9067\n",
      "Epoch  500 | Loss: 0.448083 | Accuracy: 0.9267\n",
      "Epoch  600 | Loss: 0.424036 | Accuracy: 0.9400\n",
      "Epoch  700 | Loss: 0.403990 | Accuracy: 0.9600\n",
      "Epoch  800 | Loss: 0.386734 | Accuracy: 0.9667\n",
      "Epoch  900 | Loss: 0.371555 | Accuracy: 0.9667\n",
      "Epoch 1000 | Loss: 0.357997 | Accuracy: 0.9667\n",
      "--------------------------------------------------\n",
      "Training completed!\n",
      "\n",
      "Final Results:\n",
      "Final Loss: 0.357997\n",
      "Final Accuracy: 0.9667\n",
      "\n",
      "Learned Weights (including bias):\n",
      "Class 0: [ 0.17308915  0.31599364  0.84142559 -1.19433931 -0.55708465]\n",
      "Class 1: [ 0.08143883  0.18379198 -0.27173557  0.17947838 -0.16933877]\n",
      "Class 2: [-0.25653638 -0.49003343 -0.55311917  1.00626368  0.7122583 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions (first 10 samples):\n",
      "True labels: [0 0 0 0 0 0 0 0 0 0]\n",
      "Predictions: [0 0 0 0 0 0 0 0 0 0]\n",
      "Probabilities for first sample:\n",
      "  Class 0: 0.9327\n",
      "  Class 1: 0.0652\n",
      "  Class 2: 0.0021\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris[\"data\"]\n",
    "y = iris[\"target\"]\n",
    "\n",
    "# Add bias term (intercept)\n",
    "X = np.c_[np.ones(X.shape[0]), X]  # Add column of ones for bias\n",
    "n_samples, n_features = X.shape\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "\n",
    "# Initialize weights for all classes (each row represents weights for one class)\n",
    "np.random.seed(42)  # for reproducibility\n",
    "W = np.random.normal(0, 0.01, (n_classes, n_features))\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "def to_one_hot(y, n_classes):\n",
    "    one_hot = np.zeros((len(y), n_classes))\n",
    "    one_hot[np.arange(len(y)), y] = 1\n",
    "    return one_hot\n",
    "\n",
    "Y_one_hot = to_one_hot(y, n_classes)\n",
    "\n",
    "# Softmax function\n",
    "def softmax(z):\n",
    "    # Subtract max for numerical stability\n",
    "    z_stable = z - np.max(z, axis=1, keepdims=True)\n",
    "    exp_z = np.exp(z_stable)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "# Cross-entropy loss\n",
    "def cross_entropy_loss(Y_true, Y_pred):\n",
    "    # Add small epsilon to prevent log(0)\n",
    "    epsilon = 1e-15\n",
    "    Y_pred = np.clip(Y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.mean(np.sum(Y_true * np.log(Y_pred), axis=1))\n",
    "\n",
    "# Gradient descent parameters\n",
    "learning_rate = 0.01\n",
    "n_epochs = 1000\n",
    "\n",
    "# Lists to store metrics\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward pass\n",
    "    z = X.dot(W.T)  # Shape: (n_samples, n_classes)\n",
    "    probabilities = softmax(z)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = cross_entropy_loss(Y_one_hot, probabilities)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    predictions = np.argmax(probabilities, axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    # Calculate gradient\n",
    "    gradient = (1/n_samples) * X.T.dot(probabilities - Y_one_hot)  # Shape: (n_features, n_classes)\n",
    "    \n",
    "    # Update weights\n",
    "    W = W - learning_rate * gradient.T  # Transpose to match W shape\n",
    "    \n",
    "    # Print progress every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1:4d} | Loss: {loss:.6f} | Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Final evaluation\n",
    "final_z = X.dot(W.T)\n",
    "final_probabilities = softmax(final_z)\n",
    "final_predictions = np.argmax(final_probabilities, axis=1)\n",
    "final_accuracy = np.mean(final_predictions == y)\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Final Loss: {losses[-1]:.6f}\")\n",
    "print(f\"Final Accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "# Print learned weights\n",
    "print(f\"\\nLearned Weights (including bias):\")\n",
    "for i in range(n_classes):\n",
    "    print(f\"Class {i}: {W[i]}\")\n",
    "\n",
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss curve\n",
    "ax1.plot(losses)\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Cross-Entropy Loss')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy curve\n",
    "ax2.plot(accuracies)\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some sample predictions\n",
    "print(f\"\\nSample Predictions (first 10 samples):\")\n",
    "print(\"True labels:\", y[:10])\n",
    "print(\"Predictions:\", final_predictions[:10])\n",
    "print(\"Probabilities for first sample:\")\n",
    "for i, prob in enumerate(final_probabilities[0]):\n",
    "    print(f\"  Class {i}: {prob:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
