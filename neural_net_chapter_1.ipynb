{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79230eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df2f4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashon_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2243740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashon_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d455d0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2250e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e66589db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additionally, since we are going to train the neural network using Gradient Descent, we must scale the input features\n",
    "\n",
    "## we’ll scale the pixel intensities down to the 0–1 range by dividing them by 255.0 (this also converts them to floats)\n",
    "\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255, X_train_full[5000:] / 255\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                   \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e9a8bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shirt'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[1234]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f28b7bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshavsharma/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Now let’s build the neural network! Here is a classification MLP with two hidden layers:\n",
    "\n",
    "# MLP --> Multi layer Percepton\n",
    "\n",
    "model = keras.models.Sequential() # keras Sequential API\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # input layer,  It is a Flatten layer whose role is to convert each input image into a 1D array:\n",
    "# model.add(keras.layers.InputLayer(input_shape=[28,28]))  can also use it for input layer\n",
    "\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # hidden layer 300 neuron \n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # hidden layer  100 neuron\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # output layer, after softmax applied to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "46d5b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "]) # better way of doing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "156a3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.name = \"Keshav Sharma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7f84e347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Keshav Sharma\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Keshav Sharma\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87d09c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Flatten name=flatten_3, built=True>,\n",
       " <Dense name=dense_11, built=True>,\n",
       " <Dense name=dense_12, built=True>,\n",
       " <Dense name=dense_13, built=True>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "981bbf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_11'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7a509d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "29ffeb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3185b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (kernel is another name for the matrix of connection\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# If instead we had one target probability per class for each instance (such as one-hot vectors, e.g. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would need to use the \"categorical_crossentropy\" loss instead.\n",
    "\n",
    "# If we were doing binary classification (with one or more binary labels), then we would use the \"sigmoid\" (i.e., logistic) activation function in the output layer instead of the \"softmax\" activation function, and we would use the \"binary_crossentropy\" loss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14515e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'Keshav Sharma' is not a valid root scope name. A root scope name has to match the following pattern: ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# training the model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: 'Keshav Sharma' is not a valid root scope name. A root scope name has to match the following pattern: ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257256e6",
   "metadata": {},
   "source": [
    "Instead of passing a validation set using the validation_data argument, you could set validation_split to the ratio of the training set that you want Keras to use for validation. For example, validation_split=0.1 tells Keras to use the last 10% of the data (before shuffling) for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b5e9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 'auto', 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c3f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106955b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.7612545490264893,\n",
       "  0.8295817971229553,\n",
       "  0.8435817956924438,\n",
       "  0.8547818064689636,\n",
       "  0.859854519367218,\n",
       "  0.8658545613288879,\n",
       "  0.8702727556228638,\n",
       "  0.8723636269569397,\n",
       "  0.876945436000824,\n",
       "  0.8802363872528076,\n",
       "  0.8837817907333374,\n",
       "  0.8855090737342834,\n",
       "  0.8885999917984009,\n",
       "  0.8903999924659729,\n",
       "  0.8934545516967773,\n",
       "  0.8953272700309753,\n",
       "  0.8961636424064636,\n",
       "  0.8991090655326843,\n",
       "  0.9004908800125122,\n",
       "  0.9028545618057251,\n",
       "  0.9042181968688965,\n",
       "  0.9057818055152893,\n",
       "  0.9070363640785217,\n",
       "  0.9102363586425781,\n",
       "  0.9107818007469177,\n",
       "  0.9109636545181274,\n",
       "  0.91356360912323,\n",
       "  0.916345477104187,\n",
       "  0.9174000024795532,\n",
       "  0.9171817898750305],\n",
       " 'loss': [0.7181106805801392,\n",
       "  0.4887324273586273,\n",
       "  0.44380155205726624,\n",
       "  0.4158899188041687,\n",
       "  0.3959178030490875,\n",
       "  0.3790874779224396,\n",
       "  0.3661527931690216,\n",
       "  0.35416123270988464,\n",
       "  0.3442692160606384,\n",
       "  0.33388322591781616,\n",
       "  0.32575860619544983,\n",
       "  0.3180176913738251,\n",
       "  0.3105897307395935,\n",
       "  0.30396968126296997,\n",
       "  0.29673418402671814,\n",
       "  0.2914596498012543,\n",
       "  0.2862705588340759,\n",
       "  0.2803114652633667,\n",
       "  0.2759174704551697,\n",
       "  0.2708044648170471,\n",
       "  0.266446977853775,\n",
       "  0.26166123151779175,\n",
       "  0.25642791390419006,\n",
       "  0.25235116481781006,\n",
       "  0.24819797277450562,\n",
       "  0.2445383369922638,\n",
       "  0.24013692140579224,\n",
       "  0.23602768778800964,\n",
       "  0.23167215287685394,\n",
       "  0.22826771438121796],\n",
       " 'val_accuracy': [0.7853999733924866,\n",
       "  0.8515999913215637,\n",
       "  0.852400004863739,\n",
       "  0.8593999743461609,\n",
       "  0.8682000041007996,\n",
       "  0.8679999709129333,\n",
       "  0.8694000244140625,\n",
       "  0.8748000264167786,\n",
       "  0.8809999823570251,\n",
       "  0.8744000196456909,\n",
       "  0.8740000128746033,\n",
       "  0.8723999857902527,\n",
       "  0.883400022983551,\n",
       "  0.8812000155448914,\n",
       "  0.8873999714851379,\n",
       "  0.8804000020027161,\n",
       "  0.8885999917984009,\n",
       "  0.8781999945640564,\n",
       "  0.8920000195503235,\n",
       "  0.8895999789237976,\n",
       "  0.8903999924659729,\n",
       "  0.8894000053405762,\n",
       "  0.8859999775886536,\n",
       "  0.8870000243186951,\n",
       "  0.8902000188827515,\n",
       "  0.890999972820282,\n",
       "  0.8907999992370605,\n",
       "  0.8916000127792358,\n",
       "  0.8888000249862671,\n",
       "  0.8934000134468079],\n",
       " 'val_loss': [0.5734629034996033,\n",
       "  0.4373597204685211,\n",
       "  0.4355165660381317,\n",
       "  0.3996412754058838,\n",
       "  0.384395569562912,\n",
       "  0.3772652745246887,\n",
       "  0.37103763222694397,\n",
       "  0.3557226061820984,\n",
       "  0.34245774149894714,\n",
       "  0.36077091097831726,\n",
       "  0.35117337107658386,\n",
       "  0.35548895597457886,\n",
       "  0.32974380254745483,\n",
       "  0.3253106474876404,\n",
       "  0.32744139432907104,\n",
       "  0.33984583616256714,\n",
       "  0.31441664695739746,\n",
       "  0.333504855632782,\n",
       "  0.31297388672828674,\n",
       "  0.30680692195892334,\n",
       "  0.307265967130661,\n",
       "  0.3088285028934479,\n",
       "  0.3122461140155792,\n",
       "  0.3095117509365082,\n",
       "  0.30996185541152954,\n",
       "  0.2994612157344818,\n",
       "  0.30608442425727844,\n",
       "  0.29960212111473083,\n",
       "  0.31061041355133057,\n",
       "  0.2925584316253662]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d38cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1] plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2294 - val_accuracy: 0.8932 - val_loss: 0.2979\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2179 - val_accuracy: 0.8902 - val_loss: 0.3020\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.2182 - val_accuracy: 0.8972 - val_loss: 0.2873\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9228 - loss: 0.2135 - val_accuracy: 0.8936 - val_loss: 0.2920\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.2092 - val_accuracy: 0.8936 - val_loss: 0.2922\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2050 - val_accuracy: 0.8930 - val_loss: 0.2994\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2055 - val_accuracy: 0.8962 - val_loss: 0.3015\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.2021 - val_accuracy: 0.8924 - val_loss: 0.2938\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.1988 - val_accuracy: 0.8922 - val_loss: 0.3059\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.1927 - val_accuracy: 0.8946 - val_loss: 0.2885\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.1966 - val_accuracy: 0.8938 - val_loss: 0.2934\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.1866 - val_accuracy: 0.8874 - val_loss: 0.3012\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.1820 - val_accuracy: 0.8952 - val_loss: 0.2893\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.1795 - val_accuracy: 0.8960 - val_loss: 0.2923\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1814 - val_accuracy: 0.8940 - val_loss: 0.2993\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.1738 - val_accuracy: 0.8934 - val_loss: 0.2951\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.1739 - val_accuracy: 0.8954 - val_loss: 0.2940\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.1707 - val_accuracy: 0.8838 - val_loss: 0.3267\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.1698 - val_accuracy: 0.8886 - val_loss: 0.3166\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.1661 - val_accuracy: 0.8994 - val_loss: 0.2859\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.1618 - val_accuracy: 0.8944 - val_loss: 0.2985\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.1595 - val_accuracy: 0.8924 - val_loss: 0.3105\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1547 - val_accuracy: 0.8896 - val_loss: 0.3101\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.1531 - val_accuracy: 0.8942 - val_loss: 0.3077\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.1516 - val_accuracy: 0.8916 - val_loss: 0.2985\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1502 - val_accuracy: 0.8926 - val_loss: 0.3149\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1459 - val_accuracy: 0.8914 - val_loss: 0.3019\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9491 - loss: 0.1435 - val_accuracy: 0.8964 - val_loss: 0.2959\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1440 - val_accuracy: 0.8890 - val_loss: 0.3205\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.1405 - val_accuracy: 0.8974 - val_loss: 0.2964\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid)) # continues from where it left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8d06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8587 - loss: 67.1447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[69.48444366455078, 0.8567000031471252]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## evaludating the model on test set\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54daadba",
   "metadata": {},
   "source": [
    "Remember to resist the temptation to tweak the hyperparameters on the test set, or else your estimate of the generalization error will be too optimistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea25b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.09, 0.  , 0.49, 0.  , 0.41, 0.  , 0.  , 0.  ],\n",
       "       [0.9 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.96, 0.  , 0.04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting\n",
    "X_new = X_train[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d7bd8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Regression MLP Using the Sequential API\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "acef3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test,  y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "         X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dab1f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b1aac3",
   "metadata": {},
   "source": [
    "The main differences are the fact that the output layer has a single neuron (since we only want to predict a sin‐ gle value) and uses no activation function, and the loss function is the mean squared error. Since the dataset is quite noisy, we just use a single hidden layer with fewer neurons than before, to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "10df9aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m  1/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 126ms/step - loss: 6.3825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshavsharma/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 1.3952 - val_loss: 0.9857\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 0.7117 - val_loss: 0.5198\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.5229 - val_loss: 0.4807\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.5015 - val_loss: 0.4652\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 0.4766 - val_loss: 0.4497\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.4551 - val_loss: 0.4468\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 0.4630 - val_loss: 0.4267\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 0.4360 - val_loss: 0.4199\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.4287 - val_loss: 0.4127\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 0.4342 - val_loss: 0.4109\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.4386 - val_loss: 0.4031\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 0.4128 - val_loss: 0.3963\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.4171 - val_loss: 0.3914\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 0.4083 - val_loss: 0.4009\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 0.4237 - val_loss: 0.3866\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.4050 - val_loss: 0.3838\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 0.3865 - val_loss: 0.3776\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 0.3992 - val_loss: 0.3743\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 0.3923 - val_loss: 0.3713\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.4045 - val_loss: 0.3796\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - loss: 0.3882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:] ), # skipping rows) # 30 neurons,\n",
    "    keras.layers.Dense(1) # output layer, only one neuron, no activation function (regression model)\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\") # ok\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "# making predictions\n",
    "X_new = X_test[:3] # pretend these are new instances y_pred = model.predict(X_new)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9e347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2105587],\n",
       "       [1.370321 ],\n",
       "       [1.8295108]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c796d4",
   "metadata": {},
   "source": [
    "## Functional API (Wide and DEEP Non Sequential Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2764ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8dca287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820044a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 2.2915 - val_loss: 0.5276\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.5781 - val_loss: 0.4967\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 0.5336 - val_loss: 0.4616\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 0.5411 - val_loss: 0.4555\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 0.4816 - val_loss: 0.4474\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.4505 - val_loss: 0.9311\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 0.5581 - val_loss: 0.4296\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.4377 - val_loss: 0.4190\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 0.4474 - val_loss: 0.4116\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 0.5326 - val_loss: 0.4104\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 0.4129 - val_loss: 0.3882\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.4442 - val_loss: 0.3820\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - loss: 0.4039 - val_loss: 0.3807\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 0.3884 - val_loss: 0.3714\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 0.3918 - val_loss: 0.3672\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 0.4729 - val_loss: 0.3728\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 0.4153 - val_loss: 0.3754\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 1.1601 - val_loss: 0.3968\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 0.4324 - val_loss: 0.3763\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - loss: 0.4184 - val_loss: 0.3741\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 0.3802\n"
     ]
    }
   ],
   "source": [
    "func_model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=[\"\"]) # ok\n",
    "history = func_model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = func_model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e5b37",
   "metadata": {},
   "source": [
    "For example, suppose we want to send five features through the wide path (features 0 to 4), and six features through the deep path (features 2 to 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bf688e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hid1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hid2 = keras.layers.Dense(30, activation=\"relu\")(hid1)\n",
    "concat_layer = keras.layers.concatenate([input_A, hid2])\n",
    "output_layer = keras.layers.Dense(1, name=\"output_layer\")(concat_layer)\n",
    "\n",
    "model_ = keras.models.Model(inputs=[input_A, input_B], outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde7cff",
   "metadata": {},
   "source": [
    "Now we can compile the model as usual, but when we call the fit() method, instead of passing a single input matrix X_train, we must pass a pair of matrices (X_train_A, X_train_B): one per input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "096998df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3)) ## lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "80e7adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1fe85d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.5244 - val_loss: 0.4868\n",
      "Epoch 2/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 0.4903 - val_loss: 0.4839\n",
      "Epoch 3/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.5034 - val_loss: 0.4805\n",
      "Epoch 4/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 0.4839 - val_loss: 0.4815\n",
      "Epoch 5/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 0.5194 - val_loss: 0.4765\n",
      "Epoch 6/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 0.4978 - val_loss: 0.4745\n",
      "Epoch 7/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.4771 - val_loss: 0.4731\n",
      "Epoch 8/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 0.5160 - val_loss: 0.4705\n",
      "Epoch 9/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.5021 - val_loss: 0.4687\n",
      "Epoch 10/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 0.4878 - val_loss: 0.4680\n",
      "Epoch 11/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.4991 - val_loss: 0.4654\n",
      "Epoch 12/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.4813 - val_loss: 0.4638\n",
      "Epoch 13/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.4798 - val_loss: 0.4630\n",
      "Epoch 14/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.4881 - val_loss: 0.4602\n",
      "Epoch 15/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.4879 - val_loss: 0.4586\n",
      "Epoch 16/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 0.4885 - val_loss: 0.4575\n",
      "Epoch 17/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - loss: 0.4762 - val_loss: 0.4546\n",
      "Epoch 18/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 0.4931 - val_loss: 0.4537\n",
      "Epoch 19/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.4781 - val_loss: 0.4522\n",
      "Epoch 20/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.4590 - val_loss: 0.4516\n",
      "Epoch 21/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.4640 - val_loss: 0.4496\n",
      "Epoch 22/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 0.4662 - val_loss: 0.4499\n",
      "Epoch 23/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - loss: 0.4675 - val_loss: 0.4471\n",
      "Epoch 24/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 0.4548 - val_loss: 0.4471\n",
      "Epoch 25/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.4643 - val_loss: 0.4451\n",
      "Epoch 26/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.4816 - val_loss: 0.4438\n",
      "Epoch 27/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 0.4578 - val_loss: 0.4431\n",
      "Epoch 28/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 0.4585 - val_loss: 0.4417\n",
      "Epoch 29/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.4455 - val_loss: 0.4410\n",
      "Epoch 30/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 0.4655 - val_loss: 0.4412\n",
      "Epoch 31/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.4608 - val_loss: 0.4392\n",
      "Epoch 32/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 0.4548 - val_loss: 0.4379\n",
      "Epoch 33/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.4603 - val_loss: 0.4363\n",
      "Epoch 34/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.4606 - val_loss: 0.4353\n",
      "Epoch 35/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 0.4576 - val_loss: 0.4347\n",
      "Epoch 36/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.4421 - val_loss: 0.4335\n",
      "Epoch 37/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 0.4407 - val_loss: 0.4326\n",
      "Epoch 38/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 0.4483 - val_loss: 0.4331\n",
      "Epoch 39/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.4621 - val_loss: 0.4318\n",
      "Epoch 40/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 0.4662 - val_loss: 0.4291\n",
      "Epoch 41/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.4416 - val_loss: 0.4295\n",
      "Epoch 42/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.4606 - val_loss: 0.4272\n",
      "Epoch 43/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.4322 - val_loss: 0.4269\n",
      "Epoch 44/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.4460 - val_loss: 0.4253\n",
      "Epoch 45/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.4468 - val_loss: 0.4252\n",
      "Epoch 46/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 0.4260 - val_loss: 0.4235\n",
      "Epoch 47/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.4479 - val_loss: 0.4249\n",
      "Epoch 48/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.4238 - val_loss: 0.4219\n",
      "Epoch 49/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.4266 - val_loss: 0.4211\n",
      "Epoch 50/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.4477 - val_loss: 0.4199\n",
      "Epoch 51/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.4395 - val_loss: 0.4196\n",
      "Epoch 52/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.4404 - val_loss: 0.4180\n",
      "Epoch 53/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.4279 - val_loss: 0.4189\n",
      "Epoch 54/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - loss: 0.4395 - val_loss: 0.4165\n",
      "Epoch 55/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 0.4375 - val_loss: 0.4157\n",
      "Epoch 56/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 0.4278 - val_loss: 0.4158\n",
      "Epoch 57/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 0.4240 - val_loss: 0.4138\n",
      "Epoch 58/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 0.4424 - val_loss: 0.4146\n",
      "Epoch 59/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.4313 - val_loss: 0.4135\n",
      "Epoch 60/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 0.4243 - val_loss: 0.4116\n",
      "Epoch 61/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 0.4240 - val_loss: 0.4100\n",
      "Epoch 62/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 0.4317 - val_loss: 0.4106\n",
      "Epoch 63/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 0.4427 - val_loss: 0.4084\n",
      "Epoch 64/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 0.4394 - val_loss: 0.4084\n",
      "Epoch 65/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 0.4332 - val_loss: 0.4074\n",
      "Epoch 66/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 0.4212 - val_loss: 0.4069\n",
      "Epoch 67/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.4369 - val_loss: 0.4065\n",
      "Epoch 68/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.4215 - val_loss: 0.4057\n",
      "Epoch 69/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.4297 - val_loss: 0.4041\n",
      "Epoch 70/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.4102 - val_loss: 0.4038\n",
      "Epoch 71/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 0.4400 - val_loss: 0.4020\n",
      "Epoch 72/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.4202 - val_loss: 0.4027\n",
      "Epoch 73/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.4346 - val_loss: 0.4006\n",
      "Epoch 74/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.4166 - val_loss: 0.4013\n",
      "Epoch 75/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.4284 - val_loss: 0.3997\n",
      "Epoch 76/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.4239 - val_loss: 0.3983\n",
      "Epoch 77/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 0.4149 - val_loss: 0.3982\n",
      "Epoch 78/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - loss: 0.4279 - val_loss: 0.3974\n",
      "Epoch 79/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.4182 - val_loss: 0.3956\n",
      "Epoch 80/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 0.4138 - val_loss: 0.3967\n",
      "Epoch 81/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.4216 - val_loss: 0.3942\n",
      "Epoch 82/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.4278 - val_loss: 0.3949\n",
      "Epoch 83/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.4010 - val_loss: 0.3938\n",
      "Epoch 84/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.4132 - val_loss: 0.3922\n",
      "Epoch 85/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.4096 - val_loss: 0.3926\n",
      "Epoch 86/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 0.4351 - val_loss: 0.3920\n",
      "Epoch 87/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.4049 - val_loss: 0.3925\n",
      "Epoch 88/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.4154 - val_loss: 0.3908\n",
      "Epoch 89/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.4114 - val_loss: 0.3911\n",
      "Epoch 90/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.4042 - val_loss: 0.3888\n",
      "Epoch 91/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.4117 - val_loss: 0.3875\n",
      "Epoch 92/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 0.4114 - val_loss: 0.3876\n",
      "Epoch 93/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.4057 - val_loss: 0.3869\n",
      "Epoch 94/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 0.4077 - val_loss: 0.3855\n",
      "Epoch 95/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.4051 - val_loss: 0.3859\n",
      "Epoch 96/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.4001 - val_loss: 0.3854\n",
      "Epoch 97/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 0.4042 - val_loss: 0.3849\n",
      "Epoch 98/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 0.4016 - val_loss: 0.3844\n",
      "Epoch 99/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 0.4135 - val_loss: 0.3829\n",
      "Epoch 100/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 0.4259 - val_loss: 0.3818\n"
     ]
    }
   ],
   "source": [
    "history = model_.fit((X_train_A, X_train_B), y_train, epochs=100, validation_data=((X_valid_A, X_valid_B), y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6ed418c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also add extra outputs if you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [...] # Same as above, up to the main output layer\n",
    "# output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "# aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "# model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "\n",
    "# # We care much more about the main output than about the auxiliary output (as it is just used for regulari‐ zation),\n",
    "# # so we want to give the main output’s loss a much greater weight\n",
    "\n",
    "# model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n",
    "\n",
    "\n",
    "# history = model.fit(\n",
    "#          [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "#          validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
    "\n",
    "#  total_loss, main_loss, aux_loss = model.evaluate(\n",
    "#         [X_test_A, X_test_B], [y_test, y_test])\n",
    "\n",
    "\n",
    "# y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a72dd",
   "metadata": {},
   "source": [
    "## Using the Subclassing API to Build Dynamic Models\n",
    "\n",
    "\n",
    "Both the Sequential API and the Functional API are declarative: you start by declar‐ ing which layers you want to use and how they should be connected, and only then can you start feeding the model some data for training or inference. This has many advantages: the model can easily be saved, cloned, and shared; its structure can be displayed and analyzed; the framework can infer shapes and check types, so errors can be caught early (i.e., before any data ever goes through the model). It’s also fairly easy to debug, since the whole model is a static graph of layers. But the flip side is just that: it’s static. Some models involve loops, varying shapes, conditional branching, and other dynamic behaviors. For such cases, or simply if you prefer a more impera‐ tive programming style, the Subclassing API is for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a06a6b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ef8e3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model): # subclassing keras.Model\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "573919b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce2a87e",
   "metadata": {},
   "source": [
    "this is for extra flexibility and you can define inputs later on this pre defined architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "54a7cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "## you can save your model by calling\n",
    "\n",
    "model_.save(\"best_model.h5\") #HDF5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved model\n",
    "loaded_model = keras.models.load_model(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586567da",
   "metadata": {},
   "source": [
    "## very important information\n",
    "\n",
    "But what if training lasts several hours? This is quite common, especially when train‐ ing on large datasets. In this case, you should not only save your model at the end of training, but also save checkpoints at regular intervals during training, to avoid losing everything if your computer crashes. But how can you tell the fit() method to save checkpoints? Use callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ae61206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshavsharma/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:] ), # skipping rows) # 30 neurons,\n",
    "    keras.layers.Dense(1) # output layer, only one neuron, no activation function (regression model)\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a8526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 1.2919\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 4.4291\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.4992\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.4737\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 0.4411\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 0.4270\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 0.4263\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 0.4129\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.4074\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 0.4153\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.keras\") # save it with this name \n",
    "# ModelCheckpoint saves your model at end each of epoch\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfeae4e",
   "metadata": {},
   "source": [
    "Moreover, if you use a validation set during training, you can set save_best_only=True when creating the ModelCheckpoint. In this case, it will only save your model when its performance on the validation set is the best so far. This way, you do not need to worry about training for too long and overfitting the training set: simply restore the last model saved after training, and this will be the best model on the validation set. The following code is a simple way to implement early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c3a5f2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4142 - val_loss: 0.3747\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.4003 - val_loss: 0.3738\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.4047 - val_loss: 0.3735\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.3887 - val_loss: 0.3651\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.4108 - val_loss: 0.3647\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.3781 - val_loss: 0.3684\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 0.3884 - val_loss: 0.3582\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.3920 - val_loss: 0.3612\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3705 - val_loss: 0.3542\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.3747 - val_loss: 0.3527\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 0.3710 - val_loss: 0.3564\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.3737 - val_loss: 0.3487\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.3618 - val_loss: 0.3561\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.3690 - val_loss: 0.3469\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.3570 - val_loss: 0.3435\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 0.3791 - val_loss: 0.3424\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.3455 - val_loss: 0.3429\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.3719 - val_loss: 0.3421\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 0.3576 - val_loss: 0.3403\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3549 - val_loss: 0.3536\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_best_model.keras\", save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20, callbacks=[checkpoint_cb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "319a9461",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_best_model = keras.models.load_model(\"my_best_model.keras\") # loads the model with lowest Validation Loss Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "97bd1cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 0.3502\n"
     ]
    }
   ],
   "source": [
    "l = my_best_model.evaluate(X_test, y_test) # good model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84d9fc",
   "metadata": {},
   "source": [
    "Another way to implement early stopping is to simply use the EarlyStopping call‐ back. It will interrupt training when it measures no progress on the validation set for \n",
    "a number of epochs (defined by the patience argument), and it will optionally roll back to the best model. You can combine both callbacks to save checkpoints of your model (in case your computer crashes) and interrupt training early when there is no more progress (to avoid wasting time and resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "328e30df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3599 - val_loss: 0.3375\n",
      "Epoch 2/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.3515 - val_loss: 0.3353\n",
      "Epoch 3/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.3493 - val_loss: 0.3378\n",
      "Epoch 4/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.3611 - val_loss: 0.3404\n",
      "Epoch 5/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 0.3448 - val_loss: 0.3423\n",
      "Epoch 6/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 0.3531 - val_loss: 0.3365\n",
      "Epoch 7/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 0.3582 - val_loss: 0.3425\n",
      "Epoch 8/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 0.3367 - val_loss: 0.3293\n",
      "Epoch 9/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.3619 - val_loss: 0.3314\n",
      "Epoch 10/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.3340 - val_loss: 0.3290\n",
      "Epoch 11/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.3423 - val_loss: 0.3279\n",
      "Epoch 12/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.3473 - val_loss: 0.3273\n",
      "Epoch 13/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.3563 - val_loss: 0.3285\n",
      "Epoch 14/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 0.3388 - val_loss: 0.3253\n",
      "Epoch 15/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.3229 - val_loss: 0.3419\n",
      "Epoch 16/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 0.3368 - val_loss: 0.3254\n",
      "Epoch 17/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.3420 - val_loss: 0.3328\n",
      "Epoch 18/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.3479 - val_loss: 0.3228\n",
      "Epoch 19/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 0.3394 - val_loss: 0.3245\n",
      "Epoch 20/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.3310 - val_loss: 0.3217\n",
      "Epoch 21/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 0.3323 - val_loss: 0.3236\n",
      "Epoch 22/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - loss: 0.3516 - val_loss: 0.3237\n",
      "Epoch 23/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 0.3464 - val_loss: 0.3190\n",
      "Epoch 24/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 0.3327 - val_loss: 0.3217\n",
      "Epoch 25/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.3345 - val_loss: 0.3175\n",
      "Epoch 26/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.3218 - val_loss: 0.3210\n",
      "Epoch 27/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 0.3298 - val_loss: 0.3196\n",
      "Epoch 28/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 0.3408 - val_loss: 0.3169\n",
      "Epoch 29/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 0.3251 - val_loss: 0.3179\n",
      "Epoch 30/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 0.3291 - val_loss: 0.3159\n",
      "Epoch 31/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 0.3285 - val_loss: 0.3154\n",
      "Epoch 32/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 0.3229 - val_loss: 0.3188\n",
      "Epoch 33/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.3323 - val_loss: 0.3244\n",
      "Epoch 34/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.3189 - val_loss: 0.3186\n",
      "Epoch 35/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.3433 - val_loss: 0.3166\n",
      "Epoch 36/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 0.3205 - val_loss: 0.3143\n",
      "Epoch 37/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 0.3204 - val_loss: 0.3352\n",
      "Epoch 38/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.3211 - val_loss: 0.3165\n",
      "Epoch 39/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 0.3291 - val_loss: 0.3128\n",
      "Epoch 40/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 0.3262 - val_loss: 0.3128\n",
      "Epoch 41/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 0.3257 - val_loss: 0.3125\n",
      "Epoch 42/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 0.3154 - val_loss: 0.3216\n",
      "Epoch 43/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 0.3248 - val_loss: 0.3140\n",
      "Epoch 44/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 0.3202 - val_loss: 0.3122\n",
      "Epoch 45/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.3389 - val_loss: 0.3179\n",
      "Epoch 46/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 0.3318 - val_loss: 0.3136\n",
      "Epoch 47/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 0.3240 - val_loss: 0.3110\n",
      "Epoch 48/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 0.3237 - val_loss: 0.3230\n",
      "Epoch 49/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.3218 - val_loss: 0.3121\n",
      "Epoch 50/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 0.3328 - val_loss: 0.3164\n",
      "Epoch 51/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - loss: 0.3163 - val_loss: 0.3094\n",
      "Epoch 52/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.3127 - val_loss: 0.3066\n",
      "Epoch 53/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 0.3058 - val_loss: 0.3137\n",
      "Epoch 54/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.3234 - val_loss: 0.3143\n",
      "Epoch 55/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 0.3245 - val_loss: 0.3094\n",
      "Epoch 56/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.3210 - val_loss: 0.3114\n",
      "Epoch 57/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 0.3027 - val_loss: 0.3215\n",
      "Epoch 58/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 0.3301 - val_loss: 0.3053\n",
      "Epoch 59/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 0.3087 - val_loss: 0.3107\n",
      "Epoch 60/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 0.3244 - val_loss: 0.3069\n",
      "Epoch 61/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 0.3240 - val_loss: 0.3050\n",
      "Epoch 62/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.3255 - val_loss: 0.3176\n",
      "Epoch 63/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 0.3240 - val_loss: 0.3151\n",
      "Epoch 64/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 0.3241 - val_loss: 0.3043\n",
      "Epoch 65/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.3337 - val_loss: 0.3446\n",
      "Epoch 66/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.4748 - val_loss: 0.3090\n",
      "Epoch 67/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 0.3437 - val_loss: 0.3375\n",
      "Epoch 68/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.3395 - val_loss: 0.8028\n",
      "Epoch 69/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.3737 - val_loss: 0.3152\n",
      "Epoch 70/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 0.3396 - val_loss: 0.3094\n",
      "Epoch 71/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 0.3193 - val_loss: 0.3069\n",
      "Epoch 72/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.3074 - val_loss: 0.3107\n",
      "Epoch 73/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 0.3232 - val_loss: 0.3126\n",
      "Epoch 74/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 0.3235 - val_loss: 0.3234\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[early_stopping_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a74f2c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 0.3276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29941442608833313"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no need to load the model again, the early stopping will automatically restore the best weights to the model\n",
    "model.evaluate(X_test, y_test) ### bestest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54dcce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## writing custom callback\n",
    "\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    # you can implement on_train_begin(), on_train_end(),\n",
    "    #  on_epoch_begin(), on_epoch_end(), on_batch_begin(), and on_batch_end()\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "190aa6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Tensorboard something\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") \n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "26a236e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3233 - val_loss: 0.3045\n",
      "Epoch 2/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3314 - val_loss: 0.3083\n",
      "Epoch 3/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3284 - val_loss: 0.3069\n",
      "Epoch 4/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3106 - val_loss: 0.3020\n",
      "Epoch 5/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3090 - val_loss: 0.3016\n",
      "Epoch 6/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.3100 - val_loss: 0.3118\n",
      "Epoch 7/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.3131 - val_loss: 0.3123\n",
      "Epoch 8/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 0.3082 - val_loss: 0.3186\n",
      "Epoch 9/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.3287 - val_loss: 0.3033\n",
      "Epoch 10/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.3171 - val_loss: 0.3019\n",
      "Epoch 11/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.3287 - val_loss: 0.3081\n",
      "Epoch 12/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.3110 - val_loss: 0.3253\n",
      "Epoch 13/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - loss: 0.3151 - val_loss: 0.3025\n",
      "Epoch 14/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.3120 - val_loss: 0.3056\n",
      "Epoch 15/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.3171 - val_loss: 0.2991\n",
      "Epoch 16/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.3230 - val_loss: 0.3009\n",
      "Epoch 17/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.3057 - val_loss: 0.3019\n",
      "Epoch 18/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.3407 - val_loss: 0.3041\n",
      "Epoch 19/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.3163 - val_loss: 0.3024\n",
      "Epoch 20/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.3092 - val_loss: 0.3064\n",
      "Epoch 21/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.3279 - val_loss: 0.3011\n",
      "Epoch 22/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - loss: 0.3206 - val_loss: 0.3043\n",
      "Epoch 23/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.3191 - val_loss: 0.3073\n",
      "Epoch 24/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.3189 - val_loss: 0.3207\n",
      "Epoch 25/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.3181 - val_loss: 0.3243\n",
      "Epoch 26/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.3071 - val_loss: 0.2992\n",
      "Epoch 27/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.3156 - val_loss: 0.3042\n",
      "Epoch 28/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.3154 - val_loss: 0.2985\n",
      "Epoch 29/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.3093 - val_loss: 0.3050\n",
      "Epoch 30/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.3186 - val_loss: 0.2983\n",
      "Epoch 31/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.3036 - val_loss: 0.3027\n",
      "Epoch 32/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.2990 - val_loss: 0.3023\n",
      "Epoch 33/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.3061 - val_loss: 0.3007\n",
      "Epoch 34/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.3182 - val_loss: 0.3064\n",
      "Epoch 35/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.3143 - val_loss: 0.3169\n",
      "Epoch 36/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.3245 - val_loss: 0.2998\n",
      "Epoch 37/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.3062 - val_loss: 0.2985\n",
      "Epoch 38/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 0.3215 - val_loss: 0.2995\n",
      "Epoch 39/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.3063 - val_loss: 0.3076\n",
      "Epoch 40/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.3264 - val_loss: 0.3408\n",
      "Epoch 41/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 0.5085 - val_loss: 0.3227\n",
      "Epoch 42/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.3409 - val_loss: 0.3185\n",
      "Epoch 43/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.3348 - val_loss: 0.3594\n",
      "Epoch 44/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.3547 - val_loss: 0.5563\n",
      "Epoch 45/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.4144 - val_loss: 0.3592\n",
      "Epoch 46/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.3366 - val_loss: 0.3325\n",
      "Epoch 47/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 0.3446 - val_loss: 0.3229\n",
      "Epoch 48/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.3211 - val_loss: 0.3153\n",
      "Epoch 49/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.3316 - val_loss: 0.3134\n",
      "Epoch 50/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.3190 - val_loss: 0.3153\n",
      "Epoch 51/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 0.3182 - val_loss: 0.3100\n",
      "Epoch 52/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.3144 - val_loss: 0.3107\n",
      "Epoch 53/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.3360 - val_loss: 0.3130\n",
      "Epoch 54/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.3179 - val_loss: 0.3100\n",
      "Epoch 55/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.3165 - val_loss: 0.3060\n",
      "Epoch 56/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.3147 - val_loss: 0.3048\n",
      "Epoch 57/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.3156 - val_loss: 0.3022\n",
      "Epoch 58/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.3063 - val_loss: 0.3075\n",
      "Epoch 59/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.3061 - val_loss: 0.3028\n",
      "Epoch 60/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.2936 - val_loss: 0.3033\n",
      "Epoch 61/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.3138 - val_loss: 0.2999\n",
      "Epoch 62/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.3183 - val_loss: 0.3021\n",
      "Epoch 63/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.3181 - val_loss: 0.3053\n",
      "Epoch 64/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.3215 - val_loss: 0.3048\n",
      "Epoch 65/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.3095 - val_loss: 0.3027\n",
      "Epoch 66/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 0.3148 - val_loss: 0.3011\n",
      "Epoch 67/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.3051 - val_loss: 0.3034\n",
      "Epoch 68/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.3072 - val_loss: 0.2999\n",
      "Epoch 69/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.3130 - val_loss: 0.3015\n",
      "Epoch 70/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.3122 - val_loss: 0.2990\n",
      "Epoch 71/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.3124 - val_loss: 0.3002\n",
      "Epoch 72/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.2956 - val_loss: 0.2994\n",
      "Epoch 73/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.3059 - val_loss: 0.2983\n",
      "Epoch 74/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 0.3045 - val_loss: 0.3038\n",
      "Epoch 75/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.3183 - val_loss: 0.2987\n",
      "Epoch 76/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.3137 - val_loss: 0.3097\n",
      "Epoch 77/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.3061 - val_loss: 0.3002\n",
      "Epoch 78/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.3170 - val_loss: 0.3004\n",
      "Epoch 79/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.3115 - val_loss: 0.2994\n",
      "Epoch 80/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.3112 - val_loss: 0.3075\n",
      "Epoch 81/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.3105 - val_loss: 0.3031\n",
      "Epoch 82/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - loss: 0.3199 - val_loss: 0.3023\n",
      "Epoch 83/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.3071 - val_loss: 0.2995\n",
      "Epoch 84/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.3293 - val_loss: 0.2995\n",
      "Epoch 85/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 0.3099 - val_loss: 0.3003\n",
      "Epoch 86/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.3037 - val_loss: 0.3095\n",
      "Epoch 87/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.3069 - val_loss: 0.3025\n",
      "Epoch 88/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.2960 - val_loss: 0.3041\n",
      "Epoch 89/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.2988 - val_loss: 0.3002\n",
      "Epoch 90/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.3095 - val_loss: 0.3066\n",
      "Epoch 91/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.3101 - val_loss: 0.3092\n",
      "Epoch 92/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.3162 - val_loss: 0.2983\n",
      "Epoch 93/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.3094 - val_loss: 0.3187\n",
      "Epoch 94/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.3388 - val_loss: 0.3190\n",
      "Epoch 95/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.3341 - val_loss: 0.3074\n",
      "Epoch 96/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.3133 - val_loss: 0.3053\n",
      "Epoch 97/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.3209 - val_loss: 0.3216\n",
      "Epoch 98/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.3498 - val_loss: 0.3015\n",
      "Epoch 99/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.3076 - val_loss: 0.3120\n",
      "Epoch 100/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.3185 - val_loss: 0.3037\n"
     ]
    }
   ],
   "source": [
    "# Keras provides a nice TensorBoard() callback:\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e68663d",
   "metadata": {},
   "source": [
    "Fine-Tuning Neural Network Hyperparameters\n",
    "\n",
    "\n",
    "using GridSearchCV\n",
    "\n",
    "or\n",
    "\n",
    "RandomisedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ff5ef12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, lr=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "\n",
    "    model.add(keras.layers.Dense(1)) # Output layer\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=lr)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9231aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KerasRegressor based on this build_model()\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "keras_reg = KerasRegressor(model=build_model, epochs=100,\n",
    "    # validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
    "    verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda117b",
   "metadata": {},
   "source": [
    "we can use this object like a regular Scikit-Learn regressor: we can train it using its fit() method, then evaluate it using its score() method, and use it to make predictions using its predict() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4a7bf4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshavsharma/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Users/keshavsharma/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/IPython/core/formatters.py:1036\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m   1033\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1036\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/base.py:469\u001b[0m, in \u001b[0;36mBaseEstimator._repr_mimebundle_\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m output \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/plain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)}\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiagram\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 469\u001b[0m     output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/html\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mestimator_html_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/utils/_estimator_html_repr.py:387\u001b[0m, in \u001b[0;36mestimator_html_repr\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m         \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m         status_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<span>Fitted</span>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         is_fitted_css_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1751\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m-> 1751\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/utils/_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[0;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/base.py:613\u001b[0m, in \u001b[0;36m__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 613\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m     )\n\u001b[1;32m    616\u001b[0m no_val_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m X \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    617\u001b[0m no_val_y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/IPython/core/formatters.py:406\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    404\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/base.py:463\u001b[0m, in \u001b[0;36mBaseEstimator._repr_html_inner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repr_html_inner\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    459\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function is returned by the @property `_repr_html_` to make\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m    `hasattr(estimator, \"_repr_html_\") return `True` or `False` depending\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03m    on `get_config()[\"display\"]`.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator_html_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/utils/_estimator_html_repr.py:387\u001b[0m, in \u001b[0;36mestimator_html_repr\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m         \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m         status_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<span>Fitted</span>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         is_fitted_css_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1751\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m-> 1751\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/utils/_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[0;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/base.py:613\u001b[0m, in \u001b[0;36m__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 613\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m     )\n\u001b[1;32m    616\u001b[0m no_val_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m X \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    617\u001b[0m no_val_y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KerasRegressor(\n",
       "\tmodel=<function build_model at 0x16d6770a0>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=[<keras.src.callbacks.early_stopping.EarlyStopping object at 0x10b9fbaf0>]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "174472f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[176], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m params_distribs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_hidden\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m ,\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neurons\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m),\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: reciprocal(\u001b[38;5;241m3e-4\u001b[39m, \u001b[38;5;241m3e-2\u001b[39m)\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     12\u001b[0m rnd_search_cv \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(keras_reg, params_distribs, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mrnd_search_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:933\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    929\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    931\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_routed_params_for_fit(params)\n\u001b[0;32m--> 933\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    934\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)\n\u001b[1;32m    936\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/base.py:1237\u001b[0m, in \u001b[0;36mis_classifier\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1233\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1234\u001b[0m     )\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_estimator_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/utils/_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[0;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[0;32m~/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/sklearn/base.py:613\u001b[0m, in \u001b[0;36m__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 613\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m     )\n\u001b[1;32m    616\u001b[0m no_val_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m X \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    617\u001b[0m no_val_y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "params_distribs = {\n",
    "    \"n_hidden\": [0, 1 ,2, 3], \n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, params_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc37a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.0\n",
      "1.5.2\n",
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import scikeras\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "print(scikeras.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55742825",
   "metadata": {},
   "source": [
    "## FUCK SCIKERAS.. ALL MY HOMIES LOVE \"KERAS TUNER\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86d499",
   "metadata": {},
   "source": [
    "### 1. how to select appropriate optimizer\n",
    "### 2. No of neurons in a layer\n",
    "### 3. how to select no of layers\n",
    "### 4. we wil make all in all one model with best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d783529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mx/gt4xb15x3vs8gsgpg6gcg1j00000gn/T/ipykernel_45769/1337601089.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35feefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading classification dataset (Diabeters) (as accuracy is a parameter of classification, not regression)\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63112a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0.221898\n",
       "Glucose                     0.466581\n",
       "BloodPressure               0.065068\n",
       "SkinThickness               0.074752\n",
       "Insulin                     0.130548\n",
       "BMI                         0.292695\n",
       "DiabetesPedigreeFunction    0.173844\n",
       "Age                         0.238356\n",
       "Outcome                     1.000000\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2405f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de21b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5de2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d4f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8bc6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "823cba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshavsharma/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(32, input_dim=8, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, name=\"output_layer\", activation=\"sigmoid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a8ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb7de833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5964 - loss: 0.7758 - val_accuracy: 0.5974 - val_loss: 0.7253\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6720 - loss: 0.6834 - val_accuracy: 0.6364 - val_loss: 0.6693\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6522 - loss: 0.6452 - val_accuracy: 0.6558 - val_loss: 0.6242\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6551 - loss: 0.6223 - val_accuracy: 0.6883 - val_loss: 0.5908\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7039 - loss: 0.5619 - val_accuracy: 0.7208 - val_loss: 0.5645\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6913 - loss: 0.5890 - val_accuracy: 0.7597 - val_loss: 0.5464\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7246 - loss: 0.5439 - val_accuracy: 0.7532 - val_loss: 0.5317\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7061 - loss: 0.5361 - val_accuracy: 0.7792 - val_loss: 0.5199\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7312 - loss: 0.5237 - val_accuracy: 0.7857 - val_loss: 0.5093\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.4889 - val_accuracy: 0.7987 - val_loss: 0.5022\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7702 - loss: 0.5041 - val_accuracy: 0.7857 - val_loss: 0.4960\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7633 - loss: 0.4828 - val_accuracy: 0.7792 - val_loss: 0.4919\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7883 - loss: 0.4759 - val_accuracy: 0.7857 - val_loss: 0.4875\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7880 - loss: 0.4632 - val_accuracy: 0.7727 - val_loss: 0.4836\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7513 - loss: 0.5026 - val_accuracy: 0.7662 - val_loss: 0.4822\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4690 - val_accuracy: 0.7727 - val_loss: 0.4816\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.4478 - val_accuracy: 0.7727 - val_loss: 0.4807\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.4760 - val_accuracy: 0.7857 - val_loss: 0.4789\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7687 - loss: 0.4645 - val_accuracy: 0.7857 - val_loss: 0.4786\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4325 - val_accuracy: 0.7792 - val_loss: 0.4785\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7651 - loss: 0.4502 - val_accuracy: 0.7727 - val_loss: 0.4785\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 0.4473 - val_accuracy: 0.7792 - val_loss: 0.4772\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7656 - loss: 0.4567 - val_accuracy: 0.7727 - val_loss: 0.4769\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7846 - loss: 0.4460 - val_accuracy: 0.7792 - val_loss: 0.4775\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7908 - loss: 0.4355 - val_accuracy: 0.7792 - val_loss: 0.4754\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7848 - loss: 0.4498 - val_accuracy: 0.7792 - val_loss: 0.4759\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7837 - loss: 0.4467 - val_accuracy: 0.7727 - val_loss: 0.4751\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7849 - loss: 0.4469 - val_accuracy: 0.7662 - val_loss: 0.4737\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4641 - val_accuracy: 0.7727 - val_loss: 0.4735\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.4367 - val_accuracy: 0.7792 - val_loss: 0.4737\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: 0.4386 - val_accuracy: 0.7727 - val_loss: 0.4728\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.4261 - val_accuracy: 0.7727 - val_loss: 0.4719\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.4155 - val_accuracy: 0.7727 - val_loss: 0.4721\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.4358 - val_accuracy: 0.7857 - val_loss: 0.4720\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.4358 - val_accuracy: 0.7727 - val_loss: 0.4712\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7858 - loss: 0.4447 - val_accuracy: 0.7727 - val_loss: 0.4707\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.4342 - val_accuracy: 0.7727 - val_loss: 0.4701\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4211 - val_accuracy: 0.7857 - val_loss: 0.4713\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7873 - loss: 0.4574 - val_accuracy: 0.7857 - val_loss: 0.4715\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7815 - loss: 0.4447 - val_accuracy: 0.7727 - val_loss: 0.4720\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.4497 - val_accuracy: 0.7792 - val_loss: 0.4698\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4458 - val_accuracy: 0.7727 - val_loss: 0.4718\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.4107 - val_accuracy: 0.7727 - val_loss: 0.4712\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7903 - loss: 0.4439 - val_accuracy: 0.7662 - val_loss: 0.4705\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7614 - loss: 0.4542 - val_accuracy: 0.7727 - val_loss: 0.4714\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7882 - loss: 0.4367 - val_accuracy: 0.7727 - val_loss: 0.4694\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.4032 - val_accuracy: 0.7727 - val_loss: 0.4692\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8002 - loss: 0.4323 - val_accuracy: 0.7662 - val_loss: 0.4674\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7687 - loss: 0.4681 - val_accuracy: 0.7792 - val_loss: 0.4678\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4357 - val_accuracy: 0.7727 - val_loss: 0.4681\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7926 - loss: 0.4363 - val_accuracy: 0.7727 - val_loss: 0.4671\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7927 - loss: 0.4360 - val_accuracy: 0.7727 - val_loss: 0.4657\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8037 - loss: 0.4220 - val_accuracy: 0.7857 - val_loss: 0.4641\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.4078 - val_accuracy: 0.7792 - val_loss: 0.4651\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.4641 - val_accuracy: 0.7792 - val_loss: 0.4652\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.4343 - val_accuracy: 0.7792 - val_loss: 0.4648\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.3956 - val_accuracy: 0.7922 - val_loss: 0.4636\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.4058 - val_accuracy: 0.7922 - val_loss: 0.4638\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8161 - loss: 0.4063 - val_accuracy: 0.7857 - val_loss: 0.4624\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7995 - loss: 0.4358 - val_accuracy: 0.7857 - val_loss: 0.4634\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7834 - loss: 0.4162 - val_accuracy: 0.7792 - val_loss: 0.4641\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8325 - loss: 0.3955 - val_accuracy: 0.7792 - val_loss: 0.4642\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7841 - loss: 0.4280 - val_accuracy: 0.7792 - val_loss: 0.4639\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7868 - loss: 0.4372 - val_accuracy: 0.7792 - val_loss: 0.4617\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8032 - loss: 0.4128 - val_accuracy: 0.7857 - val_loss: 0.4613\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7771 - loss: 0.4475 - val_accuracy: 0.7792 - val_loss: 0.4627\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8087 - loss: 0.4123 - val_accuracy: 0.7792 - val_loss: 0.4626\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7657 - loss: 0.4448 - val_accuracy: 0.7857 - val_loss: 0.4617\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7694 - loss: 0.4556 - val_accuracy: 0.7857 - val_loss: 0.4617\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7838 - loss: 0.4300 - val_accuracy: 0.7727 - val_loss: 0.4621\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.4208 - val_accuracy: 0.7727 - val_loss: 0.4637\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8101 - loss: 0.4209 - val_accuracy: 0.7727 - val_loss: 0.4645\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8106 - loss: 0.4265 - val_accuracy: 0.7727 - val_loss: 0.4635\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7889 - loss: 0.4421 - val_accuracy: 0.7727 - val_loss: 0.4620\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.4193 - val_accuracy: 0.7857 - val_loss: 0.4605\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.4105 - val_accuracy: 0.7857 - val_loss: 0.4597\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3910 - val_accuracy: 0.7857 - val_loss: 0.4598\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7974 - loss: 0.4396 - val_accuracy: 0.7857 - val_loss: 0.4617\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7545 - loss: 0.4563 - val_accuracy: 0.7857 - val_loss: 0.4616\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.4209 - val_accuracy: 0.7987 - val_loss: 0.4607\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8070 - loss: 0.4089 - val_accuracy: 0.7857 - val_loss: 0.4610\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7971 - loss: 0.4031 - val_accuracy: 0.7922 - val_loss: 0.4589\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7872 - loss: 0.4435 - val_accuracy: 0.7857 - val_loss: 0.4572\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4106 - val_accuracy: 0.7857 - val_loss: 0.4578\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7670 - loss: 0.4557 - val_accuracy: 0.7857 - val_loss: 0.4582\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.4330 - val_accuracy: 0.7857 - val_loss: 0.4583\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4018 - val_accuracy: 0.7857 - val_loss: 0.4586\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.4139 - val_accuracy: 0.7857 - val_loss: 0.4579\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8153 - loss: 0.4181 - val_accuracy: 0.7792 - val_loss: 0.4575\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8116 - loss: 0.4116 - val_accuracy: 0.7922 - val_loss: 0.4584\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4316 - val_accuracy: 0.7857 - val_loss: 0.4593\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.4117 - val_accuracy: 0.7792 - val_loss: 0.4592\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.4461 - val_accuracy: 0.7922 - val_loss: 0.4592\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.4101 - val_accuracy: 0.7857 - val_loss: 0.4579\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.4108 - val_accuracy: 0.7857 - val_loss: 0.4589\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8149 - loss: 0.4021 - val_accuracy: 0.7857 - val_loss: 0.4599\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.4068 - val_accuracy: 0.7987 - val_loss: 0.4579\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.4084 - val_accuracy: 0.7922 - val_loss: 0.4571\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8150 - loss: 0.3954 - val_accuracy: 0.7922 - val_loss: 0.4561\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7831 - loss: 0.4300 - val_accuracy: 0.7857 - val_loss: 0.4564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16404d900>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "772aa6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(32, activation=\"relu\", input_dim=8))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"adam\", \"sgd\", \"rmsprop\", \"adadelta\"])\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9da573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshavsharma/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(hypermodel=build_model, objective=\"val_accuracy\", max_trials=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05e06288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.7727272510528564\n",
      "\n",
      "Best val_accuracy So Far: 0.7922077775001526\n",
      "Total elapsed time: 00h 00m 05s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cc44da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c9c5300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5673af52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshavsharma/Downloads/DATA SCIENCE LESSGO/chai_aur_code_numpy/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_ = tuner.get_best_models(num_models=1)[0] # to get top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a4645dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb48556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7220 - loss: 0.5629 - val_accuracy: 0.7792 - val_loss: 0.5324\n",
      "Epoch 2/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7456 - loss: 0.5470 - val_accuracy: 0.7792 - val_loss: 0.5249\n",
      "Epoch 3/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7405 - loss: 0.5607 - val_accuracy: 0.7792 - val_loss: 0.5184\n",
      "Epoch 4/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7221 - loss: 0.5402 - val_accuracy: 0.7727 - val_loss: 0.5127\n",
      "Epoch 5/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7763 - loss: 0.5180 - val_accuracy: 0.7727 - val_loss: 0.5073\n",
      "Epoch 6/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.5153 - val_accuracy: 0.7857 - val_loss: 0.5028\n",
      "Epoch 7/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7474 - loss: 0.5307 - val_accuracy: 0.7857 - val_loss: 0.4996\n",
      "Epoch 8/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7529 - loss: 0.5169 - val_accuracy: 0.7987 - val_loss: 0.4958\n",
      "Epoch 9/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.4829 - val_accuracy: 0.8052 - val_loss: 0.4917\n",
      "Epoch 10/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7819 - loss: 0.4963 - val_accuracy: 0.8052 - val_loss: 0.4880\n",
      "Epoch 11/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.4984 - val_accuracy: 0.8052 - val_loss: 0.4852\n",
      "Epoch 12/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7703 - loss: 0.5066 - val_accuracy: 0.8117 - val_loss: 0.4825\n",
      "Epoch 13/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.4805 - val_accuracy: 0.8052 - val_loss: 0.4805\n",
      "Epoch 14/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: 0.4792 - val_accuracy: 0.8052 - val_loss: 0.4783\n",
      "Epoch 15/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7700 - loss: 0.5007 - val_accuracy: 0.7987 - val_loss: 0.4758\n",
      "Epoch 16/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7902 - loss: 0.4881 - val_accuracy: 0.7987 - val_loss: 0.4737\n",
      "Epoch 17/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8087 - loss: 0.4692 - val_accuracy: 0.7987 - val_loss: 0.4717\n",
      "Epoch 18/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.4772 - val_accuracy: 0.7987 - val_loss: 0.4698\n",
      "Epoch 19/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7998 - loss: 0.4651 - val_accuracy: 0.7987 - val_loss: 0.4679\n",
      "Epoch 20/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.4962 - val_accuracy: 0.7987 - val_loss: 0.4666\n",
      "Epoch 21/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7665 - loss: 0.4937 - val_accuracy: 0.7987 - val_loss: 0.4651\n",
      "Epoch 22/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7852 - loss: 0.4741 - val_accuracy: 0.8052 - val_loss: 0.4640\n",
      "Epoch 23/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7729 - loss: 0.4870 - val_accuracy: 0.8052 - val_loss: 0.4629\n",
      "Epoch 24/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7757 - loss: 0.4856 - val_accuracy: 0.8052 - val_loss: 0.4617\n",
      "Epoch 25/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7493 - loss: 0.4964 - val_accuracy: 0.8052 - val_loss: 0.4604\n",
      "Epoch 26/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7893 - loss: 0.4765 - val_accuracy: 0.8052 - val_loss: 0.4594\n",
      "Epoch 27/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.4989 - val_accuracy: 0.8052 - val_loss: 0.4586\n",
      "Epoch 28/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7787 - loss: 0.4932 - val_accuracy: 0.7987 - val_loss: 0.4579\n",
      "Epoch 29/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7886 - loss: 0.4705 - val_accuracy: 0.8052 - val_loss: 0.4571\n",
      "Epoch 30/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7713 - loss: 0.4890 - val_accuracy: 0.7857 - val_loss: 0.4561\n",
      "Epoch 31/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7773 - loss: 0.4854 - val_accuracy: 0.7922 - val_loss: 0.4555\n",
      "Epoch 32/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7571 - loss: 0.4992 - val_accuracy: 0.7987 - val_loss: 0.4550\n",
      "Epoch 33/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7952 - loss: 0.4597 - val_accuracy: 0.7987 - val_loss: 0.4543\n",
      "Epoch 34/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7595 - loss: 0.4742 - val_accuracy: 0.7987 - val_loss: 0.4534\n",
      "Epoch 35/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7868 - loss: 0.4628 - val_accuracy: 0.7987 - val_loss: 0.4530\n",
      "Epoch 36/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.4689 - val_accuracy: 0.7987 - val_loss: 0.4522\n",
      "Epoch 37/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7790 - loss: 0.4810 - val_accuracy: 0.7987 - val_loss: 0.4519\n",
      "Epoch 38/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7756 - loss: 0.4779 - val_accuracy: 0.7987 - val_loss: 0.4513\n",
      "Epoch 39/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7958 - loss: 0.4484 - val_accuracy: 0.7987 - val_loss: 0.4510\n",
      "Epoch 40/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7751 - loss: 0.4650 - val_accuracy: 0.7987 - val_loss: 0.4508\n",
      "Epoch 41/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.4653 - val_accuracy: 0.7987 - val_loss: 0.4505\n",
      "Epoch 42/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.4796 - val_accuracy: 0.7987 - val_loss: 0.4502\n",
      "Epoch 43/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7714 - loss: 0.4832 - val_accuracy: 0.7987 - val_loss: 0.4499\n",
      "Epoch 44/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7917 - loss: 0.4478 - val_accuracy: 0.7987 - val_loss: 0.4496\n",
      "Epoch 45/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8001 - loss: 0.4549 - val_accuracy: 0.7987 - val_loss: 0.4492\n",
      "Epoch 46/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.4520 - val_accuracy: 0.7922 - val_loss: 0.4489\n",
      "Epoch 47/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.4401 - val_accuracy: 0.7922 - val_loss: 0.4487\n",
      "Epoch 48/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7856 - loss: 0.4609 - val_accuracy: 0.7922 - val_loss: 0.4486\n",
      "Epoch 49/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8068 - loss: 0.4507 - val_accuracy: 0.7922 - val_loss: 0.4483\n",
      "Epoch 50/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7983 - loss: 0.4484 - val_accuracy: 0.7922 - val_loss: 0.4481\n",
      "Epoch 51/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7886 - loss: 0.4538 - val_accuracy: 0.7987 - val_loss: 0.4480\n",
      "Epoch 52/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.4529 - val_accuracy: 0.7987 - val_loss: 0.4479\n",
      "Epoch 53/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7963 - loss: 0.4358 - val_accuracy: 0.7922 - val_loss: 0.4480\n",
      "Epoch 54/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.4459 - val_accuracy: 0.7922 - val_loss: 0.4479\n",
      "Epoch 55/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.4526 - val_accuracy: 0.7987 - val_loss: 0.4478\n",
      "Epoch 56/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7645 - loss: 0.4980 - val_accuracy: 0.7987 - val_loss: 0.4478\n",
      "Epoch 57/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.4361 - val_accuracy: 0.7987 - val_loss: 0.4476\n",
      "Epoch 58/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7871 - loss: 0.4422 - val_accuracy: 0.7987 - val_loss: 0.4473\n",
      "Epoch 59/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7883 - loss: 0.4535 - val_accuracy: 0.7987 - val_loss: 0.4473\n",
      "Epoch 60/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7865 - loss: 0.4517 - val_accuracy: 0.7987 - val_loss: 0.4470\n",
      "Epoch 61/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7713 - loss: 0.4674 - val_accuracy: 0.7987 - val_loss: 0.4469\n",
      "Epoch 62/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4558 - val_accuracy: 0.7987 - val_loss: 0.4469\n",
      "Epoch 63/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.4373 - val_accuracy: 0.7987 - val_loss: 0.4468\n",
      "Epoch 64/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.4643 - val_accuracy: 0.7987 - val_loss: 0.4465\n",
      "Epoch 65/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7892 - loss: 0.4349 - val_accuracy: 0.7987 - val_loss: 0.4463\n",
      "Epoch 66/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.4272 - val_accuracy: 0.7987 - val_loss: 0.4462\n",
      "Epoch 67/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.3817 - val_accuracy: 0.7987 - val_loss: 0.4463\n",
      "Epoch 68/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.4434 - val_accuracy: 0.7987 - val_loss: 0.4465\n",
      "Epoch 69/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.4537 - val_accuracy: 0.7987 - val_loss: 0.4463\n",
      "Epoch 70/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7887 - loss: 0.4575 - val_accuracy: 0.7987 - val_loss: 0.4462\n",
      "Epoch 71/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7917 - loss: 0.4594 - val_accuracy: 0.7987 - val_loss: 0.4462\n",
      "Epoch 72/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7855 - loss: 0.4613 - val_accuracy: 0.7987 - val_loss: 0.4462\n",
      "Epoch 73/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7755 - loss: 0.4499 - val_accuracy: 0.7987 - val_loss: 0.4460\n",
      "Epoch 74/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7679 - loss: 0.4517 - val_accuracy: 0.7987 - val_loss: 0.4461\n",
      "Epoch 75/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7834 - loss: 0.4453 - val_accuracy: 0.7987 - val_loss: 0.4459\n",
      "Epoch 76/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.4358 - val_accuracy: 0.7987 - val_loss: 0.4460\n",
      "Epoch 77/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.4831 - val_accuracy: 0.7987 - val_loss: 0.4461\n",
      "Epoch 78/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.4535 - val_accuracy: 0.7987 - val_loss: 0.4462\n",
      "Epoch 79/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.4447 - val_accuracy: 0.7987 - val_loss: 0.4458\n",
      "Epoch 80/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7834 - loss: 0.4598 - val_accuracy: 0.7987 - val_loss: 0.4461\n",
      "Epoch 81/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7805 - loss: 0.4646 - val_accuracy: 0.7987 - val_loss: 0.4460\n",
      "Epoch 82/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.4566 - val_accuracy: 0.7987 - val_loss: 0.4461\n",
      "Epoch 83/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.4348 - val_accuracy: 0.7987 - val_loss: 0.4462\n",
      "Epoch 84/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7796 - loss: 0.4584 - val_accuracy: 0.7987 - val_loss: 0.4462\n",
      "Epoch 85/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7866 - loss: 0.4454 - val_accuracy: 0.7987 - val_loss: 0.4461\n",
      "Epoch 86/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.4271 - val_accuracy: 0.7987 - val_loss: 0.4462\n",
      "Epoch 87/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7851 - loss: 0.4472 - val_accuracy: 0.7922 - val_loss: 0.4463\n",
      "Epoch 88/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7721 - loss: 0.4680 - val_accuracy: 0.7922 - val_loss: 0.4463\n",
      "Epoch 89/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7991 - loss: 0.4161 - val_accuracy: 0.7922 - val_loss: 0.4462\n",
      "Epoch 90/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7852 - loss: 0.4619 - val_accuracy: 0.7922 - val_loss: 0.4462\n",
      "Epoch 91/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.4425 - val_accuracy: 0.7922 - val_loss: 0.4462\n",
      "Epoch 92/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7771 - loss: 0.4629 - val_accuracy: 0.7922 - val_loss: 0.4461\n",
      "Epoch 93/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7940 - loss: 0.4425 - val_accuracy: 0.7922 - val_loss: 0.4462\n",
      "Epoch 94/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7854 - loss: 0.4591 - val_accuracy: 0.7922 - val_loss: 0.4461\n",
      "Epoch 95/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7735 - loss: 0.4425 - val_accuracy: 0.7922 - val_loss: 0.4461\n",
      "Epoch 96/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7847 - loss: 0.4622 - val_accuracy: 0.7922 - val_loss: 0.4461\n",
      "Epoch 97/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.4301 - val_accuracy: 0.7987 - val_loss: 0.4457\n",
      "Epoch 98/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7877 - loss: 0.4471 - val_accuracy: 0.7922 - val_loss: 0.4459\n",
      "Epoch 99/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7810 - loss: 0.4637 - val_accuracy: 0.7922 - val_loss: 0.4459\n",
      "Epoch 100/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7895 - loss: 0.4503 - val_accuracy: 0.7987 - val_loss: 0.4459\n",
      "Epoch 101/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7616 - loss: 0.4631 - val_accuracy: 0.7987 - val_loss: 0.4457\n",
      "Epoch 102/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7767 - loss: 0.4454 - val_accuracy: 0.7987 - val_loss: 0.4457\n",
      "Epoch 103/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7908 - loss: 0.4609 - val_accuracy: 0.7987 - val_loss: 0.4457\n",
      "Epoch 104/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7722 - loss: 0.4702 - val_accuracy: 0.7987 - val_loss: 0.4458\n",
      "Epoch 105/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7817 - loss: 0.4715 - val_accuracy: 0.7922 - val_loss: 0.4460\n",
      "Epoch 106/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7717 - loss: 0.4609 - val_accuracy: 0.7987 - val_loss: 0.4459\n",
      "Epoch 107/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4361 - val_accuracy: 0.7922 - val_loss: 0.4459\n",
      "Epoch 108/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7644 - loss: 0.4505 - val_accuracy: 0.7922 - val_loss: 0.4460\n",
      "Epoch 109/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7871 - loss: 0.4397 - val_accuracy: 0.7922 - val_loss: 0.4458\n",
      "Epoch 110/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8095 - loss: 0.4073 - val_accuracy: 0.7922 - val_loss: 0.4459\n",
      "Epoch 111/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7865 - loss: 0.4483 - val_accuracy: 0.7922 - val_loss: 0.4457\n",
      "Epoch 112/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7655 - loss: 0.4578 - val_accuracy: 0.7922 - val_loss: 0.4458\n",
      "Epoch 113/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7995 - loss: 0.4115 - val_accuracy: 0.8052 - val_loss: 0.4457\n",
      "Epoch 114/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.4147 - val_accuracy: 0.7987 - val_loss: 0.4456\n",
      "Epoch 115/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7766 - loss: 0.4422 - val_accuracy: 0.7987 - val_loss: 0.4458\n",
      "Epoch 116/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.4631 - val_accuracy: 0.8052 - val_loss: 0.4454\n",
      "Epoch 117/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7951 - loss: 0.4166 - val_accuracy: 0.8052 - val_loss: 0.4455\n",
      "Epoch 118/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.4429 - val_accuracy: 0.8052 - val_loss: 0.4455\n",
      "Epoch 119/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.4392 - val_accuracy: 0.8052 - val_loss: 0.4452\n",
      "Epoch 120/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7784 - loss: 0.4358 - val_accuracy: 0.8117 - val_loss: 0.4456\n",
      "Epoch 121/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7655 - loss: 0.4637 - val_accuracy: 0.8052 - val_loss: 0.4455\n",
      "Epoch 122/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7950 - loss: 0.4378 - val_accuracy: 0.8052 - val_loss: 0.4454\n",
      "Epoch 123/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7852 - loss: 0.4516 - val_accuracy: 0.8052 - val_loss: 0.4450\n",
      "Epoch 124/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7847 - loss: 0.4561 - val_accuracy: 0.8052 - val_loss: 0.4448\n",
      "Epoch 125/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7628 - loss: 0.4569 - val_accuracy: 0.8052 - val_loss: 0.4449\n",
      "Epoch 126/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7993 - loss: 0.4182 - val_accuracy: 0.8117 - val_loss: 0.4451\n",
      "Epoch 127/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7604 - loss: 0.4654 - val_accuracy: 0.8117 - val_loss: 0.4451\n",
      "Epoch 128/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: 0.4307 - val_accuracy: 0.8117 - val_loss: 0.4451\n",
      "Epoch 129/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7696 - loss: 0.4559 - val_accuracy: 0.8117 - val_loss: 0.4448\n",
      "Epoch 130/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.4376 - val_accuracy: 0.8052 - val_loss: 0.4447\n",
      "Epoch 131/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.4166 - val_accuracy: 0.8117 - val_loss: 0.4448\n",
      "Epoch 132/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7863 - loss: 0.4324 - val_accuracy: 0.8117 - val_loss: 0.4448\n",
      "Epoch 133/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7810 - loss: 0.4642 - val_accuracy: 0.8117 - val_loss: 0.4449\n",
      "Epoch 134/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7822 - loss: 0.4336 - val_accuracy: 0.8117 - val_loss: 0.4452\n",
      "Epoch 135/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7814 - loss: 0.4400 - val_accuracy: 0.8117 - val_loss: 0.4453\n",
      "Epoch 136/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7845 - loss: 0.4307 - val_accuracy: 0.8117 - val_loss: 0.4454\n",
      "Epoch 137/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7657 - loss: 0.4606 - val_accuracy: 0.8117 - val_loss: 0.4454\n",
      "Epoch 138/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7751 - loss: 0.4530 - val_accuracy: 0.8117 - val_loss: 0.4453\n",
      "Epoch 139/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7653 - loss: 0.4685 - val_accuracy: 0.8117 - val_loss: 0.4448\n",
      "Epoch 140/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7907 - loss: 0.4306 - val_accuracy: 0.8117 - val_loss: 0.4448\n",
      "Epoch 141/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.4542 - val_accuracy: 0.8117 - val_loss: 0.4446\n",
      "Epoch 142/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7888 - loss: 0.4317 - val_accuracy: 0.8117 - val_loss: 0.4446\n",
      "Epoch 143/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4378 - val_accuracy: 0.8117 - val_loss: 0.4450\n",
      "Epoch 144/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.4477 - val_accuracy: 0.8117 - val_loss: 0.4454\n",
      "Epoch 145/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7919 - loss: 0.4311 - val_accuracy: 0.8052 - val_loss: 0.4454\n",
      "Epoch 146/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7630 - loss: 0.4675 - val_accuracy: 0.8052 - val_loss: 0.4456\n",
      "Epoch 147/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.4160 - val_accuracy: 0.8052 - val_loss: 0.4454\n",
      "Epoch 148/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7851 - loss: 0.4282 - val_accuracy: 0.7987 - val_loss: 0.4455\n",
      "Epoch 149/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.3828 - val_accuracy: 0.8052 - val_loss: 0.4452\n",
      "Epoch 150/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.4294 - val_accuracy: 0.8117 - val_loss: 0.4457\n",
      "Epoch 151/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.4374 - val_accuracy: 0.8117 - val_loss: 0.4458\n",
      "Epoch 152/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7636 - loss: 0.4640 - val_accuracy: 0.8117 - val_loss: 0.4458\n",
      "Epoch 153/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.4333 - val_accuracy: 0.8117 - val_loss: 0.4459\n",
      "Epoch 154/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.4452 - val_accuracy: 0.8117 - val_loss: 0.4457\n",
      "Epoch 155/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.4374 - val_accuracy: 0.8117 - val_loss: 0.4457\n",
      "Epoch 156/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7811 - loss: 0.4465 - val_accuracy: 0.8182 - val_loss: 0.4457\n",
      "Epoch 157/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8012 - loss: 0.4060 - val_accuracy: 0.8117 - val_loss: 0.4458\n",
      "Epoch 158/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.4366 - val_accuracy: 0.8117 - val_loss: 0.4456\n",
      "Epoch 159/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7623 - loss: 0.4554 - val_accuracy: 0.8117 - val_loss: 0.4455\n",
      "Epoch 160/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7708 - loss: 0.4401 - val_accuracy: 0.8052 - val_loss: 0.4455\n",
      "Epoch 161/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.4346 - val_accuracy: 0.8117 - val_loss: 0.4459\n",
      "Epoch 162/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7845 - loss: 0.4284 - val_accuracy: 0.8117 - val_loss: 0.4459\n",
      "Epoch 163/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7609 - loss: 0.4604 - val_accuracy: 0.8117 - val_loss: 0.4457\n",
      "Epoch 164/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7937 - loss: 0.4384 - val_accuracy: 0.8182 - val_loss: 0.4457\n",
      "Epoch 165/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7922 - loss: 0.4386 - val_accuracy: 0.8182 - val_loss: 0.4457\n",
      "Epoch 166/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7874 - loss: 0.4358 - val_accuracy: 0.8052 - val_loss: 0.4459\n",
      "Epoch 167/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7745 - loss: 0.4381 - val_accuracy: 0.8182 - val_loss: 0.4458\n",
      "Epoch 168/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7553 - loss: 0.4670 - val_accuracy: 0.8182 - val_loss: 0.4459\n",
      "Epoch 169/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.4049 - val_accuracy: 0.8052 - val_loss: 0.4459\n",
      "Epoch 170/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.4335 - val_accuracy: 0.8052 - val_loss: 0.4461\n",
      "Epoch 171/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7753 - loss: 0.4329 - val_accuracy: 0.8117 - val_loss: 0.4457\n",
      "Epoch 172/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.4288 - val_accuracy: 0.8052 - val_loss: 0.4458\n",
      "Epoch 173/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7875 - loss: 0.4527 - val_accuracy: 0.8117 - val_loss: 0.4457\n",
      "Epoch 174/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7839 - loss: 0.4541 - val_accuracy: 0.8117 - val_loss: 0.4458\n",
      "Epoch 175/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.3887 - val_accuracy: 0.8052 - val_loss: 0.4461\n",
      "Epoch 176/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7712 - loss: 0.4495 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 177/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7841 - loss: 0.4544 - val_accuracy: 0.8052 - val_loss: 0.4462\n",
      "Epoch 178/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7888 - loss: 0.4248 - val_accuracy: 0.8052 - val_loss: 0.4466\n",
      "Epoch 179/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7898 - loss: 0.4346 - val_accuracy: 0.8052 - val_loss: 0.4466\n",
      "Epoch 180/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7746 - loss: 0.4431 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 181/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7718 - loss: 0.4662 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 182/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.4356 - val_accuracy: 0.8052 - val_loss: 0.4466\n",
      "Epoch 183/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7900 - loss: 0.4543 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 184/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8138 - loss: 0.4142 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 185/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.4169 - val_accuracy: 0.8052 - val_loss: 0.4462\n",
      "Epoch 186/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7971 - loss: 0.4352 - val_accuracy: 0.8117 - val_loss: 0.4465\n",
      "Epoch 187/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7869 - loss: 0.4444 - val_accuracy: 0.8052 - val_loss: 0.4466\n",
      "Epoch 188/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7830 - loss: 0.4312 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 189/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.4546 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 190/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8153 - loss: 0.4033 - val_accuracy: 0.8052 - val_loss: 0.4470\n",
      "Epoch 191/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4115 - val_accuracy: 0.8052 - val_loss: 0.4471\n",
      "Epoch 192/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.4165 - val_accuracy: 0.8052 - val_loss: 0.4467\n",
      "Epoch 193/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7783 - loss: 0.4369 - val_accuracy: 0.8052 - val_loss: 0.4463\n",
      "Epoch 194/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7837 - loss: 0.4381 - val_accuracy: 0.8052 - val_loss: 0.4463\n",
      "Epoch 195/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7842 - loss: 0.4460 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 196/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7833 - loss: 0.4368 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 197/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7670 - loss: 0.4605 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 198/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7898 - loss: 0.4515 - val_accuracy: 0.8052 - val_loss: 0.4466\n",
      "Epoch 199/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7782 - loss: 0.4504 - val_accuracy: 0.8052 - val_loss: 0.4467\n",
      "Epoch 200/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.4471 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 201/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.4346 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 202/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.4128 - val_accuracy: 0.8052 - val_loss: 0.4466\n",
      "Epoch 203/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4114 - val_accuracy: 0.8052 - val_loss: 0.4467\n",
      "Epoch 204/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.4632 - val_accuracy: 0.8052 - val_loss: 0.4466\n",
      "Epoch 205/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.4203 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 206/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7955 - loss: 0.4284 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 207/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.3967 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 208/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.4318 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 209/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7983 - loss: 0.4268 - val_accuracy: 0.8117 - val_loss: 0.4464\n",
      "Epoch 210/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: 0.4333 - val_accuracy: 0.8117 - val_loss: 0.4466\n",
      "Epoch 211/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7990 - loss: 0.4380 - val_accuracy: 0.8117 - val_loss: 0.4462\n",
      "Epoch 212/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7793 - loss: 0.4583 - val_accuracy: 0.8117 - val_loss: 0.4462\n",
      "Epoch 213/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.4300 - val_accuracy: 0.8117 - val_loss: 0.4463\n",
      "Epoch 214/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7866 - loss: 0.4335 - val_accuracy: 0.8117 - val_loss: 0.4463\n",
      "Epoch 215/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.4316 - val_accuracy: 0.8117 - val_loss: 0.4462\n",
      "Epoch 216/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7999 - loss: 0.4179 - val_accuracy: 0.8182 - val_loss: 0.4462\n",
      "Epoch 217/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.4274 - val_accuracy: 0.8117 - val_loss: 0.4460\n",
      "Epoch 218/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.4588 - val_accuracy: 0.8117 - val_loss: 0.4462\n",
      "Epoch 219/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.4506 - val_accuracy: 0.8117 - val_loss: 0.4462\n",
      "Epoch 220/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8063 - loss: 0.4091 - val_accuracy: 0.8117 - val_loss: 0.4462\n",
      "Epoch 221/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8040 - loss: 0.4350 - val_accuracy: 0.8117 - val_loss: 0.4460\n",
      "Epoch 222/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.4317 - val_accuracy: 0.8117 - val_loss: 0.4452\n",
      "Epoch 223/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8022 - loss: 0.4366 - val_accuracy: 0.8117 - val_loss: 0.4452\n",
      "Epoch 224/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7648 - loss: 0.4538 - val_accuracy: 0.8117 - val_loss: 0.4453\n",
      "Epoch 225/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8150 - loss: 0.3868 - val_accuracy: 0.8117 - val_loss: 0.4453\n",
      "Epoch 226/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.4247 - val_accuracy: 0.8117 - val_loss: 0.4455\n",
      "Epoch 227/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7659 - loss: 0.4538 - val_accuracy: 0.8117 - val_loss: 0.4448\n",
      "Epoch 228/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7925 - loss: 0.4287 - val_accuracy: 0.8182 - val_loss: 0.4445\n",
      "Epoch 229/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7743 - loss: 0.4568 - val_accuracy: 0.8117 - val_loss: 0.4445\n",
      "Epoch 230/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7716 - loss: 0.4435 - val_accuracy: 0.8117 - val_loss: 0.4446\n",
      "Epoch 231/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7921 - loss: 0.4316 - val_accuracy: 0.8117 - val_loss: 0.4449\n",
      "Epoch 232/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7842 - loss: 0.4603 - val_accuracy: 0.8117 - val_loss: 0.4446\n",
      "Epoch 233/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7610 - loss: 0.4620 - val_accuracy: 0.8117 - val_loss: 0.4446\n",
      "Epoch 234/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 0.4545 - val_accuracy: 0.8182 - val_loss: 0.4447\n",
      "Epoch 235/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.4054 - val_accuracy: 0.8117 - val_loss: 0.4450\n",
      "Epoch 236/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7797 - loss: 0.4486 - val_accuracy: 0.8182 - val_loss: 0.4453\n",
      "Epoch 237/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7837 - loss: 0.4346 - val_accuracy: 0.8117 - val_loss: 0.4454\n",
      "Epoch 238/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7875 - loss: 0.4414 - val_accuracy: 0.8117 - val_loss: 0.4453\n",
      "Epoch 239/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8008 - loss: 0.4503 - val_accuracy: 0.8052 - val_loss: 0.4458\n",
      "Epoch 240/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.4579 - val_accuracy: 0.8052 - val_loss: 0.4462\n",
      "Epoch 241/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.4342 - val_accuracy: 0.8052 - val_loss: 0.4463\n",
      "Epoch 242/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.4270 - val_accuracy: 0.8052 - val_loss: 0.4463\n",
      "Epoch 243/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: 0.4273 - val_accuracy: 0.8052 - val_loss: 0.4462\n",
      "Epoch 244/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7868 - loss: 0.4389 - val_accuracy: 0.8052 - val_loss: 0.4467\n",
      "Epoch 245/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7792 - loss: 0.4361 - val_accuracy: 0.8052 - val_loss: 0.4468\n",
      "Epoch 246/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7762 - loss: 0.4469 - val_accuracy: 0.8052 - val_loss: 0.4468\n",
      "Epoch 247/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.4601 - val_accuracy: 0.8052 - val_loss: 0.4467\n",
      "Epoch 248/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4195 - val_accuracy: 0.8052 - val_loss: 0.4466\n",
      "Epoch 249/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4306 - val_accuracy: 0.8052 - val_loss: 0.4469\n",
      "Epoch 250/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.4267 - val_accuracy: 0.8052 - val_loss: 0.4467\n",
      "Epoch 251/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7865 - loss: 0.4401 - val_accuracy: 0.8052 - val_loss: 0.4462\n",
      "Epoch 252/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.4542 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 253/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.4237 - val_accuracy: 0.8052 - val_loss: 0.4462\n",
      "Epoch 254/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7837 - loss: 0.4410 - val_accuracy: 0.8052 - val_loss: 0.4461\n",
      "Epoch 255/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.4388 - val_accuracy: 0.8052 - val_loss: 0.4461\n",
      "Epoch 256/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.4156 - val_accuracy: 0.8052 - val_loss: 0.4460\n",
      "Epoch 257/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.4382 - val_accuracy: 0.8052 - val_loss: 0.4458\n",
      "Epoch 258/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7731 - loss: 0.4493 - val_accuracy: 0.8052 - val_loss: 0.4458\n",
      "Epoch 259/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7917 - loss: 0.4450 - val_accuracy: 0.8052 - val_loss: 0.4458\n",
      "Epoch 260/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.4201 - val_accuracy: 0.8052 - val_loss: 0.4458\n",
      "Epoch 261/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.3939 - val_accuracy: 0.8052 - val_loss: 0.4458\n",
      "Epoch 262/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8130 - loss: 0.4074 - val_accuracy: 0.8052 - val_loss: 0.4460\n",
      "Epoch 263/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7754 - loss: 0.4347 - val_accuracy: 0.8052 - val_loss: 0.4460\n",
      "Epoch 264/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7816 - loss: 0.4465 - val_accuracy: 0.8052 - val_loss: 0.4460\n",
      "Epoch 265/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7691 - loss: 0.4441 - val_accuracy: 0.8117 - val_loss: 0.4462\n",
      "Epoch 266/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7792 - loss: 0.4317 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 267/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.4440 - val_accuracy: 0.8052 - val_loss: 0.4463\n",
      "Epoch 268/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7904 - loss: 0.4208 - val_accuracy: 0.8117 - val_loss: 0.4465\n",
      "Epoch 269/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8098 - loss: 0.4026 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 270/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4183 - val_accuracy: 0.8052 - val_loss: 0.4466\n",
      "Epoch 271/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.4235 - val_accuracy: 0.8052 - val_loss: 0.4466\n",
      "Epoch 272/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.4262 - val_accuracy: 0.8052 - val_loss: 0.4470\n",
      "Epoch 273/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7814 - loss: 0.4217 - val_accuracy: 0.8117 - val_loss: 0.4473\n",
      "Epoch 274/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7912 - loss: 0.4515 - val_accuracy: 0.8052 - val_loss: 0.4472\n",
      "Epoch 275/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7815 - loss: 0.4483 - val_accuracy: 0.8052 - val_loss: 0.4469\n",
      "Epoch 276/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.4349 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 277/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.4158 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 278/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8139 - loss: 0.4115 - val_accuracy: 0.8052 - val_loss: 0.4465\n",
      "Epoch 279/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8003 - loss: 0.4298 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 280/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.4350 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 281/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.4243 - val_accuracy: 0.8052 - val_loss: 0.4463\n",
      "Epoch 282/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7914 - loss: 0.4529 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 283/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7794 - loss: 0.4537 - val_accuracy: 0.8052 - val_loss: 0.4468\n",
      "Epoch 284/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.4292 - val_accuracy: 0.8052 - val_loss: 0.4467\n",
      "Epoch 285/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.4324 - val_accuracy: 0.8052 - val_loss: 0.4463\n",
      "Epoch 286/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.4259 - val_accuracy: 0.8052 - val_loss: 0.4460\n",
      "Epoch 287/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7813 - loss: 0.4405 - val_accuracy: 0.8052 - val_loss: 0.4461\n",
      "Epoch 288/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.4317 - val_accuracy: 0.8052 - val_loss: 0.4463\n",
      "Epoch 289/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7873 - loss: 0.4382 - val_accuracy: 0.8117 - val_loss: 0.4464\n",
      "Epoch 290/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.3991 - val_accuracy: 0.8052 - val_loss: 0.4464\n",
      "Epoch 291/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7891 - loss: 0.4303 - val_accuracy: 0.8052 - val_loss: 0.4458\n",
      "Epoch 292/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8035 - loss: 0.4191 - val_accuracy: 0.8052 - val_loss: 0.4457\n",
      "Epoch 293/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7845 - loss: 0.4489 - val_accuracy: 0.8117 - val_loss: 0.4459\n",
      "Epoch 294/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.3857 - val_accuracy: 0.8117 - val_loss: 0.4460\n",
      "Epoch 295/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7943 - loss: 0.4326 - val_accuracy: 0.8117 - val_loss: 0.4460\n",
      "Epoch 296/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.4142 - val_accuracy: 0.8052 - val_loss: 0.4461\n",
      "Epoch 297/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.4377 - val_accuracy: 0.8117 - val_loss: 0.4460\n",
      "Epoch 298/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7875 - loss: 0.4414 - val_accuracy: 0.8052 - val_loss: 0.4461\n",
      "Epoch 299/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7884 - loss: 0.4434 - val_accuracy: 0.8052 - val_loss: 0.4459\n",
      "Epoch 300/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4169 - val_accuracy: 0.8117 - val_loss: 0.4455\n",
      "Epoch 301/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7815 - loss: 0.4521 - val_accuracy: 0.8052 - val_loss: 0.4457\n",
      "Epoch 302/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7889 - loss: 0.4343 - val_accuracy: 0.8052 - val_loss: 0.4455\n",
      "Epoch 303/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.3985 - val_accuracy: 0.8117 - val_loss: 0.4457\n",
      "Epoch 304/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7828 - loss: 0.4437 - val_accuracy: 0.8117 - val_loss: 0.4455\n",
      "Epoch 305/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.4213 - val_accuracy: 0.8117 - val_loss: 0.4460\n",
      "Epoch 306/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.4376 - val_accuracy: 0.8052 - val_loss: 0.4458\n",
      "Epoch 307/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.4106 - val_accuracy: 0.8052 - val_loss: 0.4456\n",
      "Epoch 308/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.3932 - val_accuracy: 0.8052 - val_loss: 0.4453\n",
      "Epoch 309/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7762 - loss: 0.4509 - val_accuracy: 0.8052 - val_loss: 0.4457\n",
      "Epoch 310/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 0.4175 - val_accuracy: 0.8052 - val_loss: 0.4455\n",
      "Epoch 311/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7993 - loss: 0.4198 - val_accuracy: 0.8052 - val_loss: 0.4461\n",
      "Epoch 312/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8217 - loss: 0.4045 - val_accuracy: 0.8052 - val_loss: 0.4460\n",
      "Epoch 313/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.3905 - val_accuracy: 0.8052 - val_loss: 0.4462\n",
      "Epoch 314/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.4389 - val_accuracy: 0.8052 - val_loss: 0.4461\n",
      "Epoch 315/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.4191 - val_accuracy: 0.8052 - val_loss: 0.4459\n",
      "Epoch 316/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.4212 - val_accuracy: 0.8052 - val_loss: 0.4456\n",
      "Epoch 317/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.4326 - val_accuracy: 0.8052 - val_loss: 0.4458\n",
      "Epoch 318/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.4370 - val_accuracy: 0.8052 - val_loss: 0.4456\n",
      "Epoch 319/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7842 - loss: 0.4447 - val_accuracy: 0.8052 - val_loss: 0.4456\n",
      "Epoch 320/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.3991 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 321/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7753 - loss: 0.4621 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 322/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.4281 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 323/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7736 - loss: 0.4485 - val_accuracy: 0.8117 - val_loss: 0.4454\n",
      "Epoch 324/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7985 - loss: 0.4318 - val_accuracy: 0.8117 - val_loss: 0.4452\n",
      "Epoch 325/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7766 - loss: 0.4612 - val_accuracy: 0.8117 - val_loss: 0.4451\n",
      "Epoch 326/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8252 - loss: 0.4013 - val_accuracy: 0.8052 - val_loss: 0.4452\n",
      "Epoch 327/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8009 - loss: 0.3965 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 328/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7891 - loss: 0.4299 - val_accuracy: 0.8052 - val_loss: 0.4449\n",
      "Epoch 329/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7824 - loss: 0.4398 - val_accuracy: 0.8052 - val_loss: 0.4450\n",
      "Epoch 330/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.4202 - val_accuracy: 0.8052 - val_loss: 0.4449\n",
      "Epoch 331/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.4069 - val_accuracy: 0.8052 - val_loss: 0.4449\n",
      "Epoch 332/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7902 - loss: 0.4275 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 333/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7900 - loss: 0.4309 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 334/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.4191 - val_accuracy: 0.8052 - val_loss: 0.4455\n",
      "Epoch 335/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4354 - val_accuracy: 0.8052 - val_loss: 0.4457\n",
      "Epoch 336/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.4394 - val_accuracy: 0.8052 - val_loss: 0.4457\n",
      "Epoch 337/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.3883 - val_accuracy: 0.8052 - val_loss: 0.4456\n",
      "Epoch 338/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.4114 - val_accuracy: 0.8052 - val_loss: 0.4456\n",
      "Epoch 339/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4100 - val_accuracy: 0.8052 - val_loss: 0.4454\n",
      "Epoch 340/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7716 - loss: 0.4389 - val_accuracy: 0.8052 - val_loss: 0.4455\n",
      "Epoch 341/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4144 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 342/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4147 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 343/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7939 - loss: 0.4244 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 344/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: 0.4679 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 345/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.4163 - val_accuracy: 0.8052 - val_loss: 0.4452\n",
      "Epoch 346/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4112 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 347/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.4362 - val_accuracy: 0.8052 - val_loss: 0.4452\n",
      "Epoch 348/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7901 - loss: 0.4330 - val_accuracy: 0.8052 - val_loss: 0.4450\n",
      "Epoch 349/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8019 - loss: 0.4212 - val_accuracy: 0.8052 - val_loss: 0.4453\n",
      "Epoch 350/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7900 - loss: 0.4123 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 351/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.4168 - val_accuracy: 0.8052 - val_loss: 0.4451\n",
      "Epoch 352/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.4306 - val_accuracy: 0.8052 - val_loss: 0.4453\n",
      "Epoch 353/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4176 - val_accuracy: 0.8117 - val_loss: 0.4454\n",
      "Epoch 354/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7840 - loss: 0.4329 - val_accuracy: 0.8052 - val_loss: 0.4452\n",
      "Epoch 355/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8116 - loss: 0.4322 - val_accuracy: 0.8052 - val_loss: 0.4448\n",
      "Epoch 356/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7986 - loss: 0.4009 - val_accuracy: 0.8117 - val_loss: 0.4451\n",
      "Epoch 357/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8203 - loss: 0.4071 - val_accuracy: 0.8117 - val_loss: 0.4453\n",
      "Epoch 358/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4200 - val_accuracy: 0.8182 - val_loss: 0.4453\n",
      "Epoch 359/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.4572 - val_accuracy: 0.8117 - val_loss: 0.4458\n",
      "Epoch 360/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.4153 - val_accuracy: 0.8182 - val_loss: 0.4458\n",
      "Epoch 361/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7928 - loss: 0.4395 - val_accuracy: 0.8182 - val_loss: 0.4460\n",
      "Epoch 362/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8004 - loss: 0.4053 - val_accuracy: 0.8117 - val_loss: 0.4461\n",
      "Epoch 363/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.4219 - val_accuracy: 0.8182 - val_loss: 0.4455\n",
      "Epoch 364/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.4197 - val_accuracy: 0.8117 - val_loss: 0.4459\n",
      "Epoch 365/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8022 - loss: 0.4275 - val_accuracy: 0.8117 - val_loss: 0.4460\n",
      "Epoch 366/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.4272 - val_accuracy: 0.8117 - val_loss: 0.4463\n",
      "Epoch 367/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7968 - loss: 0.4397 - val_accuracy: 0.8117 - val_loss: 0.4461\n",
      "Epoch 368/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7859 - loss: 0.4424 - val_accuracy: 0.8117 - val_loss: 0.4465\n",
      "Epoch 369/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8005 - loss: 0.4296 - val_accuracy: 0.8117 - val_loss: 0.4470\n",
      "Epoch 370/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.3978 - val_accuracy: 0.8182 - val_loss: 0.4466\n",
      "Epoch 371/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7973 - loss: 0.4356 - val_accuracy: 0.8117 - val_loss: 0.4466\n",
      "Epoch 372/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.4307 - val_accuracy: 0.8117 - val_loss: 0.4468\n",
      "Epoch 373/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7944 - loss: 0.4098 - val_accuracy: 0.8117 - val_loss: 0.4467\n",
      "Epoch 374/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7824 - loss: 0.4549 - val_accuracy: 0.8117 - val_loss: 0.4466\n",
      "Epoch 375/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8284 - loss: 0.3914 - val_accuracy: 0.8052 - val_loss: 0.4473\n",
      "Epoch 376/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.4226 - val_accuracy: 0.8117 - val_loss: 0.4469\n",
      "Epoch 377/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.3940 - val_accuracy: 0.8117 - val_loss: 0.4470\n",
      "Epoch 378/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4337 - val_accuracy: 0.8117 - val_loss: 0.4470\n",
      "Epoch 379/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3992 - val_accuracy: 0.8117 - val_loss: 0.4469\n",
      "Epoch 380/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4284 - val_accuracy: 0.8117 - val_loss: 0.4469\n",
      "Epoch 381/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.4015 - val_accuracy: 0.8117 - val_loss: 0.4465\n",
      "Epoch 382/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.4172 - val_accuracy: 0.8117 - val_loss: 0.4467\n",
      "Epoch 383/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8203 - loss: 0.4284 - val_accuracy: 0.8182 - val_loss: 0.4463\n",
      "Epoch 384/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8038 - loss: 0.4268 - val_accuracy: 0.8182 - val_loss: 0.4459\n",
      "Epoch 385/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.3965 - val_accuracy: 0.8182 - val_loss: 0.4463\n",
      "Epoch 386/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.4269 - val_accuracy: 0.8182 - val_loss: 0.4463\n",
      "Epoch 387/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8258 - loss: 0.4100 - val_accuracy: 0.8182 - val_loss: 0.4461\n",
      "Epoch 388/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.4610 - val_accuracy: 0.8182 - val_loss: 0.4463\n",
      "Epoch 389/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8115 - loss: 0.4077 - val_accuracy: 0.8182 - val_loss: 0.4460\n",
      "Epoch 390/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.4079 - val_accuracy: 0.8182 - val_loss: 0.4461\n",
      "Epoch 391/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7948 - loss: 0.4233 - val_accuracy: 0.8182 - val_loss: 0.4460\n",
      "Epoch 392/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.4024 - val_accuracy: 0.8117 - val_loss: 0.4462\n",
      "Epoch 393/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8254 - loss: 0.4208 - val_accuracy: 0.8117 - val_loss: 0.4463\n",
      "Epoch 394/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8273 - loss: 0.3867 - val_accuracy: 0.8117 - val_loss: 0.4461\n",
      "Epoch 395/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4275 - val_accuracy: 0.8117 - val_loss: 0.4461\n",
      "Epoch 396/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.4012 - val_accuracy: 0.8117 - val_loss: 0.4462\n",
      "Epoch 397/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.4262 - val_accuracy: 0.8117 - val_loss: 0.4459\n",
      "Epoch 398/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8097 - loss: 0.4236 - val_accuracy: 0.8182 - val_loss: 0.4459\n",
      "Epoch 399/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.4212 - val_accuracy: 0.8117 - val_loss: 0.4458\n",
      "Epoch 400/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.4385 - val_accuracy: 0.8182 - val_loss: 0.4460\n",
      "Epoch 401/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7996 - loss: 0.4370 - val_accuracy: 0.8247 - val_loss: 0.4461\n",
      "Epoch 402/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.4101 - val_accuracy: 0.8247 - val_loss: 0.4462\n",
      "Epoch 403/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7997 - loss: 0.4405 - val_accuracy: 0.8247 - val_loss: 0.4460\n",
      "Epoch 404/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.4273 - val_accuracy: 0.8247 - val_loss: 0.4459\n",
      "Epoch 405/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8212 - loss: 0.4098 - val_accuracy: 0.8247 - val_loss: 0.4462\n",
      "Epoch 406/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.3900 - val_accuracy: 0.8247 - val_loss: 0.4463\n",
      "Epoch 407/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8003 - loss: 0.4415 - val_accuracy: 0.8247 - val_loss: 0.4463\n",
      "Epoch 408/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.3868 - val_accuracy: 0.8247 - val_loss: 0.4466\n",
      "Epoch 409/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.4098 - val_accuracy: 0.8182 - val_loss: 0.4471\n",
      "Epoch 410/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.4057 - val_accuracy: 0.8247 - val_loss: 0.4470\n",
      "Epoch 411/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.4012 - val_accuracy: 0.8247 - val_loss: 0.4472\n",
      "Epoch 412/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.4365 - val_accuracy: 0.8182 - val_loss: 0.4476\n",
      "Epoch 413/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4243 - val_accuracy: 0.8182 - val_loss: 0.4477\n",
      "Epoch 414/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7864 - loss: 0.4682 - val_accuracy: 0.8182 - val_loss: 0.4476\n",
      "Epoch 415/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.4280 - val_accuracy: 0.8182 - val_loss: 0.4473\n",
      "Epoch 416/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4152 - val_accuracy: 0.8182 - val_loss: 0.4472\n",
      "Epoch 417/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.4198 - val_accuracy: 0.8247 - val_loss: 0.4472\n",
      "Epoch 418/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.4375 - val_accuracy: 0.8247 - val_loss: 0.4470\n",
      "Epoch 419/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8135 - loss: 0.4328 - val_accuracy: 0.8247 - val_loss: 0.4470\n",
      "Epoch 420/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8155 - loss: 0.4325 - val_accuracy: 0.8247 - val_loss: 0.4473\n",
      "Epoch 421/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.3912 - val_accuracy: 0.8247 - val_loss: 0.4469\n",
      "Epoch 422/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.4077 - val_accuracy: 0.8247 - val_loss: 0.4469\n",
      "Epoch 423/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8077 - loss: 0.4223 - val_accuracy: 0.8247 - val_loss: 0.4468\n",
      "Epoch 424/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8413 - loss: 0.3852 - val_accuracy: 0.8182 - val_loss: 0.4477\n",
      "Epoch 425/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.4000 - val_accuracy: 0.8247 - val_loss: 0.4472\n",
      "Epoch 426/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8129 - loss: 0.4201 - val_accuracy: 0.8247 - val_loss: 0.4473\n",
      "Epoch 427/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.4226 - val_accuracy: 0.8182 - val_loss: 0.4484\n",
      "Epoch 428/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8116 - loss: 0.4116 - val_accuracy: 0.8182 - val_loss: 0.4482\n",
      "Epoch 429/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.4394 - val_accuracy: 0.8182 - val_loss: 0.4482\n",
      "Epoch 430/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.4205 - val_accuracy: 0.8247 - val_loss: 0.4480\n",
      "Epoch 431/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4204 - val_accuracy: 0.8182 - val_loss: 0.4477\n",
      "Epoch 432/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8294 - loss: 0.3958 - val_accuracy: 0.8247 - val_loss: 0.4480\n",
      "Epoch 433/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.4026 - val_accuracy: 0.8247 - val_loss: 0.4480\n",
      "Epoch 434/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.3819 - val_accuracy: 0.8247 - val_loss: 0.4482\n",
      "Epoch 435/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.4223 - val_accuracy: 0.8247 - val_loss: 0.4480\n",
      "Epoch 436/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8219 - loss: 0.4038 - val_accuracy: 0.8247 - val_loss: 0.4479\n",
      "Epoch 437/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.4450 - val_accuracy: 0.8247 - val_loss: 0.4476\n",
      "Epoch 438/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.4365 - val_accuracy: 0.8247 - val_loss: 0.4474\n",
      "Epoch 439/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.4124 - val_accuracy: 0.8182 - val_loss: 0.4480\n",
      "Epoch 440/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4188 - val_accuracy: 0.8182 - val_loss: 0.4482\n",
      "Epoch 441/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.4044 - val_accuracy: 0.8182 - val_loss: 0.4477\n",
      "Epoch 442/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.4277 - val_accuracy: 0.8247 - val_loss: 0.4477\n",
      "Epoch 443/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.4200 - val_accuracy: 0.8247 - val_loss: 0.4478\n",
      "Epoch 444/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.4109 - val_accuracy: 0.8247 - val_loss: 0.4478\n",
      "Epoch 445/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.4213 - val_accuracy: 0.8247 - val_loss: 0.4479\n",
      "Epoch 446/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.4106 - val_accuracy: 0.8247 - val_loss: 0.4481\n",
      "Epoch 447/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.4040 - val_accuracy: 0.8247 - val_loss: 0.4484\n",
      "Epoch 448/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.4310 - val_accuracy: 0.8247 - val_loss: 0.4484\n",
      "Epoch 449/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8047 - loss: 0.4172 - val_accuracy: 0.8247 - val_loss: 0.4483\n",
      "Epoch 450/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.4129 - val_accuracy: 0.8247 - val_loss: 0.4487\n",
      "Epoch 451/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8159 - loss: 0.4290 - val_accuracy: 0.8247 - val_loss: 0.4485\n",
      "Epoch 452/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4248 - val_accuracy: 0.8182 - val_loss: 0.4485\n",
      "Epoch 453/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7996 - loss: 0.4256 - val_accuracy: 0.8182 - val_loss: 0.4484\n",
      "Epoch 454/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.3773 - val_accuracy: 0.8182 - val_loss: 0.4485\n",
      "Epoch 455/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.3952 - val_accuracy: 0.8182 - val_loss: 0.4489\n",
      "Epoch 456/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8011 - loss: 0.4309 - val_accuracy: 0.8182 - val_loss: 0.4488\n",
      "Epoch 457/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3728 - val_accuracy: 0.8247 - val_loss: 0.4486\n",
      "Epoch 458/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8290 - loss: 0.3946 - val_accuracy: 0.8247 - val_loss: 0.4485\n",
      "Epoch 459/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7953 - loss: 0.4592 - val_accuracy: 0.8247 - val_loss: 0.4483\n",
      "Epoch 460/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8069 - loss: 0.4420 - val_accuracy: 0.8247 - val_loss: 0.4482\n",
      "Epoch 461/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.4347 - val_accuracy: 0.8247 - val_loss: 0.4478\n",
      "Epoch 462/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4162 - val_accuracy: 0.8247 - val_loss: 0.4480\n",
      "Epoch 463/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.4249 - val_accuracy: 0.8247 - val_loss: 0.4474\n",
      "Epoch 464/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4021 - val_accuracy: 0.8247 - val_loss: 0.4469\n",
      "Epoch 465/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4144 - val_accuracy: 0.8247 - val_loss: 0.4469\n",
      "Epoch 466/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.4348 - val_accuracy: 0.8247 - val_loss: 0.4477\n",
      "Epoch 467/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.4259 - val_accuracy: 0.8247 - val_loss: 0.4476\n",
      "Epoch 468/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4186 - val_accuracy: 0.8247 - val_loss: 0.4476\n",
      "Epoch 469/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.4303 - val_accuracy: 0.8247 - val_loss: 0.4472\n",
      "Epoch 470/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8235 - loss: 0.4024 - val_accuracy: 0.8247 - val_loss: 0.4472\n",
      "Epoch 471/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8370 - loss: 0.3771 - val_accuracy: 0.8247 - val_loss: 0.4469\n",
      "Epoch 472/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.4127 - val_accuracy: 0.8247 - val_loss: 0.4471\n",
      "Epoch 473/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8303 - loss: 0.4081 - val_accuracy: 0.8247 - val_loss: 0.4478\n",
      "Epoch 474/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.4096 - val_accuracy: 0.8247 - val_loss: 0.4478\n",
      "Epoch 475/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.4108 - val_accuracy: 0.8247 - val_loss: 0.4479\n",
      "Epoch 476/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8196 - loss: 0.3939 - val_accuracy: 0.8247 - val_loss: 0.4479\n",
      "Epoch 477/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.4093 - val_accuracy: 0.8182 - val_loss: 0.4479\n",
      "Epoch 478/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8163 - loss: 0.4223 - val_accuracy: 0.8182 - val_loss: 0.4480\n",
      "Epoch 479/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.3979 - val_accuracy: 0.8182 - val_loss: 0.4481\n",
      "Epoch 480/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7879 - loss: 0.4315 - val_accuracy: 0.8182 - val_loss: 0.4477\n",
      "Epoch 481/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.4142 - val_accuracy: 0.8182 - val_loss: 0.4478\n",
      "Epoch 482/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.4209 - val_accuracy: 0.8182 - val_loss: 0.4480\n",
      "Epoch 483/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4239 - val_accuracy: 0.8182 - val_loss: 0.4477\n",
      "Epoch 484/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8314 - loss: 0.3833 - val_accuracy: 0.8182 - val_loss: 0.4480\n",
      "Epoch 485/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8086 - loss: 0.4180 - val_accuracy: 0.8182 - val_loss: 0.4479\n",
      "Epoch 486/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.4316 - val_accuracy: 0.8182 - val_loss: 0.4474\n",
      "Epoch 487/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8312 - loss: 0.4093 - val_accuracy: 0.8182 - val_loss: 0.4479\n",
      "Epoch 488/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4364 - val_accuracy: 0.8182 - val_loss: 0.4479\n",
      "Epoch 489/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8095 - loss: 0.4161 - val_accuracy: 0.8182 - val_loss: 0.4481\n",
      "Epoch 490/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.4235 - val_accuracy: 0.8182 - val_loss: 0.4483\n",
      "Epoch 491/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4157 - val_accuracy: 0.8182 - val_loss: 0.4488\n",
      "Epoch 492/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4251 - val_accuracy: 0.8182 - val_loss: 0.4486\n",
      "Epoch 493/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.3909 - val_accuracy: 0.8182 - val_loss: 0.4488\n",
      "Epoch 494/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.4104 - val_accuracy: 0.8182 - val_loss: 0.4486\n",
      "Epoch 495/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.3929 - val_accuracy: 0.8182 - val_loss: 0.4489\n",
      "Epoch 496/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8120 - loss: 0.4156 - val_accuracy: 0.8182 - val_loss: 0.4490\n",
      "Epoch 497/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8153 - loss: 0.4084 - val_accuracy: 0.8182 - val_loss: 0.4493\n",
      "Epoch 498/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7998 - loss: 0.4479 - val_accuracy: 0.8182 - val_loss: 0.4495\n",
      "Epoch 499/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.4428 - val_accuracy: 0.8182 - val_loss: 0.4493\n",
      "Epoch 500/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8135 - loss: 0.4242 - val_accuracy: 0.8182 - val_loss: 0.4498\n",
      "Epoch 501/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 0.4202 - val_accuracy: 0.8182 - val_loss: 0.4499\n",
      "Epoch 502/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.4082 - val_accuracy: 0.8182 - val_loss: 0.4500\n",
      "Epoch 503/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8009 - loss: 0.4263 - val_accuracy: 0.8182 - val_loss: 0.4496\n",
      "Epoch 504/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.4211 - val_accuracy: 0.8182 - val_loss: 0.4492\n",
      "Epoch 505/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.4142 - val_accuracy: 0.8182 - val_loss: 0.4491\n",
      "Epoch 506/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8118 - loss: 0.4119 - val_accuracy: 0.8182 - val_loss: 0.4491\n",
      "Epoch 507/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4012 - val_accuracy: 0.8182 - val_loss: 0.4490\n",
      "Epoch 508/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.4219 - val_accuracy: 0.8182 - val_loss: 0.4492\n",
      "Epoch 509/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8252 - loss: 0.3959 - val_accuracy: 0.8182 - val_loss: 0.4497\n",
      "Epoch 510/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.4174 - val_accuracy: 0.8182 - val_loss: 0.4498\n",
      "Epoch 511/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.4106 - val_accuracy: 0.8182 - val_loss: 0.4501\n",
      "Epoch 512/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.3998 - val_accuracy: 0.8182 - val_loss: 0.4498\n",
      "Epoch 513/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.4393 - val_accuracy: 0.8182 - val_loss: 0.4501\n",
      "Epoch 514/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8091 - loss: 0.4521 - val_accuracy: 0.8182 - val_loss: 0.4499\n",
      "Epoch 515/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8223 - loss: 0.4106 - val_accuracy: 0.8182 - val_loss: 0.4498\n",
      "Epoch 516/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.3957 - val_accuracy: 0.8182 - val_loss: 0.4498\n",
      "Epoch 517/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.3920 - val_accuracy: 0.8182 - val_loss: 0.4497\n",
      "Epoch 518/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.4185 - val_accuracy: 0.8182 - val_loss: 0.4497\n",
      "Epoch 519/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7983 - loss: 0.4185 - val_accuracy: 0.8182 - val_loss: 0.4496\n",
      "Epoch 520/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7930 - loss: 0.4365 - val_accuracy: 0.8182 - val_loss: 0.4493\n",
      "Epoch 521/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8304 - loss: 0.3909 - val_accuracy: 0.8182 - val_loss: 0.4495\n",
      "Epoch 522/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.4092 - val_accuracy: 0.8182 - val_loss: 0.4495\n",
      "Epoch 523/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.4151 - val_accuracy: 0.8182 - val_loss: 0.4502\n",
      "Epoch 524/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8095 - loss: 0.4092 - val_accuracy: 0.8182 - val_loss: 0.4499\n",
      "Epoch 525/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.4166 - val_accuracy: 0.8182 - val_loss: 0.4497\n",
      "Epoch 526/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8317 - loss: 0.4102 - val_accuracy: 0.8182 - val_loss: 0.4499\n",
      "Epoch 527/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8284 - loss: 0.3970 - val_accuracy: 0.8182 - val_loss: 0.4499\n",
      "Epoch 528/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8015 - loss: 0.4269 - val_accuracy: 0.8182 - val_loss: 0.4502\n",
      "Epoch 529/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8005 - loss: 0.4383 - val_accuracy: 0.8182 - val_loss: 0.4506\n",
      "Epoch 530/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8182 - loss: 0.4295 - val_accuracy: 0.8182 - val_loss: 0.4508\n",
      "Epoch 531/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4425 - val_accuracy: 0.8182 - val_loss: 0.4506\n",
      "Epoch 532/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.4255 - val_accuracy: 0.8182 - val_loss: 0.4507\n",
      "Epoch 533/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.4317 - val_accuracy: 0.8182 - val_loss: 0.4514\n",
      "Epoch 534/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8021 - loss: 0.4156 - val_accuracy: 0.8182 - val_loss: 0.4509\n",
      "Epoch 535/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8162 - loss: 0.4155 - val_accuracy: 0.8182 - val_loss: 0.4508\n",
      "Epoch 536/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8090 - loss: 0.4201 - val_accuracy: 0.8182 - val_loss: 0.4508\n",
      "Epoch 537/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.4177 - val_accuracy: 0.8117 - val_loss: 0.4500\n",
      "Epoch 538/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7908 - loss: 0.4331 - val_accuracy: 0.8182 - val_loss: 0.4503\n",
      "Epoch 539/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.3997 - val_accuracy: 0.8117 - val_loss: 0.4504\n",
      "Epoch 540/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.4132 - val_accuracy: 0.8182 - val_loss: 0.4510\n",
      "Epoch 541/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.4016 - val_accuracy: 0.8182 - val_loss: 0.4509\n",
      "Epoch 542/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.4095 - val_accuracy: 0.8117 - val_loss: 0.4507\n",
      "Epoch 543/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.3823 - val_accuracy: 0.8117 - val_loss: 0.4506\n",
      "Epoch 544/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.4307 - val_accuracy: 0.8117 - val_loss: 0.4507\n",
      "Epoch 545/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.4271 - val_accuracy: 0.8182 - val_loss: 0.4508\n",
      "Epoch 546/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4420 - val_accuracy: 0.8117 - val_loss: 0.4508\n",
      "Epoch 547/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.4304 - val_accuracy: 0.8182 - val_loss: 0.4511\n",
      "Epoch 548/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.4383 - val_accuracy: 0.8182 - val_loss: 0.4508\n",
      "Epoch 549/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.4000 - val_accuracy: 0.8117 - val_loss: 0.4514\n",
      "Epoch 550/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.4035 - val_accuracy: 0.8117 - val_loss: 0.4517\n",
      "Epoch 551/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.4310 - val_accuracy: 0.8182 - val_loss: 0.4517\n",
      "Epoch 552/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.4218 - val_accuracy: 0.8182 - val_loss: 0.4510\n",
      "Epoch 553/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4345 - val_accuracy: 0.8117 - val_loss: 0.4511\n",
      "Epoch 554/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8174 - loss: 0.4236 - val_accuracy: 0.8182 - val_loss: 0.4509\n",
      "Epoch 555/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8016 - loss: 0.4459 - val_accuracy: 0.8182 - val_loss: 0.4511\n",
      "Epoch 556/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.4107 - val_accuracy: 0.8182 - val_loss: 0.4510\n",
      "Epoch 557/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.4155 - val_accuracy: 0.8182 - val_loss: 0.4513\n",
      "Epoch 558/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.4011 - val_accuracy: 0.8117 - val_loss: 0.4522\n",
      "Epoch 559/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.3970 - val_accuracy: 0.8117 - val_loss: 0.4521\n",
      "Epoch 560/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8142 - loss: 0.4108 - val_accuracy: 0.8117 - val_loss: 0.4518\n",
      "Epoch 561/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8303 - loss: 0.4138 - val_accuracy: 0.8117 - val_loss: 0.4523\n",
      "Epoch 562/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8237 - loss: 0.4097 - val_accuracy: 0.8117 - val_loss: 0.4518\n",
      "Epoch 563/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4130 - val_accuracy: 0.8117 - val_loss: 0.4519\n",
      "Epoch 564/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.3878 - val_accuracy: 0.8052 - val_loss: 0.4519\n",
      "Epoch 565/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.4311 - val_accuracy: 0.8117 - val_loss: 0.4517\n",
      "Epoch 566/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.3924 - val_accuracy: 0.8052 - val_loss: 0.4517\n",
      "Epoch 567/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.4105 - val_accuracy: 0.8052 - val_loss: 0.4514\n",
      "Epoch 568/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.4100 - val_accuracy: 0.8117 - val_loss: 0.4517\n",
      "Epoch 569/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7917 - loss: 0.4363 - val_accuracy: 0.8117 - val_loss: 0.4521\n",
      "Epoch 570/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8337 - loss: 0.3881 - val_accuracy: 0.8182 - val_loss: 0.4514\n",
      "Epoch 571/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.4079 - val_accuracy: 0.8117 - val_loss: 0.4516\n",
      "Epoch 572/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.3824 - val_accuracy: 0.8117 - val_loss: 0.4514\n",
      "Epoch 573/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3888 - val_accuracy: 0.8052 - val_loss: 0.4512\n",
      "Epoch 574/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.4164 - val_accuracy: 0.8052 - val_loss: 0.4511\n",
      "Epoch 575/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.4371 - val_accuracy: 0.8052 - val_loss: 0.4511\n",
      "Epoch 576/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7951 - loss: 0.4404 - val_accuracy: 0.8117 - val_loss: 0.4509\n",
      "Epoch 577/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.3924 - val_accuracy: 0.8117 - val_loss: 0.4514\n",
      "Epoch 578/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8150 - loss: 0.4237 - val_accuracy: 0.8117 - val_loss: 0.4516\n",
      "Epoch 579/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.4182 - val_accuracy: 0.8117 - val_loss: 0.4520\n",
      "Epoch 580/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 0.4209 - val_accuracy: 0.8052 - val_loss: 0.4518\n",
      "Epoch 581/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4234 - val_accuracy: 0.8117 - val_loss: 0.4519\n",
      "Epoch 582/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.3948 - val_accuracy: 0.8117 - val_loss: 0.4519\n",
      "Epoch 583/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.4295 - val_accuracy: 0.8052 - val_loss: 0.4515\n",
      "Epoch 584/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.3857 - val_accuracy: 0.8052 - val_loss: 0.4520\n",
      "Epoch 585/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.3970 - val_accuracy: 0.8052 - val_loss: 0.4515\n",
      "Epoch 586/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.4023 - val_accuracy: 0.8052 - val_loss: 0.4513\n",
      "Epoch 587/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.4225 - val_accuracy: 0.8052 - val_loss: 0.4513\n",
      "Epoch 588/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.4008 - val_accuracy: 0.8052 - val_loss: 0.4510\n",
      "Epoch 589/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.4085 - val_accuracy: 0.8052 - val_loss: 0.4512\n",
      "Epoch 590/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.4048 - val_accuracy: 0.8052 - val_loss: 0.4513\n",
      "Epoch 591/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.4188 - val_accuracy: 0.8052 - val_loss: 0.4516\n",
      "Epoch 592/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.4284 - val_accuracy: 0.8052 - val_loss: 0.4519\n",
      "Epoch 593/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.4358 - val_accuracy: 0.8117 - val_loss: 0.4527\n",
      "Epoch 594/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.4270 - val_accuracy: 0.8117 - val_loss: 0.4532\n",
      "Epoch 595/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8366 - loss: 0.4180 - val_accuracy: 0.8117 - val_loss: 0.4530\n",
      "Epoch 596/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.4201 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 597/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.3941 - val_accuracy: 0.8117 - val_loss: 0.4536\n",
      "Epoch 598/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.4140 - val_accuracy: 0.8117 - val_loss: 0.4534\n",
      "Epoch 599/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.4484 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 600/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8265 - loss: 0.4012 - val_accuracy: 0.8117 - val_loss: 0.4526\n",
      "Epoch 601/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.4096 - val_accuracy: 0.8117 - val_loss: 0.4523\n",
      "Epoch 602/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.4012 - val_accuracy: 0.8117 - val_loss: 0.4526\n",
      "Epoch 603/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8478 - loss: 0.3932 - val_accuracy: 0.8117 - val_loss: 0.4523\n",
      "Epoch 604/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8221 - loss: 0.3991 - val_accuracy: 0.8117 - val_loss: 0.4532\n",
      "Epoch 605/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8386 - loss: 0.3903 - val_accuracy: 0.8117 - val_loss: 0.4532\n",
      "Epoch 606/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.4002 - val_accuracy: 0.8117 - val_loss: 0.4529\n",
      "Epoch 607/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.3984 - val_accuracy: 0.8117 - val_loss: 0.4526\n",
      "Epoch 608/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.3879 - val_accuracy: 0.8052 - val_loss: 0.4519\n",
      "Epoch 609/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8104 - loss: 0.4217 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 610/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7996 - loss: 0.4219 - val_accuracy: 0.8117 - val_loss: 0.4527\n",
      "Epoch 611/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4217 - val_accuracy: 0.8052 - val_loss: 0.4528\n",
      "Epoch 612/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8135 - loss: 0.4246 - val_accuracy: 0.8052 - val_loss: 0.4526\n",
      "Epoch 613/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.3945 - val_accuracy: 0.8052 - val_loss: 0.4520\n",
      "Epoch 614/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.3979 - val_accuracy: 0.8117 - val_loss: 0.4526\n",
      "Epoch 615/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4335 - val_accuracy: 0.8182 - val_loss: 0.4534\n",
      "Epoch 616/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7940 - loss: 0.4507 - val_accuracy: 0.8117 - val_loss: 0.4531\n",
      "Epoch 617/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8047 - loss: 0.4398 - val_accuracy: 0.8052 - val_loss: 0.4530\n",
      "Epoch 618/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.4330 - val_accuracy: 0.8117 - val_loss: 0.4527\n",
      "Epoch 619/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8264 - loss: 0.4067 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 620/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8159 - loss: 0.4108 - val_accuracy: 0.8052 - val_loss: 0.4528\n",
      "Epoch 621/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.4145 - val_accuracy: 0.8052 - val_loss: 0.4530\n",
      "Epoch 622/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.3926 - val_accuracy: 0.8052 - val_loss: 0.4530\n",
      "Epoch 623/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8175 - loss: 0.4253 - val_accuracy: 0.8052 - val_loss: 0.4529\n",
      "Epoch 624/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.4001 - val_accuracy: 0.8052 - val_loss: 0.4523\n",
      "Epoch 625/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.4694 - val_accuracy: 0.8052 - val_loss: 0.4520\n",
      "Epoch 626/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.4221 - val_accuracy: 0.8052 - val_loss: 0.4525\n",
      "Epoch 627/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8112 - loss: 0.4169 - val_accuracy: 0.8052 - val_loss: 0.4523\n",
      "Epoch 628/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.4063 - val_accuracy: 0.8052 - val_loss: 0.4526\n",
      "Epoch 629/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8158 - loss: 0.3923 - val_accuracy: 0.8052 - val_loss: 0.4527\n",
      "Epoch 630/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.4056 - val_accuracy: 0.8052 - val_loss: 0.4527\n",
      "Epoch 631/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.4101 - val_accuracy: 0.8052 - val_loss: 0.4533\n",
      "Epoch 632/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.4108 - val_accuracy: 0.8052 - val_loss: 0.4527\n",
      "Epoch 633/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3826 - val_accuracy: 0.8052 - val_loss: 0.4525\n",
      "Epoch 634/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.4076 - val_accuracy: 0.8052 - val_loss: 0.4527\n",
      "Epoch 635/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8043 - loss: 0.4460 - val_accuracy: 0.8052 - val_loss: 0.4526\n",
      "Epoch 636/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.3681 - val_accuracy: 0.8052 - val_loss: 0.4528\n",
      "Epoch 637/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8223 - loss: 0.4022 - val_accuracy: 0.8052 - val_loss: 0.4527\n",
      "Epoch 638/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8413 - loss: 0.3675 - val_accuracy: 0.8052 - val_loss: 0.4525\n",
      "Epoch 639/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.4230 - val_accuracy: 0.8052 - val_loss: 0.4530\n",
      "Epoch 640/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8386 - loss: 0.3847 - val_accuracy: 0.8052 - val_loss: 0.4523\n",
      "Epoch 641/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.4210 - val_accuracy: 0.8052 - val_loss: 0.4522\n",
      "Epoch 642/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.4402 - val_accuracy: 0.8052 - val_loss: 0.4519\n",
      "Epoch 643/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.3962 - val_accuracy: 0.8052 - val_loss: 0.4522\n",
      "Epoch 644/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.4048 - val_accuracy: 0.8052 - val_loss: 0.4523\n",
      "Epoch 645/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.4151 - val_accuracy: 0.8052 - val_loss: 0.4529\n",
      "Epoch 646/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 0.4057 - val_accuracy: 0.8052 - val_loss: 0.4528\n",
      "Epoch 647/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.3830 - val_accuracy: 0.8052 - val_loss: 0.4526\n",
      "Epoch 648/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8097 - loss: 0.4107 - val_accuracy: 0.8052 - val_loss: 0.4524\n",
      "Epoch 649/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.4046 - val_accuracy: 0.8052 - val_loss: 0.4524\n",
      "Epoch 650/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.3977 - val_accuracy: 0.8052 - val_loss: 0.4520\n",
      "Epoch 651/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8038 - loss: 0.4336 - val_accuracy: 0.8052 - val_loss: 0.4523\n",
      "Epoch 652/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8172 - loss: 0.4253 - val_accuracy: 0.8052 - val_loss: 0.4524\n",
      "Epoch 653/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8489 - loss: 0.3956 - val_accuracy: 0.8052 - val_loss: 0.4523\n",
      "Epoch 654/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.3982 - val_accuracy: 0.8052 - val_loss: 0.4520\n",
      "Epoch 655/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.4067 - val_accuracy: 0.8052 - val_loss: 0.4521\n",
      "Epoch 656/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.4241 - val_accuracy: 0.8052 - val_loss: 0.4523\n",
      "Epoch 657/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.4147 - val_accuracy: 0.8052 - val_loss: 0.4513\n",
      "Epoch 658/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4010 - val_accuracy: 0.8052 - val_loss: 0.4517\n",
      "Epoch 659/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.3993 - val_accuracy: 0.8052 - val_loss: 0.4521\n",
      "Epoch 660/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.4109 - val_accuracy: 0.8052 - val_loss: 0.4521\n",
      "Epoch 661/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.4016 - val_accuracy: 0.8052 - val_loss: 0.4523\n",
      "Epoch 662/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8355 - loss: 0.3793 - val_accuracy: 0.8052 - val_loss: 0.4521\n",
      "Epoch 663/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.4139 - val_accuracy: 0.8052 - val_loss: 0.4526\n",
      "Epoch 664/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3835 - val_accuracy: 0.8052 - val_loss: 0.4523\n",
      "Epoch 665/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.4010 - val_accuracy: 0.8052 - val_loss: 0.4520\n",
      "Epoch 666/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.4069 - val_accuracy: 0.8052 - val_loss: 0.4519\n",
      "Epoch 667/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.4196 - val_accuracy: 0.8052 - val_loss: 0.4517\n",
      "Epoch 668/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.4127 - val_accuracy: 0.8052 - val_loss: 0.4518\n",
      "Epoch 669/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.4151 - val_accuracy: 0.8052 - val_loss: 0.4515\n",
      "Epoch 670/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.4273 - val_accuracy: 0.8052 - val_loss: 0.4516\n",
      "Epoch 671/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.4058 - val_accuracy: 0.8052 - val_loss: 0.4517\n",
      "Epoch 672/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.4010 - val_accuracy: 0.8052 - val_loss: 0.4516\n",
      "Epoch 673/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.3856 - val_accuracy: 0.8052 - val_loss: 0.4521\n",
      "Epoch 674/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.4025 - val_accuracy: 0.8052 - val_loss: 0.4527\n",
      "Epoch 675/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4011 - val_accuracy: 0.8052 - val_loss: 0.4530\n",
      "Epoch 676/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 0.3990 - val_accuracy: 0.8052 - val_loss: 0.4519\n",
      "Epoch 677/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3716 - val_accuracy: 0.8052 - val_loss: 0.4520\n",
      "Epoch 678/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8020 - loss: 0.4386 - val_accuracy: 0.8052 - val_loss: 0.4526\n",
      "Epoch 679/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.3984 - val_accuracy: 0.8052 - val_loss: 0.4534\n",
      "Epoch 680/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.4364 - val_accuracy: 0.8052 - val_loss: 0.4534\n",
      "Epoch 681/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.3920 - val_accuracy: 0.8052 - val_loss: 0.4535\n",
      "Epoch 682/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.4037 - val_accuracy: 0.8052 - val_loss: 0.4531\n",
      "Epoch 683/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.3800 - val_accuracy: 0.8052 - val_loss: 0.4527\n",
      "Epoch 684/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4401 - val_accuracy: 0.8052 - val_loss: 0.4529\n",
      "Epoch 685/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.3987 - val_accuracy: 0.8052 - val_loss: 0.4534\n",
      "Epoch 686/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.3982 - val_accuracy: 0.8052 - val_loss: 0.4538\n",
      "Epoch 687/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.3921 - val_accuracy: 0.8052 - val_loss: 0.4532\n",
      "Epoch 688/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.3968 - val_accuracy: 0.8052 - val_loss: 0.4530\n",
      "Epoch 689/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.4226 - val_accuracy: 0.8052 - val_loss: 0.4527\n",
      "Epoch 690/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.4062 - val_accuracy: 0.8052 - val_loss: 0.4533\n",
      "Epoch 691/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.4162 - val_accuracy: 0.8052 - val_loss: 0.4531\n",
      "Epoch 692/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8259 - loss: 0.3965 - val_accuracy: 0.8052 - val_loss: 0.4530\n",
      "Epoch 693/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.3999 - val_accuracy: 0.8052 - val_loss: 0.4528\n",
      "Epoch 694/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.4230 - val_accuracy: 0.8052 - val_loss: 0.4530\n",
      "Epoch 695/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.4082 - val_accuracy: 0.8052 - val_loss: 0.4530\n",
      "Epoch 696/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.4005 - val_accuracy: 0.8052 - val_loss: 0.4533\n",
      "Epoch 697/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.4080 - val_accuracy: 0.8052 - val_loss: 0.4532\n",
      "Epoch 698/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.3974 - val_accuracy: 0.8052 - val_loss: 0.4527\n",
      "Epoch 699/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.4318 - val_accuracy: 0.8052 - val_loss: 0.4528\n",
      "Epoch 700/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 0.4332 - val_accuracy: 0.8052 - val_loss: 0.4528\n",
      "Epoch 701/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.3994 - val_accuracy: 0.8117 - val_loss: 0.4522\n",
      "Epoch 702/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8293 - loss: 0.3944 - val_accuracy: 0.8117 - val_loss: 0.4522\n",
      "Epoch 703/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.4018 - val_accuracy: 0.8052 - val_loss: 0.4524\n",
      "Epoch 704/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8073 - loss: 0.3918 - val_accuracy: 0.8052 - val_loss: 0.4527\n",
      "Epoch 705/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.4251 - val_accuracy: 0.8117 - val_loss: 0.4534\n",
      "Epoch 706/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8317 - loss: 0.3885 - val_accuracy: 0.8117 - val_loss: 0.4534\n",
      "Epoch 707/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8267 - loss: 0.4020 - val_accuracy: 0.8052 - val_loss: 0.4531\n",
      "Epoch 708/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.4191 - val_accuracy: 0.8052 - val_loss: 0.4534\n",
      "Epoch 709/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7864 - loss: 0.4225 - val_accuracy: 0.8052 - val_loss: 0.4530\n",
      "Epoch 710/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8225 - loss: 0.3827 - val_accuracy: 0.8052 - val_loss: 0.4532\n",
      "Epoch 711/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4141 - val_accuracy: 0.8052 - val_loss: 0.4536\n",
      "Epoch 712/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.4008 - val_accuracy: 0.8052 - val_loss: 0.4536\n",
      "Epoch 713/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3718 - val_accuracy: 0.8052 - val_loss: 0.4536\n",
      "Epoch 714/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.3987 - val_accuracy: 0.8052 - val_loss: 0.4538\n",
      "Epoch 715/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3931 - val_accuracy: 0.7987 - val_loss: 0.4539\n",
      "Epoch 716/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.3732 - val_accuracy: 0.8052 - val_loss: 0.4537\n",
      "Epoch 717/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.3939 - val_accuracy: 0.8052 - val_loss: 0.4540\n",
      "Epoch 718/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.4003 - val_accuracy: 0.7987 - val_loss: 0.4540\n",
      "Epoch 719/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4344 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 720/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7991 - loss: 0.4153 - val_accuracy: 0.8117 - val_loss: 0.4530\n",
      "Epoch 721/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.4020 - val_accuracy: 0.8052 - val_loss: 0.4540\n",
      "Epoch 722/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.4051 - val_accuracy: 0.8052 - val_loss: 0.4543\n",
      "Epoch 723/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4232 - val_accuracy: 0.8117 - val_loss: 0.4536\n",
      "Epoch 724/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.4250 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 725/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8314 - loss: 0.3816 - val_accuracy: 0.8117 - val_loss: 0.4537\n",
      "Epoch 726/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.3952 - val_accuracy: 0.8117 - val_loss: 0.4531\n",
      "Epoch 727/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8124 - loss: 0.4030 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 728/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.3780 - val_accuracy: 0.8117 - val_loss: 0.4529\n",
      "Epoch 729/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.4228 - val_accuracy: 0.8117 - val_loss: 0.4532\n",
      "Epoch 730/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8290 - loss: 0.4092 - val_accuracy: 0.8117 - val_loss: 0.4536\n",
      "Epoch 731/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.3752 - val_accuracy: 0.8117 - val_loss: 0.4534\n",
      "Epoch 732/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8316 - loss: 0.3951 - val_accuracy: 0.8117 - val_loss: 0.4535\n",
      "Epoch 733/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8207 - loss: 0.4017 - val_accuracy: 0.8117 - val_loss: 0.4533\n",
      "Epoch 734/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8274 - loss: 0.3904 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 735/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.3793 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 736/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.4014 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 737/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.4308 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 738/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.3872 - val_accuracy: 0.8117 - val_loss: 0.4544\n",
      "Epoch 739/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.4073 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 740/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4357 - val_accuracy: 0.8117 - val_loss: 0.4540\n",
      "Epoch 741/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.4226 - val_accuracy: 0.8117 - val_loss: 0.4537\n",
      "Epoch 742/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.3990 - val_accuracy: 0.8052 - val_loss: 0.4541\n",
      "Epoch 743/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.4052 - val_accuracy: 0.8052 - val_loss: 0.4544\n",
      "Epoch 744/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.3943 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 745/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8073 - loss: 0.4040 - val_accuracy: 0.8117 - val_loss: 0.4540\n",
      "Epoch 746/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.3670 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 747/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7990 - loss: 0.4271 - val_accuracy: 0.8117 - val_loss: 0.4545\n",
      "Epoch 748/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.4030 - val_accuracy: 0.8117 - val_loss: 0.4544\n",
      "Epoch 749/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.3934 - val_accuracy: 0.8117 - val_loss: 0.4536\n",
      "Epoch 750/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.4032 - val_accuracy: 0.8117 - val_loss: 0.4533\n",
      "Epoch 751/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8177 - loss: 0.4315 - val_accuracy: 0.8117 - val_loss: 0.4531\n",
      "Epoch 752/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.3868 - val_accuracy: 0.8117 - val_loss: 0.4534\n",
      "Epoch 753/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.3953 - val_accuracy: 0.8117 - val_loss: 0.4527\n",
      "Epoch 754/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.4284 - val_accuracy: 0.8117 - val_loss: 0.4527\n",
      "Epoch 755/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8311 - loss: 0.3868 - val_accuracy: 0.8117 - val_loss: 0.4532\n",
      "Epoch 756/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.3896 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 757/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.3821 - val_accuracy: 0.8117 - val_loss: 0.4527\n",
      "Epoch 758/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4163 - val_accuracy: 0.8117 - val_loss: 0.4529\n",
      "Epoch 759/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.3806 - val_accuracy: 0.8117 - val_loss: 0.4525\n",
      "Epoch 760/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7805 - loss: 0.4395 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 761/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8168 - loss: 0.4035 - val_accuracy: 0.8117 - val_loss: 0.4527\n",
      "Epoch 762/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8299 - loss: 0.3923 - val_accuracy: 0.8117 - val_loss: 0.4529\n",
      "Epoch 763/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.3863 - val_accuracy: 0.8117 - val_loss: 0.4531\n",
      "Epoch 764/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.3590 - val_accuracy: 0.8117 - val_loss: 0.4523\n",
      "Epoch 765/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.3877 - val_accuracy: 0.8117 - val_loss: 0.4523\n",
      "Epoch 766/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8247 - loss: 0.3862 - val_accuracy: 0.8117 - val_loss: 0.4529\n",
      "Epoch 767/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.3994 - val_accuracy: 0.8117 - val_loss: 0.4530\n",
      "Epoch 768/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8197 - loss: 0.3863 - val_accuracy: 0.8052 - val_loss: 0.4529\n",
      "Epoch 769/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8074 - loss: 0.4109 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 770/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7993 - loss: 0.4180 - val_accuracy: 0.8117 - val_loss: 0.4526\n",
      "Epoch 771/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8279 - loss: 0.3939 - val_accuracy: 0.8117 - val_loss: 0.4523\n",
      "Epoch 772/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.3875 - val_accuracy: 0.8117 - val_loss: 0.4523\n",
      "Epoch 773/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4064 - val_accuracy: 0.8117 - val_loss: 0.4520\n",
      "Epoch 774/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.4104 - val_accuracy: 0.8117 - val_loss: 0.4521\n",
      "Epoch 775/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8120 - loss: 0.4135 - val_accuracy: 0.8117 - val_loss: 0.4527\n",
      "Epoch 776/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.3978 - val_accuracy: 0.8117 - val_loss: 0.4524\n",
      "Epoch 777/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.3985 - val_accuracy: 0.8117 - val_loss: 0.4522\n",
      "Epoch 778/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.4083 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 779/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8206 - loss: 0.4059 - val_accuracy: 0.8117 - val_loss: 0.4525\n",
      "Epoch 780/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.3925 - val_accuracy: 0.8117 - val_loss: 0.4526\n",
      "Epoch 781/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8004 - loss: 0.4090 - val_accuracy: 0.8052 - val_loss: 0.4535\n",
      "Epoch 782/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.4155 - val_accuracy: 0.8117 - val_loss: 0.4532\n",
      "Epoch 783/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8092 - loss: 0.4192 - val_accuracy: 0.8117 - val_loss: 0.4526\n",
      "Epoch 784/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.3790 - val_accuracy: 0.8117 - val_loss: 0.4529\n",
      "Epoch 785/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.3908 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 786/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.4297 - val_accuracy: 0.8117 - val_loss: 0.4530\n",
      "Epoch 787/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4214 - val_accuracy: 0.8117 - val_loss: 0.4527\n",
      "Epoch 788/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.4159 - val_accuracy: 0.8117 - val_loss: 0.4528\n",
      "Epoch 789/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8093 - loss: 0.4072 - val_accuracy: 0.8117 - val_loss: 0.4532\n",
      "Epoch 790/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.3931 - val_accuracy: 0.8117 - val_loss: 0.4531\n",
      "Epoch 791/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.3842 - val_accuracy: 0.8117 - val_loss: 0.4526\n",
      "Epoch 792/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.3682 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 793/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8331 - loss: 0.3836 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 794/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4084 - val_accuracy: 0.8052 - val_loss: 0.4546\n",
      "Epoch 795/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.3819 - val_accuracy: 0.8052 - val_loss: 0.4549\n",
      "Epoch 796/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.4159 - val_accuracy: 0.8052 - val_loss: 0.4547\n",
      "Epoch 797/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.3762 - val_accuracy: 0.8052 - val_loss: 0.4546\n",
      "Epoch 798/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8175 - loss: 0.4113 - val_accuracy: 0.8052 - val_loss: 0.4549\n",
      "Epoch 799/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8171 - loss: 0.4193 - val_accuracy: 0.8052 - val_loss: 0.4548\n",
      "Epoch 800/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.4029 - val_accuracy: 0.8052 - val_loss: 0.4551\n",
      "Epoch 801/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8058 - loss: 0.4207 - val_accuracy: 0.8052 - val_loss: 0.4552\n",
      "Epoch 802/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.4033 - val_accuracy: 0.8052 - val_loss: 0.4549\n",
      "Epoch 803/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8247 - loss: 0.4013 - val_accuracy: 0.8052 - val_loss: 0.4551\n",
      "Epoch 804/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.3991 - val_accuracy: 0.8052 - val_loss: 0.4550\n",
      "Epoch 805/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.4237 - val_accuracy: 0.8052 - val_loss: 0.4545\n",
      "Epoch 806/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4342 - val_accuracy: 0.8052 - val_loss: 0.4544\n",
      "Epoch 807/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8050 - loss: 0.4097 - val_accuracy: 0.8052 - val_loss: 0.4547\n",
      "Epoch 808/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8016 - loss: 0.4191 - val_accuracy: 0.8052 - val_loss: 0.4549\n",
      "Epoch 809/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.4209 - val_accuracy: 0.8052 - val_loss: 0.4550\n",
      "Epoch 810/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.4113 - val_accuracy: 0.8052 - val_loss: 0.4549\n",
      "Epoch 811/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.4087 - val_accuracy: 0.8052 - val_loss: 0.4542\n",
      "Epoch 812/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8086 - loss: 0.4195 - val_accuracy: 0.8052 - val_loss: 0.4542\n",
      "Epoch 813/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8459 - loss: 0.3996 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 814/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.4131 - val_accuracy: 0.8052 - val_loss: 0.4547\n",
      "Epoch 815/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.3936 - val_accuracy: 0.8052 - val_loss: 0.4555\n",
      "Epoch 816/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.3817 - val_accuracy: 0.8117 - val_loss: 0.4551\n",
      "Epoch 817/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.3896 - val_accuracy: 0.8052 - val_loss: 0.4548\n",
      "Epoch 818/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4027 - val_accuracy: 0.8052 - val_loss: 0.4546\n",
      "Epoch 819/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.4035 - val_accuracy: 0.8052 - val_loss: 0.4547\n",
      "Epoch 820/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.4055 - val_accuracy: 0.8052 - val_loss: 0.4550\n",
      "Epoch 821/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8132 - loss: 0.4126 - val_accuracy: 0.8052 - val_loss: 0.4550\n",
      "Epoch 822/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.3874 - val_accuracy: 0.8052 - val_loss: 0.4552\n",
      "Epoch 823/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.3825 - val_accuracy: 0.8117 - val_loss: 0.4549\n",
      "Epoch 824/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.3910 - val_accuracy: 0.8117 - val_loss: 0.4537\n",
      "Epoch 825/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.3892 - val_accuracy: 0.8117 - val_loss: 0.4549\n",
      "Epoch 826/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8182 - loss: 0.4026 - val_accuracy: 0.8052 - val_loss: 0.4550\n",
      "Epoch 827/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8303 - loss: 0.3819 - val_accuracy: 0.8117 - val_loss: 0.4547\n",
      "Epoch 828/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.4020 - val_accuracy: 0.8117 - val_loss: 0.4545\n",
      "Epoch 829/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.3685 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 830/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3693 - val_accuracy: 0.8117 - val_loss: 0.4544\n",
      "Epoch 831/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.4180 - val_accuracy: 0.8117 - val_loss: 0.4545\n",
      "Epoch 832/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.3985 - val_accuracy: 0.8052 - val_loss: 0.4552\n",
      "Epoch 833/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3700 - val_accuracy: 0.8052 - val_loss: 0.4548\n",
      "Epoch 834/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.4066 - val_accuracy: 0.8052 - val_loss: 0.4545\n",
      "Epoch 835/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3679 - val_accuracy: 0.8117 - val_loss: 0.4535\n",
      "Epoch 836/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.4030 - val_accuracy: 0.8117 - val_loss: 0.4536\n",
      "Epoch 837/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.4074 - val_accuracy: 0.8117 - val_loss: 0.4533\n",
      "Epoch 838/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.4114 - val_accuracy: 0.8052 - val_loss: 0.4540\n",
      "Epoch 839/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.4025 - val_accuracy: 0.8052 - val_loss: 0.4544\n",
      "Epoch 840/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.3920 - val_accuracy: 0.8052 - val_loss: 0.4544\n",
      "Epoch 841/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.3960 - val_accuracy: 0.8052 - val_loss: 0.4545\n",
      "Epoch 842/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.3825 - val_accuracy: 0.8052 - val_loss: 0.4543\n",
      "Epoch 843/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3769 - val_accuracy: 0.8052 - val_loss: 0.4544\n",
      "Epoch 844/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.4104 - val_accuracy: 0.8052 - val_loss: 0.4554\n",
      "Epoch 845/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.3908 - val_accuracy: 0.8052 - val_loss: 0.4548\n",
      "Epoch 846/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8270 - loss: 0.4005 - val_accuracy: 0.8117 - val_loss: 0.4544\n",
      "Epoch 847/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.4004 - val_accuracy: 0.8117 - val_loss: 0.4545\n",
      "Epoch 848/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.4241 - val_accuracy: 0.8117 - val_loss: 0.4542\n",
      "Epoch 849/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8140 - loss: 0.4080 - val_accuracy: 0.8052 - val_loss: 0.4544\n",
      "Epoch 850/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.3970 - val_accuracy: 0.8117 - val_loss: 0.4535\n",
      "Epoch 851/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.4235 - val_accuracy: 0.8052 - val_loss: 0.4536\n",
      "Epoch 852/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.3776 - val_accuracy: 0.8052 - val_loss: 0.4540\n",
      "Epoch 853/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.3853 - val_accuracy: 0.8117 - val_loss: 0.4540\n",
      "Epoch 854/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.4069 - val_accuracy: 0.8052 - val_loss: 0.4539\n",
      "Epoch 855/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.3889 - val_accuracy: 0.8117 - val_loss: 0.4536\n",
      "Epoch 856/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.3834 - val_accuracy: 0.8052 - val_loss: 0.4538\n",
      "Epoch 857/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8142 - loss: 0.4054 - val_accuracy: 0.8117 - val_loss: 0.4541\n",
      "Epoch 858/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.3886 - val_accuracy: 0.8117 - val_loss: 0.4538\n",
      "Epoch 859/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.4330 - val_accuracy: 0.8117 - val_loss: 0.4534\n",
      "Epoch 860/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.4077 - val_accuracy: 0.8117 - val_loss: 0.4537\n",
      "Epoch 861/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.3781 - val_accuracy: 0.8117 - val_loss: 0.4542\n",
      "Epoch 862/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.3890 - val_accuracy: 0.8117 - val_loss: 0.4540\n",
      "Epoch 863/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8139 - loss: 0.3948 - val_accuracy: 0.8117 - val_loss: 0.4545\n",
      "Epoch 864/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4135 - val_accuracy: 0.8117 - val_loss: 0.4547\n",
      "Epoch 865/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7887 - loss: 0.4013 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 866/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.4023 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 867/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3790 - val_accuracy: 0.8117 - val_loss: 0.4551\n",
      "Epoch 868/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.3945 - val_accuracy: 0.8117 - val_loss: 0.4548\n",
      "Epoch 869/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8009 - loss: 0.4091 - val_accuracy: 0.8117 - val_loss: 0.4549\n",
      "Epoch 870/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.3899 - val_accuracy: 0.8117 - val_loss: 0.4546\n",
      "Epoch 871/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.3826 - val_accuracy: 0.8117 - val_loss: 0.4542\n",
      "Epoch 872/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.4135 - val_accuracy: 0.8117 - val_loss: 0.4542\n",
      "Epoch 873/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.3798 - val_accuracy: 0.8117 - val_loss: 0.4538\n",
      "Epoch 874/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.4011 - val_accuracy: 0.8117 - val_loss: 0.4536\n",
      "Epoch 875/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.4125 - val_accuracy: 0.8117 - val_loss: 0.4537\n",
      "Epoch 876/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4022 - val_accuracy: 0.8117 - val_loss: 0.4541\n",
      "Epoch 877/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.3988 - val_accuracy: 0.8117 - val_loss: 0.4536\n",
      "Epoch 878/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.3698 - val_accuracy: 0.8117 - val_loss: 0.4542\n",
      "Epoch 879/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.3878 - val_accuracy: 0.8117 - val_loss: 0.4541\n",
      "Epoch 880/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8183 - loss: 0.4136 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 881/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.4027 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 882/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.3978 - val_accuracy: 0.8117 - val_loss: 0.4535\n",
      "Epoch 883/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3600 - val_accuracy: 0.8117 - val_loss: 0.4535\n",
      "Epoch 884/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8062 - loss: 0.4065 - val_accuracy: 0.8117 - val_loss: 0.4540\n",
      "Epoch 885/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.4225 - val_accuracy: 0.8117 - val_loss: 0.4533\n",
      "Epoch 886/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.3968 - val_accuracy: 0.8117 - val_loss: 0.4533\n",
      "Epoch 887/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.4016 - val_accuracy: 0.8117 - val_loss: 0.4538\n",
      "Epoch 888/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7917 - loss: 0.4397 - val_accuracy: 0.8117 - val_loss: 0.4547\n",
      "Epoch 889/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8207 - loss: 0.3940 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 890/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.3879 - val_accuracy: 0.8117 - val_loss: 0.4545\n",
      "Epoch 891/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3734 - val_accuracy: 0.8117 - val_loss: 0.4547\n",
      "Epoch 892/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.3982 - val_accuracy: 0.8117 - val_loss: 0.4542\n",
      "Epoch 893/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.4131 - val_accuracy: 0.8117 - val_loss: 0.4540\n",
      "Epoch 894/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8237 - loss: 0.4069 - val_accuracy: 0.8117 - val_loss: 0.4545\n",
      "Epoch 895/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3682 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 896/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.4131 - val_accuracy: 0.8117 - val_loss: 0.4544\n",
      "Epoch 897/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8153 - loss: 0.3917 - val_accuracy: 0.8117 - val_loss: 0.4537\n",
      "Epoch 898/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.3971 - val_accuracy: 0.8182 - val_loss: 0.4538\n",
      "Epoch 899/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.3996 - val_accuracy: 0.8182 - val_loss: 0.4540\n",
      "Epoch 900/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8218 - loss: 0.4000 - val_accuracy: 0.8117 - val_loss: 0.4548\n",
      "Epoch 901/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.3892 - val_accuracy: 0.8117 - val_loss: 0.4547\n",
      "Epoch 902/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.3968 - val_accuracy: 0.8117 - val_loss: 0.4550\n",
      "Epoch 903/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8051 - loss: 0.4136 - val_accuracy: 0.8117 - val_loss: 0.4548\n",
      "Epoch 904/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8386 - loss: 0.3697 - val_accuracy: 0.8117 - val_loss: 0.4539\n",
      "Epoch 905/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7981 - loss: 0.4150 - val_accuracy: 0.8117 - val_loss: 0.4541\n",
      "Epoch 906/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7910 - loss: 0.4382 - val_accuracy: 0.8117 - val_loss: 0.4553\n",
      "Epoch 907/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.3894 - val_accuracy: 0.8117 - val_loss: 0.4550\n",
      "Epoch 908/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8271 - loss: 0.3990 - val_accuracy: 0.8117 - val_loss: 0.4548\n",
      "Epoch 909/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.4009 - val_accuracy: 0.8117 - val_loss: 0.4546\n",
      "Epoch 910/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.3827 - val_accuracy: 0.8117 - val_loss: 0.4546\n",
      "Epoch 911/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.3726 - val_accuracy: 0.8117 - val_loss: 0.4552\n",
      "Epoch 912/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.4393 - val_accuracy: 0.8117 - val_loss: 0.4547\n",
      "Epoch 913/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.3782 - val_accuracy: 0.8117 - val_loss: 0.4541\n",
      "Epoch 914/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3877 - val_accuracy: 0.8117 - val_loss: 0.4540\n",
      "Epoch 915/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8153 - loss: 0.4067 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 916/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.3858 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 917/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.4086 - val_accuracy: 0.8117 - val_loss: 0.4550\n",
      "Epoch 918/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4064 - val_accuracy: 0.8117 - val_loss: 0.4552\n",
      "Epoch 919/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4107 - val_accuracy: 0.8117 - val_loss: 0.4553\n",
      "Epoch 920/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3984 - val_accuracy: 0.8182 - val_loss: 0.4550\n",
      "Epoch 921/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.4081 - val_accuracy: 0.8117 - val_loss: 0.4559\n",
      "Epoch 922/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4131 - val_accuracy: 0.8182 - val_loss: 0.4561\n",
      "Epoch 923/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4075 - val_accuracy: 0.8182 - val_loss: 0.4560\n",
      "Epoch 924/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.3747 - val_accuracy: 0.8117 - val_loss: 0.4549\n",
      "Epoch 925/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.3993 - val_accuracy: 0.8182 - val_loss: 0.4550\n",
      "Epoch 926/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.4134 - val_accuracy: 0.8182 - val_loss: 0.4551\n",
      "Epoch 927/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.4043 - val_accuracy: 0.8182 - val_loss: 0.4550\n",
      "Epoch 928/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.4188 - val_accuracy: 0.8182 - val_loss: 0.4554\n",
      "Epoch 929/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3705 - val_accuracy: 0.8182 - val_loss: 0.4553\n",
      "Epoch 930/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4122 - val_accuracy: 0.8117 - val_loss: 0.4553\n",
      "Epoch 931/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.3839 - val_accuracy: 0.8182 - val_loss: 0.4552\n",
      "Epoch 932/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8184 - loss: 0.3942 - val_accuracy: 0.8182 - val_loss: 0.4549\n",
      "Epoch 933/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.3954 - val_accuracy: 0.8182 - val_loss: 0.4548\n",
      "Epoch 934/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7847 - loss: 0.4285 - val_accuracy: 0.8182 - val_loss: 0.4552\n",
      "Epoch 935/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.3890 - val_accuracy: 0.8182 - val_loss: 0.4552\n",
      "Epoch 936/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.3978 - val_accuracy: 0.8182 - val_loss: 0.4558\n",
      "Epoch 937/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8140 - loss: 0.4057 - val_accuracy: 0.8117 - val_loss: 0.4563\n",
      "Epoch 938/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.3886 - val_accuracy: 0.8117 - val_loss: 0.4559\n",
      "Epoch 939/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3632 - val_accuracy: 0.8182 - val_loss: 0.4565\n",
      "Epoch 940/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7907 - loss: 0.4304 - val_accuracy: 0.8182 - val_loss: 0.4548\n",
      "Epoch 941/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8252 - loss: 0.3756 - val_accuracy: 0.8182 - val_loss: 0.4548\n",
      "Epoch 942/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.3943 - val_accuracy: 0.8182 - val_loss: 0.4539\n",
      "Epoch 943/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.3980 - val_accuracy: 0.8117 - val_loss: 0.4549\n",
      "Epoch 944/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.3950 - val_accuracy: 0.8182 - val_loss: 0.4551\n",
      "Epoch 945/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.3823 - val_accuracy: 0.8182 - val_loss: 0.4552\n",
      "Epoch 946/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.4019 - val_accuracy: 0.8117 - val_loss: 0.4549\n",
      "Epoch 947/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8202 - loss: 0.3974 - val_accuracy: 0.8117 - val_loss: 0.4552\n",
      "Epoch 948/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.3954 - val_accuracy: 0.8117 - val_loss: 0.4559\n",
      "Epoch 949/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.3782 - val_accuracy: 0.8117 - val_loss: 0.4562\n",
      "Epoch 950/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.3739 - val_accuracy: 0.8117 - val_loss: 0.4559\n",
      "Epoch 951/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8173 - loss: 0.4034 - val_accuracy: 0.8117 - val_loss: 0.4553\n",
      "Epoch 952/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.3994 - val_accuracy: 0.8182 - val_loss: 0.4559\n",
      "Epoch 953/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.3873 - val_accuracy: 0.8182 - val_loss: 0.4554\n",
      "Epoch 954/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.3981 - val_accuracy: 0.8182 - val_loss: 0.4556\n",
      "Epoch 955/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8073 - loss: 0.4167 - val_accuracy: 0.8182 - val_loss: 0.4559\n",
      "Epoch 956/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.3859 - val_accuracy: 0.8117 - val_loss: 0.4564\n",
      "Epoch 957/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8282 - loss: 0.3787 - val_accuracy: 0.8117 - val_loss: 0.4562\n",
      "Epoch 958/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.3682 - val_accuracy: 0.8117 - val_loss: 0.4563\n",
      "Epoch 959/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.3955 - val_accuracy: 0.8117 - val_loss: 0.4562\n",
      "Epoch 960/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3638 - val_accuracy: 0.8117 - val_loss: 0.4568\n",
      "Epoch 961/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8329 - loss: 0.3821 - val_accuracy: 0.8117 - val_loss: 0.4556\n",
      "Epoch 962/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.3887 - val_accuracy: 0.8117 - val_loss: 0.4553\n",
      "Epoch 963/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.3763 - val_accuracy: 0.8117 - val_loss: 0.4545\n",
      "Epoch 964/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.3902 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 965/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.4326 - val_accuracy: 0.8117 - val_loss: 0.4540\n",
      "Epoch 966/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8196 - loss: 0.3923 - val_accuracy: 0.8117 - val_loss: 0.4543\n",
      "Epoch 967/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.3959 - val_accuracy: 0.8117 - val_loss: 0.4544\n",
      "Epoch 968/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8245 - loss: 0.3859 - val_accuracy: 0.8117 - val_loss: 0.4551\n",
      "Epoch 969/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.4065 - val_accuracy: 0.8182 - val_loss: 0.4565\n",
      "Epoch 970/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.3972 - val_accuracy: 0.8182 - val_loss: 0.4565\n",
      "Epoch 971/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.3921 - val_accuracy: 0.8117 - val_loss: 0.4566\n",
      "Epoch 972/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.3806 - val_accuracy: 0.8117 - val_loss: 0.4561\n",
      "Epoch 973/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8457 - loss: 0.3643 - val_accuracy: 0.8117 - val_loss: 0.4562\n",
      "Epoch 974/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7903 - loss: 0.4190 - val_accuracy: 0.8117 - val_loss: 0.4564\n",
      "Epoch 975/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4081 - val_accuracy: 0.8117 - val_loss: 0.4565\n",
      "Epoch 976/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8104 - loss: 0.3888 - val_accuracy: 0.8117 - val_loss: 0.4560\n",
      "Epoch 977/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3784 - val_accuracy: 0.8117 - val_loss: 0.4560\n",
      "Epoch 978/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.3921 - val_accuracy: 0.8117 - val_loss: 0.4556\n",
      "Epoch 979/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.3997 - val_accuracy: 0.8182 - val_loss: 0.4554\n",
      "Epoch 980/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.4045 - val_accuracy: 0.8117 - val_loss: 0.4552\n",
      "Epoch 981/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.3866 - val_accuracy: 0.8117 - val_loss: 0.4550\n",
      "Epoch 982/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.3757 - val_accuracy: 0.8182 - val_loss: 0.4550\n",
      "Epoch 983/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8093 - loss: 0.4029 - val_accuracy: 0.8117 - val_loss: 0.4558\n",
      "Epoch 984/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.3980 - val_accuracy: 0.8117 - val_loss: 0.4561\n",
      "Epoch 985/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4185 - val_accuracy: 0.8117 - val_loss: 0.4558\n",
      "Epoch 986/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.3839 - val_accuracy: 0.8117 - val_loss: 0.4559\n",
      "Epoch 987/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.3558 - val_accuracy: 0.8117 - val_loss: 0.4561\n",
      "Epoch 988/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.3940 - val_accuracy: 0.8117 - val_loss: 0.4566\n",
      "Epoch 989/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4087 - val_accuracy: 0.8117 - val_loss: 0.4570\n",
      "Epoch 990/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.4060 - val_accuracy: 0.8182 - val_loss: 0.4567\n",
      "Epoch 991/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 0.4198 - val_accuracy: 0.8182 - val_loss: 0.4565\n",
      "Epoch 992/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.4087 - val_accuracy: 0.8182 - val_loss: 0.4566\n",
      "Epoch 993/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.3729 - val_accuracy: 0.8182 - val_loss: 0.4564\n",
      "Epoch 994/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.3859 - val_accuracy: 0.8182 - val_loss: 0.4564\n",
      "Epoch 995/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8186 - loss: 0.3925 - val_accuracy: 0.8182 - val_loss: 0.4554\n",
      "Epoch 996/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8149 - loss: 0.3749 - val_accuracy: 0.8182 - val_loss: 0.4560\n",
      "Epoch 997/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.3821 - val_accuracy: 0.8182 - val_loss: 0.4562\n",
      "Epoch 998/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.3866 - val_accuracy: 0.8182 - val_loss: 0.4559\n",
      "Epoch 999/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8320 - loss: 0.3801 - val_accuracy: 0.8182 - val_loss: 0.4559\n",
      "Epoch 1000/1000\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.3873 - val_accuracy: 0.8182 - val_loss: 0.4562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16568a920>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba7e64",
   "metadata": {},
   "source": [
    "OKAYYY.. so best optimizer is SGD\n",
    "\n",
    "now, lets find number of neurons using keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5babd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef8e44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    units = hp.Int('units', min_value= 8, max_value = 128, step=8)\n",
    "    lr = hp.Choice(\"learning_rate\", values=[1e-1, 2e-2, 3e-3, 4e-4])\n",
    "    model.add(keras.layers.Dense(units, activation=\"relu\", input_dim=8))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61c5c69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(hypermodel=build_model, objective=\"val_accuracy\", max_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71e67854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.27272728085517883\n",
      "\n",
      "Best val_accuracy So Far: 0.8181818127632141\n",
      "Total elapsed time: 00h 01m 36s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5eecb431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 48, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters(num_trials=1)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba3dca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## best parameters\n",
    "best_params= {'units': 48, 'learning_rate': 0.1, \"optimizer\": \"sgd\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c155d",
   "metadata": {},
   "source": [
    "# now lets find the best number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e81af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(best_params[\"units\"], activation=\"relu\", input_dim=8))\n",
    "    units = hp.Int('units', min_value= 8, max_value = 128, step=8)\n",
    "\n",
    "    for i in range(hp.Int(\"num_layers\", min_value=1, max_value=10)):\n",
    "        model.add(keras.layers.Dense(units, activation=\"relu\"))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(learning_rate=best_params[\"learning_rate\"])\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\",  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55348ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(hypermodel=build_model,\n",
    "                        objective=\"val_accuracy\",\n",
    "                        max_trials=1000,\n",
    "                        directory=\"newdir\",\n",
    "                        project_name=\"David Harvey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f41f902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133 Complete [00h 00m 02s]\n",
      "val_accuracy: 0.798701286315918\n",
      "\n",
      "Best val_accuracy So Far: 0.8636363744735718\n",
      "Total elapsed time: 00h 04m 34s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train,y_train, validation_data=(X_test,y_test), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b4a1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tuner.get_best_hyperparameters(num_trials=1)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eeeba772",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params.update(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fa15100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 88, 'learning_rate': 0.1, 'optimizer': 'sgd', 'num_layers': 6}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e167a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
